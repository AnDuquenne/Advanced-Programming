  0%|          | 0/350 [00:00<?, ?it/s]C:\Users\dadou\anaconda3\envs\Advanced-Programming\Lib\site-packages\torch\nn\functional.py:5476: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\aten\src\ATen\native\transformers\cuda\sdp_utils.cpp:263.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0954e+01,  1.0955e+01,  1.0956e+01,  1.0955e+01,  1.0955e+01,
          1.0956e+01,  1.0955e+01,  1.0955e+01,  1.0955e+01,  1.0955e+01],
        [ 4.1928e-01,  5.3986e-01,  6.3195e-01,  6.8159e-01,  7.0957e-01,
          7.5385e-01,  7.5375e-01,  7.4273e-01,  6.8199e-01,  6.6741e-01],
        [ 4.8901e-01,  5.0627e-01,  5.3970e-01,  5.7703e-01,  6.1285e-01,
          6.5095e-01,  6.8140e-01,  7.0342e-01,  7.0809e-01,  7.0871e-01],
        [-1.2812e-01,  2.0960e-01,  4.0603e-01,  4.5331e-01,  4.3508e-01,
          4.6267e-01,  3.6987e-01,  2.6738e-01,  5.6696e-02,  7.6037e-03],
        [        nan,         nan,         nan,         nan,         nan,
                 nan,         nan,         nan,         nan,         nan],
        [        nan,         nan,         nan,         nan,         nan,
                 nan,         nan,         nan,         nan,         nan],
        [ 6.4059e-01,  2.0614e-01,  1.4891e-01,  6.4274e-02,  3.1280e-01,
          2.6810e-01,  5.4688e-01, -4.6018e-01, -5.4050e-01, -7.7851e-01],
        [ 2.7249e-01,  2.8551e-01,  3.3758e-01,  4.0267e-01,  4.4172e-01,
          4.4172e-01,  4.5474e-01,  4.5474e-01,  4.4172e-01,  4.1568e-01]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.9555, 10.9555, 10.9553, 10.9553, 10.9557, 10.9553, 10.9553, 10.9547,
         10.9552, 10.9554]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[10.6428, 10.6421, 10.6435, 10.6439, 10.6417, 10.6416, 10.6430, 10.6412,
         10.6398, 10.6378],
        [-1.0199, -1.0037, -0.9024, -0.7879, -0.8103, -0.8241, -0.7490, -0.7825,
         -0.8748, -1.0475],
        [-0.9739, -0.9930, -0.9867, -0.9573, -0.9385, -0.9265, -0.9008, -0.8874,
         -0.8964, -0.9404],
        [-0.3430, -0.2325,  0.0762,  0.3574,  0.2279,  0.1465,  0.3116,  0.1626,
         -0.1089, -0.5340],
        [    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
             nan,     nan],
        [    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
             nan,     nan],
        [-0.4619,  0.4570,  0.9480, -0.0297, -1.3519, -2.5821, -1.7384, -0.6577,
         -1.0352, -0.2808],
        [-1.0814, -1.1464, -1.1855, -1.1985, -1.0814, -0.9772, -0.8731, -0.6778,
         -0.5737, -0.5476]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.6421, 10.6435, 10.6439, 10.6417, 10.6416, 10.6430, 10.6412, 10.6398,
         10.6378, 10.6395]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[10.5526, 10.5526, 10.5522, 10.5512, 10.5511, 10.5507, 10.5507, 10.5506,
         10.5513, 10.5513],
        [-0.4882, -0.4590, -0.4509, -0.4865, -0.5161, -0.5516, -0.5721, -0.5870,
         -0.5582, -0.5290],
        [-0.5141, -0.5091, -0.5034, -0.5064, -0.5151, -0.5296, -0.5456, -0.5616,
         -0.5683, -0.5674],
        [-0.0187,  0.0607,  0.0695, -0.0367, -0.1058, -0.1766, -0.1942, -0.1942,
         -0.0808,  0.0111],
        [    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
             nan,     nan],
        [    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
             nan,     nan],
        [-0.1960, -0.2538, -0.3889, -0.4761, -0.2982, -0.3159, -0.2299, -0.1968,
         -0.2960,  0.2214],
        [-0.5997, -0.5606, -0.5086, -0.4956, -0.4825, -0.4565, -0.4565, -0.4435,
         -0.4435, -0.4044]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.5526, 10.5522, 10.5512, 10.5511, 10.5507, 10.5507, 10.5506, 10.5513,
         10.5513, 10.5523]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0757e+01,  1.0758e+01,  1.0757e+01,  1.0758e+01,  1.0757e+01,
          1.0758e+01,  1.0758e+01,  1.0757e+01,  1.0757e+01,  1.0757e+01],
        [ 3.7901e-01,  3.5996e-01,  2.7412e-01,  2.9021e-01,  2.4279e-01,
          2.0975e-01,  2.2047e-01,  1.7474e-01,  9.8457e-02,  5.0596e-02],
        [ 4.9559e-01,  4.7319e-01,  4.3697e-01,  4.1143e-01,  3.8089e-01,
          3.4942e-01,  3.2652e-01,  2.9846e-01,  2.5975e-01,  2.1858e-01],
        [-2.7841e-01, -2.7204e-01, -4.3980e-01, -3.1019e-01, -3.7091e-01,
         -3.8223e-01, -2.7804e-01, -3.4079e-01, -4.7008e-01, -4.9995e-01],
        [        nan,         nan,         nan,         nan,         nan,
                 nan,         nan,         nan,         nan,         nan],
        [        nan,         nan,         nan,         nan,         nan,
                 nan,         nan,         nan,         nan,         nan],
        [ 2.3670e-01,  3.2755e-01,  7.9371e-02,  3.0751e-01,  1.7582e-01,
          3.4111e-01,  2.2194e-02,  4.5693e-01,  1.8055e-01,  2.2751e-01],
        [ 2.8551e-01,  2.2042e-01,  1.9438e-01,  1.1628e-01,  1.1628e-01,
          5.1188e-02,  1.2135e-02, -8.8277e-04, -3.9936e-02, -1.1804e-01]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.7580, 10.7570, 10.7584, 10.7574, 10.7575, 10.7582, 10.7573, 10.7567,
         10.7569, 10.7575]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[10.8359, 10.8354, 10.8357, 10.8367, 10.8362, 10.8363, 10.8363, 10.8367,
         10.8364, 10.8370],
        [-0.4992, -0.5971, -0.6447, -0.6105, -0.6137, -0.5970, -0.5774, -0.5332,
         -0.5073, -0.4413],
        [-0.3188, -0.3823, -0.4432, -0.4847, -0.5185, -0.5421, -0.5567, -0.5590,
         -0.5553, -0.5383],
        [-0.6474, -0.7712, -0.7401, -0.5036, -0.4112, -0.2858, -0.1779, -0.0279,
          0.0447,  0.2065],
        [    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
             nan,     nan],
        [    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
             nan,     nan],
        [-0.1172,  0.5717,  0.2955,  0.3868,  0.2843, -0.4672, -0.0772,  0.0764,
          0.2984, -0.9699],
        [-0.2873, -0.4175, -0.5216, -0.6388, -0.6388, -0.6388, -0.6518, -0.5997,
         -0.5606, -0.5216]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.8354, 10.8357, 10.8367, 10.8362, 10.8363, 10.8363, 10.8367, 10.8364,
         10.8370, 10.8373]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[10.5018, 10.5010, 10.5005, 10.5000, 10.5022, 10.5029, 10.5021, 10.5019,
         10.4997, 10.4998],
        [ 0.3964,  0.3388,  0.2642,  0.1795,  0.2192,  0.2806,  0.2873,  0.2771,
          0.1632,  0.0788],
        [ 0.4143,  0.4037,  0.3793,  0.3416,  0.3200,  0.3159,  0.3139,  0.3102,
          0.2829,  0.2431],
        [ 0.0246, -0.1294, -0.2965, -0.4566, -0.2624, -0.0509, -0.0235, -0.0453,
         -0.3309, -0.4833],
        [    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
             nan,     nan],
        [    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
             nan,     nan],
        [ 0.3734,  0.1617, -0.5629, -0.1837,  0.2141,  0.5512,  0.0933,  0.3048,
          0.3278,  0.0921],
        [ 0.4157,  0.3636,  0.2465,  0.1423,  0.0382,  0.0382,  0.0772,  0.0902,
          0.0902, -0.0269]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.5010, 10.5005, 10.5000, 10.5022, 10.5029, 10.5021, 10.5019, 10.4997,
         10.4998, 10.5003]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0677e+01,  1.0677e+01,  1.0677e+01,  1.0677e+01,  1.0678e+01,
          1.0678e+01,  1.0678e+01,  1.0678e+01,  1.0678e+01,  1.0677e+01],
        [-5.3767e-02, -7.8096e-02, -7.7269e-02, -6.8784e-02, -4.6703e-02,
         -3.7928e-02,  7.5927e-03,  4.7082e-02,  4.2175e-02, -2.3943e-04],
        [-1.1008e-01, -1.0471e-01, -1.0023e-01, -9.4847e-02, -8.5831e-02,
         -7.6749e-02, -5.9780e-02, -3.7791e-02, -2.1244e-02, -1.7046e-02],
        [ 1.6024e-01,  6.5221e-02,  5.4323e-02,  6.5419e-02,  1.0949e-01,
          1.1031e-01,  2.0607e-01,  2.6707e-01,  2.0095e-01,  5.0983e-02],
        [        nan,         nan,         nan,         nan,         nan,
                 nan,         nan,         nan,         nan,         nan],
        [        nan,         nan,         nan,         nan,         nan,
                 nan,         nan,         nan,         nan,         nan],
        [-1.4860e-02,  6.9799e-02,  2.1053e-01,  3.8732e-01,  4.2429e-01,
          3.4183e-01,  7.4485e-01,  2.0472e-01,  7.6578e-02, -2.5095e-02],
        [ 2.2042e-01,  2.4645e-01,  2.0740e-01,  1.9438e-01,  1.9438e-01,
          1.6835e-01,  1.2929e-01,  1.1628e-01,  9.0241e-02,  6.4206e-02]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.6770, 10.6773, 10.6775, 10.6777, 10.6776, 10.6782, 10.6783, 10.6777,
         10.6770, 10.6760]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[10.7885, 10.7890, 10.7879, 10.7867, 10.7864, 10.7856, 10.7860, 10.7857,
         10.7855, 10.7850],
        [-0.0325,  0.0521,  0.0471, -0.0329, -0.1152, -0.2315, -0.2946, -0.3606,
         -0.4195, -0.4919],
        [-0.1361, -0.0978, -0.0682, -0.0616, -0.0738, -0.1084, -0.1495, -0.1965,
         -0.2466, -0.3021],
        [ 0.3081,  0.4655,  0.3593,  0.0804, -0.1487, -0.4199, -0.4993, -0.5701,
         -0.6086, -0.6744],
        [    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
             nan,     nan],
        [    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
             nan,     nan],
        [-0.3656, -0.4898, -0.2361, -0.3244, -0.2909, -0.0819, -0.6797, -0.7738,
          0.4850,  0.9241],
        [-0.2612, -0.1961, -0.0920, -0.0399, -0.0660, -0.0790, -0.1311, -0.1831,
         -0.2092, -0.2612]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.7890, 10.7879, 10.7867, 10.7864, 10.7856, 10.7860, 10.7857, 10.7855,
         10.7850, 10.7851]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0650e+01,  1.0650e+01,  1.0651e+01,  1.0652e+01,  1.0653e+01,
          1.0654e+01,  1.0654e+01,  1.0654e+01,  1.0654e+01,  1.0652e+01],
        [ 2.2673e-01,  2.1503e-01,  2.3660e-01,  2.8874e-01,  3.9749e-01,
          5.5491e-01,  6.5419e-01,  7.1499e-01,  7.5451e-01,  6.7960e-01],
        [ 2.2845e-01,  2.2859e-01,  2.3330e-01,  2.4818e-01,  2.8326e-01,
          3.4488e-01,  4.1533e-01,  4.8465e-01,  5.4852e-01,  5.8366e-01],
        [ 3.9967e-02,  1.6815e-03,  5.7183e-02,  1.8071e-01,  4.2604e-01,
          7.4829e-01,  8.5560e-01,  8.4184e-01,  7.7577e-01,  4.2673e-01],
        [        nan,         nan,         nan,         nan,         nan,
                 nan,         nan,         nan,         nan,         nan],
        [        nan,         nan,         nan,         nan,         nan,
                 nan,         nan,         nan,         nan,         nan],
        [-3.4611e-01, -5.4022e-01, -2.2545e-01,  1.1556e-01,  6.2614e-01,
          4.0969e-01,  2.0747e-01,  2.5433e-01,  2.1642e-01, -5.8314e-01],
        [ 2.3344e-01,  2.7249e-01,  3.1154e-01,  3.7663e-01,  4.4172e-01,
          5.1983e-01,  6.3699e-01,  7.2811e-01,  7.6716e-01,  7.8018e-01]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.6504, 10.6510, 10.6517, 10.6530, 10.6544, 10.6540, 10.6539, 10.6539,
         10.6521, 10.6517]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[10.4372, 10.4374, 10.4376, 10.4349, 10.4308, 10.4297, 10.4301, 10.4335,
         10.4361, 10.4361],
        [ 1.3518,  1.3384,  1.3209,  1.1706,  0.8577,  0.5528,  0.3268,  0.2983,
          0.3895,  0.4549],
        [ 1.3810,  1.3901,  1.3936,  1.3643,  1.2743,  1.1372,  0.9794,  0.8471,
          0.7607,  0.7055],
        [ 0.1810,  0.1100,  0.0427, -0.3550, -1.0938, -1.6641, -1.9164, -1.6069,
         -1.0495, -0.6703],
        [    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
             nan,     nan],
        [    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
             nan,     nan],
        [ 2.1594,  1.8958,  0.6179, -0.2508, -0.7154, -0.1660,  0.5137,  0.5171,
          0.5157,  1.3312],
        [ 1.5612,  1.4050,  1.2488,  1.0275,  0.7411,  0.3115, -0.1180, -0.4305,
         -0.5216, -0.4435]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.4374, 10.4376, 10.4349, 10.4308, 10.4297, 10.4301, 10.4335, 10.4361,
         10.4361, 10.4343]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[10.5792, 10.5779, 10.5781, 10.5782, 10.5789, 10.5795, 10.5799, 10.5799,
         10.5796, 10.5792],
        [-0.3297, -0.4945, -0.6064, -0.6807, -0.6947, -0.6707, -0.6202, -0.5727,
         -0.5451, -0.5413],
        [ 0.0811, -0.0406, -0.1617, -0.2744, -0.3676, -0.4370, -0.4818, -0.5075,
         -0.5222, -0.5331],
        [-1.3127, -1.4769, -1.4710, -1.3693, -1.1315, -0.8430, -0.5438, -0.3122,
         -0.1783, -0.1327],
        [    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
             nan,     nan],
        [    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
             nan,     nan],
        [ 0.7242,  0.9435,  0.7849,  1.7503,  1.4377,  1.0957,  0.9436, -0.5201,
         -1.0614, -1.3306],
        [-0.0790, -0.3003, -0.5737, -0.8080, -0.9902, -1.1595, -1.2376, -1.2376,
         -1.2506, -1.1725]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.5779, 10.5781, 10.5782, 10.5789, 10.5795, 10.5799, 10.5799, 10.5796,
         10.5792, 10.5800]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[10.9236, 10.9216, 10.9221, 10.9232, 10.9235, 10.9232, 10.9246, 10.9264,
         10.9253, 10.9258],
        [-2.4015, -2.6493, -2.7797, -2.7676, -2.7106, -2.6552, -2.4805, -2.1834,
         -2.0037, -1.8025],
        [-1.4967, -1.7620, -2.0020, -2.1915, -2.3309, -2.4306, -2.4731, -2.4439,
         -2.3821, -2.2899],
        [-3.2259, -3.2219, -2.9151, -2.3007, -1.6931, -1.2111, -0.5166,  0.3556,
          0.7495,  1.1204],
        [    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
             nan,     nan],
        [    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
             nan,     nan],
        [ 1.7941,  0.6353,  1.2521, -1.0723, -2.1291, -1.9287, -2.3000, -1.7247,
         -2.3163, -2.2714],
        [-2.2660, -2.5784, -2.7476, -2.8648, -3.0080, -2.8648, -2.6565, -2.3701,
         -1.9275, -1.5370]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.9216, 10.9221, 10.9232, 10.9235, 10.9232, 10.9246, 10.9264, 10.9253,
         10.9258, 10.9261]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[10.8348, 10.8337, 10.8330, 10.8333, 10.8330, 10.8329, 10.8340, 10.8339,
         10.8310, 10.8340],
        [-0.0922, -0.1596, -0.2592, -0.3147, -0.3722, -0.4228, -0.3810, -0.3496,
         -0.5183, -0.4445],
        [-0.1385, -0.1448, -0.1711, -0.2040, -0.2425, -0.2841, -0.3085, -0.3213,
         -0.3675, -0.3888],
        [ 0.1224, -0.0765, -0.3191, -0.3989, -0.4679, -0.5054, -0.2962, -0.1557,
         -0.5612, -0.2579],
        [    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
             nan,     nan],
        [    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
             nan,     nan],
        [-0.6236, -0.5447,  0.2614,  1.0505,  1.3096,  1.1692,  0.8947,  0.6529,
         -0.2728,  0.1077],
        [ 0.2595,  0.2725,  0.2074,  0.1163,  0.0252, -0.0920, -0.1961, -0.2612,
         -0.3263, -0.5216]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.8337, 10.8330, 10.8333, 10.8330, 10.8329, 10.8340, 10.8339, 10.8310,
         10.8340, 10.8373]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[10.9582, 10.9583, 10.9580, 10.9587, 10.9591, 10.9592, 10.9606, 10.9600,
         10.9607, 10.9609],
        [ 0.3865,  0.4448,  0.4635,  0.5254,  0.5977,  0.6583,  0.8071,  0.8644,
          0.9560,  1.0284],
        [ 0.0765,  0.1560,  0.2236,  0.2908,  0.3601,  0.4283,  0.5147,  0.5960,
          0.6805,  0.7636],
        [ 1.0181,  0.9653,  0.8208,  0.8169,  0.8405,  0.8293,  1.0486,  0.9873,
          1.0270,  1.0090],
        [    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
             nan,     nan],
        [    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
             nan,     nan],
        [ 0.9958,  0.4844, -0.9805, -0.4194, -0.9379, -0.5921, -0.0244,  0.2705,
          0.4551,  0.2771],
        [ 0.6370,  0.5979,  0.5459,  0.4938,  0.5198,  0.5328,  0.5849,  0.7151,
          0.7541,  0.8323]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.9583, 10.9580, 10.9587, 10.9591, 10.9592, 10.9606, 10.9600, 10.9607,
         10.9609, 10.9607]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[10.3611, 10.3625, 10.3646, 10.3628, 10.3634, 10.3626, 10.3651, 10.3637,
         10.3628, 10.3638],
        [-0.5701, -0.5534, -0.4458, -0.4317, -0.3938, -0.3908, -0.2788, -0.2458,
         -0.2549, -0.2193],
        [-0.1042, -0.2013, -0.2561, -0.2969, -0.3214, -0.3405, -0.3318, -0.3178,
         -0.3086, -0.2936],
        [-1.5282, -1.1792, -0.6649, -0.4954, -0.2982, -0.2309,  0.1054,  0.1696,
          0.1122,  0.1819],
        [    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
             nan,     nan],
        [    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
             nan,     nan],
        [ 1.7634,  0.8421, -0.1113, -0.9141, -0.0518, -2.1000, -1.8248, -1.0754,
         -1.6610, -1.4712],
        [-1.4198, -1.7192, -1.8103, -1.7713, -1.7843, -1.6411, -1.5109, -1.0944,
         -0.7559, -0.5737]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.3625, 10.3646, 10.3628, 10.3634, 10.3626, 10.3651, 10.3637, 10.3628,
         10.3638, 10.3653]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0963e+01,  1.0963e+01,  1.0963e+01,  1.0963e+01,  1.0963e+01,
          1.0962e+01,  1.0962e+01,  1.0964e+01,  1.0963e+01,  1.0963e+01],
        [ 6.2104e-01,  5.8275e-01,  5.4886e-01,  4.7469e-01,  4.2246e-01,
          2.9787e-01,  2.3900e-01,  3.0274e-01,  2.9747e-01,  2.7203e-01],
        [ 7.2158e-01,  7.0146e-01,  6.7815e-01,  6.4369e-01,  6.0499e-01,
          5.4748e-01,  4.8892e-01,  4.5566e-01,  4.2793e-01,  4.0032e-01],
        [-1.8145e-01, -2.4427e-01, -2.8314e-01, -4.1848e-01, -4.6996e-01,
         -6.9846e-01, -7.1115e-01, -4.0393e-01, -3.3680e-01, -3.3528e-01],
        [        nan,         nan,         nan,         nan,         nan,
                 nan,         nan,         nan,         nan,         nan],
        [        nan,         nan,         nan,         nan,         nan,
                 nan,         nan,         nan,         nan,         nan],
        [ 7.1161e-02,  3.6615e-01,  5.1810e-01, -1.8524e-01,  5.1388e-01,
          3.5185e-01,  3.6058e-01,  5.8358e-01,  1.9050e-01, -1.2846e-01],
        [ 3.7663e-01,  3.5060e-01,  2.8551e-01,  2.2042e-01,  1.5533e-01,
          1.1628e-01, -8.8277e-04, -6.5971e-02, -3.9936e-02, -6.5971e-02]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.9631, 10.9631, 10.9625, 10.9627, 10.9617, 10.9622, 10.9637, 10.9630,
         10.9628, 10.9627]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0798e+01,  1.0801e+01,  1.0801e+01,  1.0799e+01,  1.0794e+01,
          1.0792e+01,  1.0794e+01,  1.0795e+01,  1.0792e+01,  1.0791e+01],
        [-2.1942e+00, -2.2486e+00, -2.2523e+00, -2.3566e+00, -2.7428e+00,
         -3.1650e+00, -3.3097e+00, -3.3316e+00, -3.4997e+00, -3.6414e+00],
        [-1.9832e+00, -2.0658e+00, -2.1327e+00, -2.2084e+00, -2.3513e+00,
         -2.5556e+00, -2.7499e+00, -2.9099e+00, -3.0739e+00, -3.2352e+00],
        [-1.0779e+00, -1.0033e+00, -8.1202e-01, -9.1959e-01, -1.7353e+00,
         -2.4810e+00, -2.3595e+00, -1.9442e+00, -1.9906e+00, -1.9591e+00],
        [        nan,         nan,         nan,         nan,         nan,
                 nan,         nan,         nan,         nan,         nan],
        [        nan,         nan,         nan,         nan,         nan,
                 nan,         nan,         nan,         nan,         nan],
        [-1.9918e+00, -9.6061e-01,  9.2552e-02,  4.5288e-01,  4.0452e-03,
          1.6122e+00,  1.0962e+00,  2.7346e+00,  9.6129e-01,  7.6393e-01],
        [-1.4979e+00, -1.4849e+00, -1.3287e+00, -1.2636e+00, -1.2636e+00,
         -1.5500e+00, -1.9145e+00, -2.2009e+00, -2.3701e+00, -2.6695e+00]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.8012, 10.8014, 10.7994, 10.7943, 10.7919, 10.7943, 10.7951, 10.7922,
         10.7914, 10.7912]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0478e+01,  1.0477e+01,  1.0477e+01,  1.0477e+01,  1.0478e+01,
          1.0479e+01,  1.0478e+01,  1.0477e+01,  1.0479e+01,  1.0479e+01],
        [ 8.9144e-01,  8.6187e-01,  7.9311e-01,  7.2643e-01,  7.4564e-01,
          7.8783e-01,  7.4580e-01,  6.6914e-01,  7.1962e-01,  7.1769e-01],
        [ 9.3812e-01,  9.3418e-01,  9.1638e-01,  8.8793e-01,  8.6926e-01,
          8.6332e-01,  8.4961e-01,  8.2230e-01,  8.1121e-01,  8.0193e-01],
        [ 3.5969e-02, -4.7764e-02, -2.1619e-01, -3.4554e-01, -2.2669e-01,
         -7.2158e-02, -1.6652e-01, -3.3163e-01, -1.3465e-01, -1.1271e-01],
        [        nan,         nan,         nan,         nan,         nan,
                 nan,         nan,         nan,         nan,         nan],
        [        nan,         nan,         nan,         nan,         nan,
                 nan,         nan,         nan,         nan,         nan],
        [-4.8876e-01, -5.9831e-01, -5.6657e-03, -4.5143e-01,  4.5675e-01,
          1.5098e+00,  1.0843e+00,  2.5355e-01,  3.9585e-01,  1.3361e-01],
        [ 7.1509e-01,  7.6716e-01,  7.9320e-01,  7.6716e-01,  7.4113e-01,
          7.6716e-01,  7.8018e-01,  6.3699e-01,  5.1983e-01,  5.1983e-01]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.4774, 10.4767, 10.4766, 10.4783, 10.4790, 10.4776, 10.4769, 10.4794,
         10.4787, 10.4804]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[10.5668, 10.5677, 10.5647, 10.5646, 10.5644, 10.5650, 10.5647, 10.5639,
         10.5629, 10.5656],
        [ 0.3528,  0.4199,  0.3141,  0.2256,  0.1428,  0.1061,  0.0625, -0.0169,
         -0.1301, -0.0754],
        [ 0.0893,  0.1609,  0.1957,  0.2046,  0.1941,  0.1779,  0.1557,  0.1209,
          0.0690,  0.0391],
        [ 0.8704,  0.8700,  0.4220,  0.1086, -0.1274, -0.1968, -0.2703, -0.4219,
         -0.6304, -0.3628],
        [    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
             nan,     nan],
        [    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
             nan,     nan],
        [-0.1548, -0.0465, -0.5664, -1.2133, -0.3342,  0.0629,  0.7186,  1.7493,
          0.4210,  1.1302],
        [ 0.6500,  0.6760,  0.7021,  0.5849,  0.4938,  0.4287,  0.3506,  0.2725,
          0.1553, -0.0790]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.5677, 10.5647, 10.5646, 10.5644, 10.5650, 10.5647, 10.5639, 10.5629,
         10.5656, 10.5664]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0752e+01,  1.0752e+01,  1.0751e+01,  1.0751e+01,  1.0749e+01,
          1.0749e+01,  1.0750e+01,  1.0750e+01,  1.0751e+01,  1.0751e+01],
        [ 2.6691e-01,  3.4662e-01,  3.8860e-01,  3.6779e-01,  2.6036e-01,
          1.8213e-01,  1.7166e-01,  1.3030e-01,  1.4824e-01,  1.7136e-01],
        [ 1.7059e-01,  2.1035e-01,  2.5110e-01,  2.7927e-01,  2.7890e-01,
          2.6194e-01,  2.4614e-01,  2.2468e-01,  2.1134e-01,  2.0559e-01],
        [ 3.4563e-01,  4.8282e-01,  4.9490e-01,  3.4206e-01, -4.3956e-03,
         -2.0602e-01, -1.9190e-01, -2.6059e-01, -1.6202e-01, -6.9774e-02],
        [        nan,         nan,         nan,         nan,         nan,
                 nan,         nan,         nan,         nan,         nan],
        [        nan,         nan,         nan,         nan,         nan,
                 nan,         nan,         nan,         nan,         nan],
        [-3.0739e-01,  2.3993e-01,  5.0118e-02, -6.9300e-01, -7.1839e-01,
         -5.9880e-01, -8.1286e-01, -7.3973e-01,  3.2693e-01,  1.0481e+00],
        [-9.2007e-02, -8.8277e-04,  1.2929e-01,  2.0740e-01,  2.3344e-01,
          2.2042e-01,  1.9438e-01,  1.9438e-01,  2.0740e-01,  2.4645e-01]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.7518, 10.7515, 10.7507, 10.7493, 10.7494, 10.7503, 10.7498, 10.7506,
         10.7508, 10.7508]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0799e+01,  1.0799e+01,  1.0799e+01,  1.0799e+01,  1.0800e+01,
          1.0801e+01,  1.0800e+01,  1.0800e+01,  1.0799e+01,  1.0800e+01],
        [ 1.8347e-02, -2.7819e-02, -8.4432e-02, -1.0931e-01, -6.4781e-02,
         -1.6901e-02, -2.5629e-02, -3.7198e-02, -1.2834e-01, -9.3965e-02],
        [ 1.7898e-01,  1.3726e-01,  9.1810e-02,  5.0151e-02,  2.6314e-02,
          1.7449e-02,  8.4967e-03, -1.1312e-03, -2.8258e-02, -4.2634e-02],
        [-4.8405e-01, -5.0673e-01, -5.5191e-01, -5.0593e-01, -2.8948e-01,
         -1.0766e-01, -1.0871e-01, -1.1692e-01, -3.2943e-01, -1.7458e-01],
        [        nan,         nan,         nan,         nan,         nan,
                 nan,         nan,         nan,         nan,         nan],
        [        nan,         nan,         nan,         nan,         nan,
                 nan,         nan,         nan,         nan,         nan],
        [-2.6173e-01, -2.6556e-01, -2.8296e-01,  6.7308e-02,  4.9539e-01,
          7.0023e-01,  9.9019e-01,  2.8158e-01,  4.5609e-02, -3.2171e-01],
        [ 9.0241e-02, -3.9936e-02, -7.8989e-02, -1.4408e-01, -1.8313e-01,
         -1.7011e-01, -1.4408e-01, -1.5710e-01, -1.9615e-01, -2.6124e-01]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.7995, 10.7991, 10.7994, 10.8004, 10.8006, 10.7999, 10.7998, 10.7985,
         10.8001, 10.8003]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0943e+01,  1.0944e+01,  1.0943e+01,  1.0943e+01,  1.0942e+01,
          1.0940e+01,  1.0941e+01,  1.0942e+01,  1.0943e+01,  1.0942e+01],
        [-6.9436e-02,  3.4561e-03,  4.6077e-02,  1.5633e-02, -7.6124e-02,
         -2.5214e-01, -3.2126e-01, -3.0585e-01, -2.5067e-01, -2.4414e-01],
        [-2.5131e-01, -2.0031e-01, -1.5043e-01, -1.1701e-01, -1.0983e-01,
         -1.4160e-01, -1.8175e-01, -2.1059e-01, -2.2189e-01, -2.2955e-01],
        [ 5.3834e-01,  6.1934e-01,  6.0579e-01,  4.0583e-01,  8.7173e-02,
         -3.8585e-01, -4.8758e-01, -3.5018e-01, -1.3731e-01, -9.2955e-02],
        [        nan,         nan,         nan,         nan,         nan,
                 nan,         nan,         nan,         nan,         nan],
        [        nan,         nan,         nan,         nan,         nan,
                 nan,         nan,         nan,         nan,         nan],
        [ 3.7634e-01,  3.5384e-01,  2.9477e-01, -1.5190e-01, -7.0967e-01,
         -4.6074e-01, -1.1798e-01,  3.2703e-01, -2.8557e-02,  8.8328e-01],
        [ 9.0241e-02,  1.0326e-01,  1.1628e-01,  1.4231e-01,  1.1628e-01,
          5.1188e-02, -5.2954e-02, -1.3106e-01, -1.4408e-01, -1.1804e-01]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.9436, 10.9434, 10.9425, 10.9416, 10.9402, 10.9411, 10.9420, 10.9425,
         10.9420, 10.9418]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0801e+01,  1.0799e+01,  1.0794e+01,  1.0792e+01,  1.0794e+01,
          1.0795e+01,  1.0792e+01,  1.0791e+01,  1.0791e+01,  1.0790e+01],
        [-2.2523e+00, -2.3566e+00, -2.7428e+00, -3.1650e+00, -3.3097e+00,
         -3.3316e+00, -3.4997e+00, -3.6414e+00, -3.7224e+00, -3.8006e+00],
        [-2.1327e+00, -2.2084e+00, -2.3513e+00, -2.5556e+00, -2.7499e+00,
         -2.9099e+00, -3.0739e+00, -3.2352e+00, -3.3815e+00, -3.5152e+00],
        [-8.1202e-01, -9.1959e-01, -1.7353e+00, -2.4810e+00, -2.3595e+00,
         -1.9442e+00, -1.9906e+00, -1.9591e+00, -1.7769e+00, -1.6240e+00],
        [        nan,         nan,         nan,         nan,         nan,
                 nan,         nan,         nan,         nan,         nan],
        [        nan,         nan,         nan,         nan,         nan,
                 nan,         nan,         nan,         nan,         nan],
        [ 9.2552e-02,  4.5288e-01,  4.0452e-03,  1.6122e+00,  1.0962e+00,
          2.7346e+00,  9.6129e-01,  7.6393e-01, -1.5236e+00,  6.4384e-01],
        [-1.3287e+00, -1.2636e+00, -1.2636e+00, -1.5500e+00, -1.9145e+00,
         -2.2009e+00, -2.3701e+00, -2.6695e+00, -2.9038e+00, -3.0470e+00]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.7994, 10.7943, 10.7919, 10.7943, 10.7951, 10.7922, 10.7914, 10.7912,
         10.7903, 10.7927]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[10.8026, 10.8024, 10.8035, 10.8003, 10.8006, 10.8005, 10.8013, 10.8015,
         10.8009, 10.8007],
        [-0.4256, -0.3821, -0.2684, -0.3846, -0.4547, -0.5082, -0.4955, -0.4686,
         -0.4782, -0.4933],
        [-0.3877, -0.3916, -0.3705, -0.3784, -0.3996, -0.4280, -0.4480, -0.4583,
         -0.4685, -0.4800],
        [-0.2000, -0.0472,  0.2565, -0.0957, -0.2578, -0.3447, -0.2431, -0.1248,
         -0.1247, -0.1388],
        [    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
             nan,     nan],
        [    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
             nan,     nan],
        [ 0.3059,  0.2234,  0.0577, -0.7197, -0.7145, -0.9215, -0.5467, -0.5450,
         -0.8045, -0.2245],
        [-0.4695, -0.5216, -0.5216, -0.4565, -0.5476, -0.5476, -0.5346, -0.4695,
         -0.3914, -0.3393]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.8024, 10.8035, 10.8003, 10.8006, 10.8005, 10.8013, 10.8015, 10.8009,
         10.8007, 10.8002]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[10.5921, 10.5925, 10.5921, 10.5924, 10.5928, 10.5923, 10.5929, 10.5918,
         10.5928, 10.5943],
        [-1.0137, -1.0265, -1.0423, -1.0315, -0.9878, -0.9699, -0.9117, -0.9151,
         -0.8514, -0.7176],
        [-0.6252, -0.7189, -0.7973, -0.8577, -0.8967, -0.9241, -0.9336, -0.9419,
         -0.9350, -0.9009],
        [-1.3815, -1.1382, -0.9516, -0.7334, -0.4735, -0.3326, -0.1154, -0.1010,
          0.0839,  0.4136],
        [    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
             nan,     nan],
        [    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
             nan,     nan],
        [-0.0448, -0.0876,  0.0732,  0.3321, -0.0854, -1.6751, -1.4925, -0.4442,
         -0.9079, -0.8981],
        [-1.4979, -1.5630, -1.5890, -1.5630, -1.4849, -1.3808, -1.2636, -1.0553,
         -0.9382, -0.8080]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.5925, 10.5921, 10.5924, 10.5928, 10.5923, 10.5929, 10.5918, 10.5928,
         10.5943, 10.5936]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[10.5187, 10.5188, 10.5185, 10.5177, 10.5207, 10.5204, 10.5206, 10.5204,
         10.5217, 10.5210],
        [ 2.5713,  2.5822,  2.5461,  2.4523,  2.4931,  2.4816,  2.4544,  2.3988,
          2.3915,  2.3235],
        [ 2.4865,  2.5396,  2.5743,  2.5821,  2.5970,  2.6065,  2.6083,  2.5979,
          2.5880,  2.5656],
        [ 0.7699,  0.6442,  0.4218,  0.0948,  0.1814,  0.1153,  0.0218, -0.1264,
         -0.1201, -0.2721],
        [    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
             nan,     nan],
        [    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
             nan,     nan],
        [ 3.1029,  2.8930,  2.3040,  2.8709,  2.0427,  1.1185,  0.7063,  0.3617,
          0.1596,  0.0866],
        [ 3.5660,  3.5530,  3.2796,  3.0322,  2.7459,  2.3683,  2.0559,  1.8216,
          1.5743,  1.4571]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.5188, 10.5185, 10.5177, 10.5207, 10.5204, 10.5206, 10.5204, 10.5217,
         10.5210, 10.5216]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[10.7523, 10.7520, 10.7520, 10.7517, 10.7524, 10.7527, 10.7537, 10.7524,
         10.7522, 10.7522],
        [-0.8378, -0.7804, -0.7294, -0.6992, -0.6235, -0.5389, -0.4046, -0.3762,
         -0.3575, -0.3393],
        [-0.8414, -0.8394, -0.8270, -0.8106, -0.7814, -0.7400, -0.6782, -0.6227,
         -0.5744, -0.5318],
        [-0.1563,  0.0236,  0.1509,  0.1988,  0.3551,  0.5030,  0.7500,  0.6735,
          0.5871,  0.5169],
        [    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
             nan,     nan],
        [    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
             nan,     nan],
        [-0.5439, -1.1471, -0.7186, -1.2021, -1.2195, -0.7769, -0.6011, -0.9213,
         -1.0042, -0.0290],
        [-1.1204, -1.0163, -0.8991, -0.7689, -0.6518, -0.4695, -0.2612, -0.0660,
          0.0512,  0.1553]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.7520, 10.7520, 10.7517, 10.7524, 10.7527, 10.7537, 10.7524, 10.7522,
         10.7522, 10.7541]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0656e+01,  1.0656e+01,  1.0655e+01,  1.0655e+01,  1.0656e+01,
          1.0656e+01,  1.0655e+01,  1.0655e+01,  1.0655e+01,  1.0655e+01],
        [ 1.8554e-01,  2.6111e-01,  3.1309e-01,  3.4765e-01,  3.8217e-01,
          4.1339e-01,  4.0984e-01,  3.8850e-01,  3.6825e-01,  3.5138e-01],
        [ 3.6608e-03,  5.8580e-02,  1.1359e-01,  1.6497e-01,  2.1343e-01,
          2.5885e-01,  2.9442e-01,  3.1834e-01,  3.3316e-01,  3.4142e-01],
        [ 5.8919e-01,  6.6696e-01,  6.6809e-01,  6.2394e-01,  5.8849e-01,
          5.5161e-01,  4.3209e-01,  2.9045e-01,  1.7995e-01,  1.0028e-01],
        [        nan,         nan,         nan,         nan,         nan,
                 nan,         nan,         nan,         nan,         nan],
        [        nan,         nan,         nan,         nan,         nan,
                 nan,         nan,         nan,         nan,         nan],
        [-1.3954e-01, -1.0026e-01,  2.4779e-02, -5.5080e-02, -3.4982e-02,
         -1.1223e-01, -3.6199e-01, -4.6415e-01, -2.4558e-01,  4.4378e-01],
        [ 2.2042e-01,  3.3758e-01,  4.2870e-01,  4.9379e-01,  5.3284e-01,
          5.7190e-01,  5.9793e-01,  5.9793e-01,  5.7190e-01,  5.4586e-01]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.6555, 10.6554, 10.6554, 10.6556, 10.6557, 10.6553, 10.6551, 10.6551,
         10.6551, 10.6552]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0770e+01,  1.0769e+01,  1.0769e+01,  1.0770e+01,  1.0770e+01,
          1.0770e+01,  1.0771e+01,  1.0770e+01,  1.0771e+01,  1.0770e+01],
        [-4.0368e-01, -4.5454e-01, -4.8616e-01, -4.8771e-01, -4.5513e-01,
         -4.2505e-01, -3.6520e-01, -3.3607e-01, -2.8220e-01, -2.6763e-01],
        [-3.9297e-01, -4.1125e-01, -4.3262e-01, -4.5004e-01, -4.5703e-01,
         -4.5622e-01, -4.4281e-01, -4.2587e-01, -4.0084e-01, -3.7771e-01],
        [-1.1298e-01, -2.2203e-01, -2.5946e-01, -2.1158e-01, -8.4927e-02,
          9.9073e-03,  1.6284e-01,  2.0567e-01,  3.0396e-01,  2.8089e-01],
        [        nan,         nan,         nan,         nan,         nan,
                 nan,         nan,         nan,         nan,         nan],
        [        nan,         nan,         nan,         nan,         nan,
                 nan,         nan,         nan,         nan,         nan],
        [ 3.1142e-02,  6.8411e-02, -2.6958e-01,  1.5838e-02,  5.0282e-01,
          4.2245e-01,  2.3505e-01, -1.0303e-01, -2.7561e-01,  2.3872e-02],
        [-2.0917e-01, -1.9615e-01, -2.2218e-01, -2.4822e-01, -2.6124e-01,
         -2.6124e-01, -2.7426e-01, -2.3520e-01, -2.0917e-01, -1.8313e-01]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.7694, 10.7694, 10.7697, 10.7701, 10.7701, 10.7706, 10.7703, 10.7707,
         10.7702, 10.7699]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[10.8006, 10.8004, 10.8011, 10.8008, 10.7997, 10.8002, 10.7998, 10.8014,
         10.8016, 10.8006],
        [-0.1087, -0.2370, -0.2879, -0.3419, -0.4495, -0.4979, -0.5550, -0.4896,
         -0.4211, -0.4285],
        [ 0.1885,  0.1003,  0.0189, -0.0578, -0.1420, -0.2197, -0.2941, -0.3396,
         -0.3614, -0.3805],
        [-0.9242, -1.0713, -0.9887, -0.9309, -1.0231, -0.9439, -0.9029, -0.5529,
         -0.2651, -0.2313],
        [    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
             nan,     nan],
        [    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
             nan,     nan],
        [ 1.2111,  0.2973,  0.3195, -0.1679,  0.3235, -0.1099, -0.4059,  0.5520,
          0.0485, -0.0926],
        [-0.1311, -0.3263, -0.4825, -0.5476, -0.6388, -0.7559, -0.7950, -0.8210,
         -0.7299, -0.6778]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.8004, 10.8011, 10.8008, 10.7997, 10.8002, 10.7998, 10.8014, 10.8016,
         10.8006, 10.8022]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[10.5263, 10.5253, 10.5249, 10.5250, 10.5264, 10.5258, 10.5257, 10.5258,
         10.5252, 10.5255],
        [-0.2362, -0.1862, -0.1649, -0.1435, -0.0533, -0.0132,  0.0146,  0.0404,
          0.0298,  0.0379],
        [-0.7694, -0.6552, -0.5593, -0.4780, -0.3938, -0.3178, -0.2511, -0.1923,
         -0.1475, -0.1099],
        [ 1.5716,  1.3869,  1.1646,  0.9872,  1.0232,  0.9222,  0.8098,  0.7145,
          0.5442,  0.4565],
        [    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
             nan,     nan],
        [    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
             nan,     nan],
        [-0.7601, -0.7490, -1.0243, -1.2289, -0.3267, -0.3005,  0.8522,  0.9582,
          0.6534,  1.1800],
        [ 0.1814,  0.4287,  0.5459,  0.6630,  0.7932,  0.9104,  0.9364,  0.9364,
          0.8843,  0.7541]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.5253, 10.5249, 10.5250, 10.5264, 10.5258, 10.5257, 10.5258, 10.5252,
         10.5255, 10.5256]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[10.5231, 10.5219, 10.5206, 10.5218, 10.5211, 10.5213, 10.5181, 10.5208,
         10.5221, 10.5215],
        [-0.8667, -0.7883, -0.7783, -0.7057, -0.6745, -0.6345, -0.7521, -0.7039,
         -0.5932, -0.5284],
        [-1.2576, -1.1741, -1.1051, -1.0345, -0.9714, -0.9123, -0.8902, -0.8622,
         -0.8162, -0.7656],
        [ 1.0139,  1.0141,  0.8371,  0.8577,  0.7669,  0.7170,  0.2692,  0.3401,
          0.5586,  0.6146],
        [    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
             nan,     nan],
        [    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
             nan,     nan],
        [-1.4811, -1.3999, -2.0898, -1.4202, -1.6361, -0.9871,  0.2926,  0.5550,
          1.0132,  0.7186],
        [-1.0814, -0.7819, -0.4825, -0.2352,  0.0252,  0.1944,  0.3506,  0.3246,
          0.3246,  0.3766]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.5219, 10.5206, 10.5218, 10.5211, 10.5213, 10.5181, 10.5208, 10.5221,
         10.5215, 10.5204]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[10.7995, 10.8006, 10.7999, 10.7997, 10.8004, 10.7997, 10.8003, 10.8004,
         10.8015, 10.8008],
        [-0.1536, -0.1070, -0.1197, -0.1382, -0.1059, -0.1272, -0.0981, -0.0695,
          0.0231,  0.0516],
        [-0.1790, -0.1660, -0.1583, -0.1561, -0.1474, -0.1451, -0.1370, -0.1244,
         -0.0946, -0.0647],
        [ 0.0464,  0.1577,  0.0935,  0.0268,  0.1052,  0.0290,  0.0983,  0.1528,
          0.3619,  0.3633],
        [    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
             nan,     nan],
        [    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
             nan,     nan],
        [ 0.1493, -0.4137, -0.4364, -0.2017, -0.2298,  0.1605, -0.0451,  0.2233,
         -0.1655,  0.2479],
        [-0.0790, -0.1180, -0.0790, -0.0660, -0.0790, -0.0530, -0.0399, -0.0139,
          0.0121,  0.0772]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.8006, 10.7999, 10.7997, 10.8004, 10.7997, 10.8003, 10.8004, 10.8015,
         10.8008, 10.8014]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[10.5247, 10.5259, 10.5253, 10.5253, 10.5251, 10.5245, 10.5247, 10.5249,
         10.5241, 10.5236],
        [-0.9755, -0.9052, -0.8700, -0.8331, -0.8067, -0.8029, -0.7836, -0.7498,
         -0.7539, -0.7731],
        [-1.1351, -1.1010, -1.0662, -1.0305, -0.9964, -0.9682, -0.9416, -0.9130,
         -0.8911, -0.8777],
        [ 0.2900,  0.4141,  0.4223,  0.4335,  0.4150,  0.3420,  0.3235,  0.3463,
          0.2663,  0.1634],
        [    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
             nan,     nan],
        [    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
             nan,     nan],
        [ 0.3624,  0.6113,  1.0236,  1.2087,  1.3568,  1.2296,  0.2031, -0.6257,
         -1.3017, -0.2021],
        [ 0.2074,  0.1163,  0.0902,  0.0121, -0.1311, -0.2612, -0.4044, -0.5346,
         -0.5737, -0.6257]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.5259, 10.5253, 10.5253, 10.5251, 10.5245, 10.5247, 10.5249, 10.5241,
         10.5236, 10.5232]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[11.0200, 11.0198, 11.0198, 11.0202, 11.0200, 11.0192, 11.0198, 11.0197,
         11.0190, 11.0196],
        [-0.6071, -0.6142, -0.6174, -0.5808, -0.5611, -0.5992, -0.5726, -0.5601,
         -0.5996, -0.5701],
        [-0.6219, -0.6285, -0.6343, -0.6313, -0.6246, -0.6274, -0.6239, -0.6185,
         -0.6226, -0.6196],
        [-0.0760, -0.0792, -0.0715,  0.0375,  0.0808, -0.0338,  0.0418,  0.0658,
         -0.0496,  0.0365],
        [    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
             nan,     nan],
        [    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
             nan,     nan],
        [ 0.2906,  0.5715,  0.7105,  0.3395,  0.2097,  0.0651, -0.5259, -0.3370,
         -0.2919, -0.4931],
        [-0.1311, -0.1831, -0.2222, -0.2873, -0.3133, -0.3263, -0.3654, -0.3784,
         -0.3524, -0.3654]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[11.0198, 11.0198, 11.0202, 11.0200, 11.0192, 11.0198, 11.0197, 11.0190,
         11.0196, 11.0191]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[10.7234, 10.7230, 10.7267, 10.7238, 10.7221, 10.7212, 10.7225, 10.7267,
         10.7268, 10.7250],
        [-3.0784, -2.8052, -2.3370, -2.1201, -2.0265, -1.9838, -1.8501, -1.4741,
         -1.1546, -0.9984],
        [-3.4030, -3.3203, -3.1543, -2.9753, -2.8122, -2.6725, -2.5323, -2.3401,
         -2.1181, -1.9073],
        [ 0.3721,  1.0048,  2.0158,  2.1740,  1.9814,  1.6957,  1.7025,  2.3352,
          2.6953,  2.5605],
        [    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
             nan,     nan],
        [    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
             nan,     nan],
        [-0.5489, -0.6743, -1.6633, -1.1702, -3.2687, -3.8160, -3.2609, -1.7994,
         -2.3697, -1.1143],
        [-2.9429, -2.5654, -2.2530, -1.7583, -1.3027, -1.0163, -0.7169, -0.3393,
          0.1293,  0.5849]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.7230, 10.7267, 10.7238, 10.7221, 10.7212, 10.7225, 10.7267, 10.7268,
         10.7250, 10.7264]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[10.5789, 10.5789, 10.5783, 10.5775, 10.5774, 10.5783, 10.5783, 10.5777,
         10.5766, 10.5779],
        [-2.1314, -2.2463, -2.3415, -2.4323, -2.4806, -2.4422, -2.3859, -2.3473,
         -2.3463, -2.2516],
        [-2.2004, -2.2391, -2.2903, -2.3506, -2.4092, -2.4479, -2.4668, -2.4737,
         -2.4790, -2.4631],
        [-0.2155, -0.4697, -0.6222, -0.7328, -0.7113, -0.4696, -0.2300, -0.0841,
         -0.0645,  0.1935],
        [    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
             nan,     nan],
        [    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
             nan,     nan],
        [ 0.5069,  1.2729,  1.0344,  1.5750,  2.5122,  1.8440,  0.4773,  0.4286,
         -0.5769, -0.5998],
        [-0.1571, -0.5086, -0.7819, -1.1334, -1.4979, -1.7843, -2.0316, -2.1618,
         -2.2269, -2.3311]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.5789, 10.5783, 10.5775, 10.5774, 10.5783, 10.5783, 10.5777, 10.5766,
         10.5779, 10.5748]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[10.4673, 10.4670, 10.4639, 10.4607, 10.4568, 10.4591, 10.4643, 10.4656,
         10.4679, 10.4700],
        [ 1.1834,  1.4714,  1.5390,  1.4268,  1.1430,  1.0146,  1.1417,  1.2892,
          1.4934,  1.7370],
        [ 0.4346,  0.6613,  0.8570,  0.9897,  1.0354,  1.0445,  1.0790,  1.1379,
          1.2286,  1.3531],
        [ 2.5094,  2.7529,  2.3774,  1.6114,  0.5546,  0.1113,  0.4180,  0.7163,
          1.1015,  1.5117],
        [    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
             nan,     nan],
        [    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
             nan,     nan],
        [ 1.0601, -1.5978, -1.8892, -3.8791, -2.3158, -3.8100, -1.2585, -0.9213,
          2.7209,  3.9315],
        [ 0.2595,  0.8192,  1.3920,  1.8607,  2.0038,  1.9388,  2.0038,  2.3163,
          2.5896,  2.7849]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.4670, 10.4639, 10.4607, 10.4568, 10.4591, 10.4643, 10.4656, 10.4679,
         10.4700, 10.4744]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0873e+01,  1.0873e+01,  1.0873e+01,  1.0873e+01,  1.0873e+01,
          1.0872e+01,  1.0871e+01,  1.0872e+01,  1.0871e+01,  1.0871e+01],
        [ 8.5595e-02,  2.3724e-02, -1.1184e-02, -2.2229e-02, -6.5528e-02,
         -1.6403e-01, -3.1322e-01, -3.4227e-01, -4.2237e-01, -4.7822e-01],
        [ 3.1487e-01,  2.5696e-01,  2.0318e-01,  1.5781e-01,  1.1228e-01,
          5.4863e-02, -2.2867e-02, -9.1241e-02, -1.6301e-01, -2.3233e-01],
        [-6.7905e-01, -7.0338e-01, -6.5306e-01, -5.5103e-01, -5.5290e-01,
         -6.9728e-01, -9.4398e-01, -8.3036e-01, -8.7161e-01, -8.4184e-01],
        [        nan,         nan,         nan,         nan,         nan,
                 nan,         nan,         nan,         nan,         nan],
        [        nan,         nan,         nan,         nan,         nan,
                 nan,         nan,         nan,         nan,         nan],
        [ 3.0648e-01,  3.4327e-01,  8.4911e-01,  5.3097e-01,  2.9157e-01,
          7.1558e-02, -9.0267e-03,  1.0498e-01, -5.2665e-01, -4.4318e-01],
        [-9.2007e-02, -1.5710e-01, -2.2218e-01, -2.7426e-01, -3.1331e-01,
         -3.6538e-01, -4.3047e-01, -5.4763e-01, -5.6065e-01, -6.1272e-01]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.8730, 10.8732, 10.8734, 10.8729, 10.8719, 10.8709, 10.8721, 10.8712,
         10.8712, 10.8716]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[10.5640, 10.5634, 10.5644, 10.5627, 10.5624, 10.5630, 10.5628, 10.5633,
         10.5634, 10.5641],
        [-0.0381, -0.0791, -0.0608, -0.1320, -0.2036, -0.2260, -0.2500, -0.2391,
         -0.2247, -0.1771],
        [-0.2460, -0.2137, -0.1839, -0.1753, -0.1836, -0.1951, -0.2093, -0.2184,
         -0.2226, -0.2158],
        [ 0.6235,  0.3926,  0.3615,  0.1049, -0.1013, -0.1391, -0.1733, -0.1105,
         -0.0512,  0.0825],
        [    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
             nan,     nan],
        [    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
             nan,     nan],
        [ 0.1704,  1.1604,  1.8492,  0.8016,  1.0583,  0.8727,  0.6474,  0.5400,
          0.3590,  0.2201],
        [ 1.1447,  1.0536,  0.8843,  0.7151,  0.4547,  0.2334,  0.0252, -0.1961,
         -0.3003, -0.3784]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.5634, 10.5644, 10.5627, 10.5624, 10.5630, 10.5628, 10.5633, 10.5634,
         10.5641, 10.5641]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[10.7737, 10.7768, 10.7815, 10.7849, 10.7839, 10.7807, 10.7818, 10.7831,
         10.7824, 10.7794],
        [ 0.1070,  0.3467,  0.8304,  1.4165,  1.7957,  1.8654,  1.9738,  2.1169,
          2.1630,  1.9787],
        [ 0.4701,  0.4499,  0.5369,  0.7314,  0.9679,  1.1719,  1.3582,  1.5377,
          1.6912,  1.7747],
        [-1.0811, -0.2444,  1.0565,  2.3623,  2.8712,  2.4774,  2.2626,  2.1803,
          1.8638,  1.0139],
        [    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
             nan,     nan],
        [    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
             nan,     nan],
        [ 1.0337,  0.5596, -0.0855,  0.8290, -1.1406, -1.6521, -1.4047, -1.8214,
         -2.5135, -5.1936],
        [-0.3263, -0.3784, -0.2612,  0.0902,  0.5719,  0.9364,  1.1837,  1.4831,
          1.7305,  1.9778]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.7768, 10.7815, 10.7849, 10.7839, 10.7807, 10.7818, 10.7831, 10.7824,
         10.7794, 10.7827]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[10.5023, 10.5029, 10.5047, 10.5042, 10.5038, 10.5023, 10.5017, 10.5003,
         10.4988, 10.4993],
        [ 0.5810,  0.4681,  0.4589,  0.4249,  0.3737,  0.2582,  0.1336, -0.0336,
         -0.2353, -0.3656],
        [ 0.4690,  0.4749,  0.4778,  0.4728,  0.4579,  0.4213,  0.3655,  0.2853,
          0.1781,  0.0645],
        [ 0.4560,  0.0725,  0.0343, -0.0607, -0.1811, -0.4437, -0.6775, -0.9749,
         -1.3020, -1.3787],
        [    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
             nan,     nan],
        [    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
             nan,     nan],
        [-0.3309, -0.7364, -1.0392, -0.4229,  0.0867,  0.5495,  1.2947,  1.7893,
          1.9084,  1.7645],
        [ 1.0536,  0.8973,  0.7932,  0.7802,  0.7411,  0.6630,  0.4938,  0.3115,
          0.0121, -0.3524]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.5029, 10.5047, 10.5042, 10.5038, 10.5023, 10.5017, 10.5003, 10.4988,
         10.4993, 10.4995]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[10.7664, 10.7661, 10.7652, 10.7642, 10.7635, 10.7655, 10.7641, 10.7640,
         10.7646, 10.7644],
        [ 0.3325,  0.2447,  0.1212, -0.0427, -0.2144, -0.2166, -0.3042, -0.3778,
         -0.3955, -0.4170],
        [ 0.6878,  0.6024,  0.5077,  0.3971,  0.2720,  0.1714,  0.0723, -0.0227,
         -0.1024, -0.1708],
        [-1.0122, -1.0373, -1.1493, -1.3436, -1.5193, -1.2212, -1.2036, -1.1535,
         -0.9685, -0.8306],
        [    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
             nan,     nan],
        [    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
             nan,     nan],
        [ 0.5720,  0.3965,  0.0798,  0.5541, -0.2782,  0.2762, -0.1350, -0.5785,
         -0.1787,  0.3247],
        [-0.1311, -0.2873, -0.4305, -0.5476, -0.6908, -0.8340, -0.8210, -0.8601,
         -0.8861, -0.8340]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.7661, 10.7652, 10.7642, 10.7635, 10.7655, 10.7641, 10.7640, 10.7646,
         10.7644, 10.7649]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[10.5512, 10.5520, 10.5515, 10.5520, 10.5521, 10.5525, 10.5549, 10.5521,
         10.5505, 10.5515],
        [-2.0967, -2.1068, -2.1164, -2.0735, -2.0115, -1.9196, -1.7063, -1.6609,
         -1.6858, -1.6361],
        [-2.2194, -2.2245, -2.2307, -2.2265, -2.2099, -2.1770, -2.1053, -2.0382,
         -1.9899, -1.9406],
        [-0.0454, -0.0624, -0.0748,  0.0513,  0.2015,  0.3989,  0.8712,  0.8145,
          0.5873,  0.5985],
        [    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
             nan,     nan],
        [    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
             nan,     nan],
        [-0.1615, -0.8673, -0.7734, -0.6060, -0.5128, -0.8061,  0.0604,  0.2476,
         -0.0499, -0.3849],
        [-1.4068, -1.5760, -1.5890, -1.6021, -1.5890, -1.5109, -1.3808, -1.1074,
         -1.0293, -1.0293]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.5520, 10.5515, 10.5520, 10.5521, 10.5525, 10.5549, 10.5521, 10.5505,
         10.5515, 10.5524]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0450e+01,  1.0450e+01,  1.0450e+01,  1.0451e+01,  1.0451e+01,
          1.0449e+01,  1.0449e+01,  1.0448e+01,  1.0448e+01,  1.0449e+01],
        [-9.4383e-01, -9.5841e-01, -9.4624e-01, -8.8112e-01, -8.3119e-01,
         -8.5448e-01, -8.7934e-01, -9.2820e-01, -9.5423e-01, -9.2300e-01],
        [-9.4232e-01, -9.5812e-01, -9.6817e-01, -9.6233e-01, -9.4702e-01,
         -9.3973e-01, -9.3920e-01, -9.4918e-01, -9.6272e-01, -9.6690e-01],
        [-1.9269e-01, -1.9189e-01, -1.2201e-01,  7.0951e-02,  1.8598e-01,
          8.8498e-02,  6.4652e-03, -1.2129e-01, -1.6442e-01, -5.0682e-02],
        [        nan,         nan,         nan,         nan,         nan,
                 nan,         nan,         nan,         nan,         nan],
        [        nan,         nan,         nan,         nan,         nan,
                 nan,         nan,         nan,         nan,         nan],
        [-1.1211e+00, -1.2073e+00, -3.7595e-01, -9.3337e-01, -1.1784e+00,
         -4.3557e-01, -2.7226e-01,  3.2857e-02, -1.7080e-01,  3.4267e-01],
        [-1.5890e+00, -1.3808e+00, -1.2636e+00, -1.1204e+00, -8.8609e-01,
         -6.7781e-01, -5.4763e-01, -5.3461e-01, -5.3461e-01, -5.3461e-01]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.4496, 10.4499, 10.4508, 10.4506, 10.4490, 10.4486, 10.4478, 10.4478,
         10.4487, 10.4500]])
  0%|          | 0/350 [00:02<?, ?it/s]
Traceback (most recent call last):
  File "C:\Users\dadou\Documents\Github\Advanced-Programming\Strategies\Transformer_strategy.py", line 420, in <module>
    trainer.train()
  File "C:\Users\dadou\Documents\Github\Advanced-Programming\utils\trainer.py", line 76, in train
    print("targets", target[0, :, :].cpu())
  File "C:\Users\dadou\anaconda3\envs\Advanced-Programming\Lib\site-packages\torch\_tensor.py", line 461, in __repr__
    return torch._tensor_str._str(self, tensor_contents=tensor_contents)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\dadou\anaconda3\envs\Advanced-Programming\Lib\site-packages\torch\_tensor_str.py", line 677, in _str
    return _str_intern(self, tensor_contents=tensor_contents)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\dadou\anaconda3\envs\Advanced-Programming\Lib\site-packages\torch\_tensor_str.py", line 597, in _str_intern
    tensor_str = _tensor_str(self, indent)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\dadou\anaconda3\envs\Advanced-Programming\Lib\site-packages\torch\_tensor_str.py", line 349, in _tensor_str
    formatter = _Formatter(get_summarized_data(self) if summarize else self)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\dadou\anaconda3\envs\Advanced-Programming\Lib\site-packages\torch\_tensor_str.py", line 151, in __init__
    if value != torch.ceil(value):
                ^^^^^^^^^^^^^^^^^
KeyboardInterrupt
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[10.6652, 10.6650, 10.6675, 10.6659, 10.6683, 10.6693, 10.6703, 10.6713,
         10.6719, 10.6720],
        [ 0.6089,  0.7652,  1.0210,  1.1170,  1.3148,  1.5159,  1.7125,  1.9047,
          2.0637,  2.1729],
        [-0.2606, -0.0454,  0.1813,  0.3831,  0.5867,  0.7924,  0.9989,  1.2051,
          1.4039,  1.5862],
        [ 2.7613,  2.6136,  2.7528,  2.4509,  2.4726,  2.4986,  2.5077,  2.5036,
          2.4145,  2.2144],
        [    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
             nan,     nan],
        [    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
             nan,     nan],
        [-1.9826,  0.6923, -0.6381, -1.3013, -1.2321,  0.1466, -0.7795,  0.9395,
          1.0048,  1.4957],
        [ 1.0666,  1.4701,  1.7695,  2.0169,  2.2382,  2.4855,  2.6027,  2.7068,
          2.8630,  2.9151]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.6650, 10.6675, 10.6659, 10.6683, 10.6693, 10.6703, 10.6713, 10.6719,
         10.6720, 10.6734]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0982e+01,  1.0982e+01,  1.0981e+01,  1.0983e+01,  1.0983e+01,
          1.0983e+01,  1.0983e+01,  1.0982e+01,  1.0981e+01,  1.0980e+01],
        [ 9.3183e-01,  1.0260e+00,  1.0222e+00,  1.1050e+00,  1.1948e+00,
          1.2578e+00,  1.3021e+00,  1.2060e+00,  1.0222e+00,  8.0918e-01],
        [ 3.8200e-01,  5.2427e-01,  6.3729e-01,  7.4535e-01,  8.5092e-01,
          9.4881e-01,  1.0366e+00,  1.0863e+00,  1.0869e+00,  1.0420e+00],
        [ 1.8551e+00,  1.7278e+00,  1.3725e+00,  1.3123e+00,  1.2822e+00,
          1.1888e+00,  1.0658e+00,  6.0394e-01,  7.2028e-03, -5.4550e-01],
        [        nan,         nan,         nan,         nan,         nan,
                 nan,         nan,         nan,         nan,         nan],
        [        nan,         nan,         nan,         nan,         nan,
                 nan,         nan,         nan,         nan,         nan],
        [-2.8167e+00, -1.0705e+00,  4.4669e-01,  4.0852e-01, -9.9639e-02,
          2.4064e-01,  5.5118e-02,  9.4288e-01,  1.6219e+00,  1.3701e+00],
        [ 8.1923e-01,  9.3639e-01,  1.1317e+00,  1.1577e+00,  1.2098e+00,
          1.3009e+00,  1.3269e+00,  1.2879e+00,  1.1577e+00,  9.4941e-01]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.9822, 10.9813, 10.9826, 10.9831, 10.9831, 10.9833, 10.9818, 10.9805,
         10.9798, 10.9790]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0913e+01,  1.0913e+01,  1.0913e+01,  1.0913e+01,  1.0913e+01,
          1.0912e+01,  1.0913e+01,  1.0913e+01,  1.0913e+01,  1.0912e+01],
        [ 9.1595e-01,  8.8531e-01,  8.5124e-01,  7.9276e-01,  7.1418e-01,
          6.2613e-01,  5.7226e-01,  5.4609e-01,  5.2097e-01,  4.3913e-01],
        [ 9.6130e-01,  9.5773e-01,  9.4760e-01,  9.2704e-01,  8.9385e-01,
          8.4852e-01,  8.0078e-01,  7.5702e-01,  7.1665e-01,  6.6691e-01],
        [ 4.4879e-02, -4.3397e-02, -1.2290e-01, -2.4969e-01, -4.0315e-01,
         -5.5042e-01, -5.7977e-01, -5.3155e-01, -4.9026e-01, -6.0403e-01],
        [        nan,         nan,         nan,         nan,         nan,
                 nan,         nan,         nan,         nan,         nan],
        [        nan,         nan,         nan,         nan,         nan,
                 nan,         nan,         nan,         nan,         nan],
        [ 3.6827e-01,  1.8136e-01,  7.3063e-01,  1.6491e-01,  4.8398e-01,
          1.0945e+00,  1.3475e+00,  7.9293e-01, -2.4274e-01,  7.4459e-02],
        [ 7.6716e-01,  6.8906e-01,  6.1095e-01,  5.4586e-01,  4.4172e-01,
          3.5060e-01,  2.3344e-01,  1.2929e-01,  5.1188e-02, -8.8277e-04]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.9132, 10.9132, 10.9129, 10.9125, 10.9123, 10.9126, 10.9129, 10.9129,
         10.9121, 10.9123]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[10.6719, 10.6719, 10.6717, 10.6715, 10.6711, 10.6705, 10.6704, 10.6707,
         10.6713, 10.6702],
        [ 0.3268,  0.3909,  0.4254,  0.4369,  0.4190,  0.3622,  0.3098,  0.2798,
          0.2912,  0.2327],
        [ 0.2026,  0.2454,  0.2870,  0.3227,  0.3475,  0.3552,  0.3502,  0.3398,
          0.3339,  0.3167],
        [ 0.4423,  0.5197,  0.5049,  0.4337,  0.3007,  0.0935, -0.0607, -0.1262,
         -0.0717, -0.2087],
        [    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
             nan,     nan],
        [    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
             nan,     nan],
        [-0.3063, -0.7297, -0.1828,  0.6232,  0.0542,  0.4465, -0.1346, -0.1850,
         -0.2605,  0.1517],
        [ 0.2855,  0.3506,  0.4027,  0.4417,  0.4678,  0.4287,  0.4157,  0.3376,
          0.2855,  0.2725]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.6719, 10.6717, 10.6715, 10.6711, 10.6705, 10.6704, 10.6707, 10.6713,
         10.6702, 10.6683]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[10.9760, 10.9761, 10.9762, 10.9759, 10.9757, 10.9752, 10.9749, 10.9749,
         10.9744, 10.9742],
        [ 0.4935,  0.5555,  0.6023,  0.6074,  0.5909,  0.5310,  0.4576,  0.3924,
          0.3046,  0.2114],
        [ 0.2824,  0.3443,  0.4038,  0.4525,  0.4880,  0.5036,  0.5004,  0.4839,
          0.4521,  0.4067],
        [ 0.7392,  0.7517,  0.7226,  0.5914,  0.4303,  0.1893, -0.0388, -0.1998,
         -0.3871, -0.5508],
        [    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
             nan,     nan],
        [    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
             nan,     nan],
        [ 0.2521,  0.4527,  0.0748, -0.3472, -0.1906,  0.1165,  0.6320,  0.4792,
          0.2213,  0.3943],
        [ 0.5068,  0.5719,  0.5979,  0.6110,  0.5979,  0.5719,  0.4938,  0.4157,
          0.3246,  0.2334]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.9761, 10.9762, 10.9759, 10.9757, 10.9752, 10.9749, 10.9749, 10.9744,
         10.9742, 10.9736]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0756e+01,  1.0756e+01,  1.0757e+01,  1.0757e+01,  1.0758e+01,
          1.0757e+01,  1.0756e+01,  1.0757e+01,  1.0757e+01,  1.0756e+01],
        [-1.1623e-01, -1.1373e-01, -5.2034e-02, -4.0010e-03,  5.9673e-02,
          3.8544e-02,  4.6670e-03, -1.5567e-02, -1.3812e-02, -6.4191e-02],
        [-6.9857e-02, -8.0126e-02, -7.5191e-02, -6.1006e-02, -3.6087e-02,
         -2.0654e-02, -1.5528e-02, -1.5741e-02, -1.5537e-02, -2.6110e-02],
        [-1.6397e-01, -1.2470e-01,  5.9935e-02,  1.7227e-01,  3.0263e-01,
          1.8742e-01,  6.2244e-02, -2.5730e-03,  2.4833e-03, -1.2841e-01],
        [        nan,         nan,         nan,         nan,         nan,
                 nan,         nan,         nan,         nan,         nan],
        [        nan,         nan,         nan,         nan,         nan,
                 nan,         nan,         nan,         nan,         nan],
        [ 3.7009e-01, -1.7110e-01,  6.6343e-02, -3.6240e-01,  3.0586e-01,
         -4.6511e-01, -3.6639e-01, -1.0475e-01, -3.9848e-01, -2.7446e-01],
        [-1.3106e-01, -1.8313e-01, -1.9615e-01, -1.3106e-01, -9.2007e-02,
         -2.6918e-02, -2.6918e-02, -1.3901e-02,  1.2135e-02,  1.2135e-02]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.7565, 10.7574, 10.7574, 10.7578, 10.7567, 10.7564, 10.7565, 10.7568,
         10.7560, 10.7561]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[10.3953, 10.3948, 10.3974, 10.3965, 10.3980, 10.3988, 10.3980, 10.3991,
         10.4007, 10.4022],
        [ 0.4679,  0.4410,  0.5275,  0.5505,  0.6288,  0.7146,  0.7413,  0.7988,
          0.9056,  1.0459],
        [ 0.3012,  0.3350,  0.3804,  0.4217,  0.4713,  0.5294,  0.5815,  0.6354,
          0.7014,  0.7840],
        [ 0.5993,  0.4098,  0.5517,  0.5009,  0.6033,  0.7048,  0.6329,  0.6553,
          0.8006,  1.0036],
        [    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
             nan,     nan],
        [    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
             nan,     nan],
        [-1.5952, -0.5313, -0.6652, -0.2556, -0.0244, -0.2331,  0.3965,  0.7384,
          0.9487,  0.1122],
        [ 0.4157,  0.5719,  0.6500,  0.7802,  0.9104,  1.0926,  1.1837,  1.2358,
          1.2618,  1.3139]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.3948, 10.3974, 10.3965, 10.3980, 10.3988, 10.3980, 10.3991, 10.4007,
         10.4022, 10.4014]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[11.0341, 11.0346, 11.0337, 11.0336, 11.0324, 11.0321, 11.0315, 11.0312,
         11.0312, 11.0321],
        [ 0.4601,  0.6178,  0.6638,  0.6796,  0.5884,  0.4840,  0.3523,  0.2239,
          0.1162,  0.1023],
        [ 0.4266,  0.4729,  0.5198,  0.5607,  0.5740,  0.5623,  0.5249,  0.4677,
          0.3989,  0.3409],
        [ 0.1934,  0.5630,  0.5696,  0.4964,  0.1611, -0.1413, -0.4541, -0.6955,
         -0.8352, -0.7040],
        [    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
             nan,     nan],
        [    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
             nan,     nan],
        [-0.5967, -0.6515, -0.0499,  0.1466,  0.1922, -0.2332, -0.4131, -0.6563,
         -0.3914,  0.1901],
        [-0.1050,  0.0512,  0.1944,  0.3115,  0.3766,  0.3636,  0.3246,  0.2595,
          0.1683,  0.0902]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets
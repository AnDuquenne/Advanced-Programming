  0%|          | 0/350 [00:00<?, ?it/s]C:\Users\dadou\anaconda3\envs\Advanced-Programming\Lib\site-packages\torch\nn\functional.py:5476: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\aten\src\ATen\native\transformers\cuda\sdp_utils.cpp:263.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0830e+01,  1.0830e+01,  1.0830e+01,  1.0830e+01,  1.0831e+01,
          1.0831e+01,  1.0831e+01,  1.0831e+01,  1.0830e+01,  1.0830e+01],
        [-9.4160e-01, -4.2837e+00, -4.7585e+00, -4.6503e+00, -2.3666e+00,
         -3.4870e-01,  1.2363e+00,  2.4641e+00,  8.7710e-01, -1.2705e+00],
        [-2.8710e-01, -1.0864e+00, -1.8208e+00, -2.3867e+00, -2.3827e+00,
         -1.9759e+00, -1.3334e+00, -5.7390e-01, -2.8370e-01, -4.8110e-01],
        [-6.5460e-01, -3.1973e+00, -2.9377e+00, -2.2636e+00,  1.6000e-02,
          1.6272e+00,  2.5698e+00,  3.0380e+00,  1.1608e+00, -7.8940e-01],
        [ 4.2030e+01,  3.9840e+01,  3.7974e+01,  4.5302e+01,  5.5508e+01,
          5.4963e+01,  5.3906e+01,  5.4027e+01,  5.3204e+01,  4.6136e+01],
        [ 2.9120e-01,  2.1050e-01,  1.4170e-01,  4.1170e-01,  7.8780e-01,
          7.6780e-01,  9.0800e-01,  9.1350e-01,  8.9230e-01,  5.6160e-01],
        [-2.8839e+01, -2.4561e+01, -1.7633e+01, -1.7182e+01, -4.2070e+01,
         -8.4390e+00, -3.3075e+01, -3.1474e+01, -8.0362e+00,  4.4600e+01],
        [-1.5000e-03, -1.7000e-03, -1.9000e-03, -1.9000e-03, -1.7000e-03,
         -1.2000e-03, -6.0000e-04, -2.0000e-04,  2.0000e-04,  4.0000e-04]])
preds tensor([[-0.0175, -0.0171, -0.0272, -0.0271, -0.0136, -0.0202, -0.0130, -0.0161,
         -0.0238, -0.0284]], grad_fn=<ToCopyBackward0>)
targets tensor([[10.8297, 10.8302, 10.8304, 10.8309, 10.8309, 10.8309, 10.8309, 10.8303,
         10.8301, 10.8303]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0453e+01,  1.0453e+01,  1.0452e+01,  1.0452e+01,  1.0451e+01,
          1.0450e+01,  1.0451e+01,  1.0451e+01,  1.0453e+01,  1.0452e+01],
        [-5.8318e+00, -2.8521e+01, -4.9105e+01, -6.4885e+01, -7.9743e+01,
         -9.2060e+01, -9.7061e+01, -9.9186e+01, -9.4998e+01, -9.4487e+01],
        [ 5.0257e+01,  3.4501e+01,  1.7780e+01,  1.2470e+00, -1.4951e+01,
         -3.0373e+01, -4.3711e+01, -5.4806e+01, -6.2844e+01, -6.9173e+01],
        [-5.6089e+01, -6.3022e+01, -6.6885e+01, -6.6132e+01, -6.4792e+01,
         -6.1687e+01, -5.3351e+01, -4.4380e+01, -3.2154e+01, -2.5315e+01],
        [ 2.5508e+01,  2.1727e+01,  2.3061e+01,  2.0012e+01,  1.6235e+01,
          1.2029e+01,  1.2537e+01,  1.6195e+01,  2.3676e+01,  2.2993e+01],
        [-1.9490e-01, -6.0500e-02,  2.3800e-02, -3.0600e-02, -6.7400e-02,
         -7.0300e-02,  8.5000e-03,  8.3000e-02,  2.5460e-01,  3.0200e-01],
        [ 8.8050e+01,  1.3874e+02,  1.9290e+02,  7.0047e+01,  6.3067e+01,
          6.1019e+01, -4.0790e+01, -6.7410e+00,  5.3790e+01,  6.2525e+01],
        [-5.3000e-03, -1.0200e-02, -1.4700e-02, -1.8500e-02, -2.1900e-02,
         -2.4500e-02, -2.6700e-02, -2.8100e-02, -2.7600e-02, -2.6200e-02]])
preds tensor([[ 3.2602e-04, -4.2151e-04, -5.8479e-05, -7.5558e-04, -9.7466e-05,
         -2.9964e-04,  3.2036e-04, -1.0776e-03,  2.5445e-04, -2.8033e-04]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.4529, 10.4518, 10.4517, 10.4505, 10.4499, 10.4512, 10.4515, 10.4532,
         10.4518, 10.4500]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0545e+01,  1.0546e+01,  1.0544e+01,  1.0543e+01,  1.0542e+01,
          1.0542e+01,  1.0540e+01,  1.0538e+01,  1.0538e+01,  1.0540e+01],
        [-1.3655e+02, -1.3361e+02, -1.3680e+02, -1.3958e+02, -1.4494e+02,
         -1.4693e+02, -1.5293e+02, -1.6141e+02, -1.6457e+02, -1.6075e+02],
        [-9.9604e+01, -1.0641e+02, -1.1248e+02, -1.1790e+02, -1.2331e+02,
         -1.2803e+02, -1.3301e+02, -1.3869e+02, -1.4387e+02, -1.4724e+02],
        [-3.6949e+01, -2.7206e+01, -2.4316e+01, -2.1679e+01, -2.1631e+01,
         -1.8891e+01, -1.9920e+01, -2.2715e+01, -2.0704e+01, -1.3501e+01],
        [ 3.3092e+01,  3.7459e+01,  3.0746e+01,  3.6109e+01,  2.9691e+01,
          2.3889e+01,  1.6561e+01,  1.5443e+01,  1.9177e+01,  2.7311e+01],
        [ 1.9300e-01,  3.4760e-01,  1.1000e-01,  3.2730e-01,  7.9400e-02,
         -1.4470e-01, -2.4730e-01, -3.4600e-02,  1.3340e-01,  5.3910e-01],
        [-3.0420e+01,  7.6102e+01,  1.6324e+02,  1.9104e+02,  1.0398e+02,
          4.0395e+00, -1.7665e+02, -2.2104e+02, -1.3948e+02, -1.2675e+02],
        [-1.9200e-02, -1.9500e-02, -1.9300e-02, -2.0600e-02, -2.1000e-02,
         -2.1900e-02, -2.2300e-02, -2.3100e-02, -2.3400e-02, -2.2700e-02]])
preds tensor([[0.0015, 0.0016, 0.0014, 0.0015, 0.0013, 0.0015, 0.0014, 0.0020, 0.0016,
         0.0014]], grad_fn=<ToCopyBackward0>)
targets tensor([[10.5460, 10.5437, 10.5431, 10.5415, 10.5417, 10.5397, 10.5378, 10.5384,
         10.5399, 10.5384]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0920e+01,  1.0920e+01,  1.0921e+01,  1.0921e+01,  1.0920e+01,
          1.0921e+01,  1.0921e+01,  1.0919e+01,  1.0918e+01,  1.0919e+01],
        [ 2.4098e+01,  2.4321e+01,  2.6116e+01,  2.9286e+01,  2.8891e+01,
          3.1169e+01,  3.1462e+01,  2.2544e+01,  1.2146e+01,  5.7123e+00],
        [ 2.5236e+01,  2.5053e+01,  2.5266e+01,  2.6070e+01,  2.6634e+01,
          2.7541e+01,  2.8325e+01,  2.7169e+01,  2.4164e+01,  2.0474e+01],
        [-1.1383e+00, -7.3260e-01,  8.4990e-01,  3.2159e+00,  2.2568e+00,
          3.6278e+00,  3.1370e+00, -4.6253e+00, -1.2019e+01, -1.4762e+01],
        [ 6.2693e+01,  5.2208e+01,  5.1679e+01,  5.5507e+01,  4.7387e+01,
          5.6169e+01,  5.9224e+01,  4.7888e+01,  4.1259e+01,  3.9358e+01],
        [ 9.5550e-01,  3.8430e-01,  2.8870e-01,  4.0240e-01, -1.4360e-01,
          5.1640e-01,  6.9600e-01,  2.9400e-02, -3.6030e-01, -8.2200e-02],
        [ 1.0286e+02,  5.5037e+01,  1.0118e+01, -2.1662e+00,  2.3326e+01,
          5.4108e+01,  3.6332e+01, -8.6681e+01, -5.1672e+01,  7.7224e+00],
        [ 3.5000e-03,  3.4000e-03,  2.7000e-03,  2.3000e-03,  2.2000e-03,
          1.8000e-03,  1.7000e-03,  1.7000e-03,  1.0000e-03,  3.0000e-04]])
preds tensor([[0.0029, 0.0025, 0.0027, 0.0034, 0.0025, 0.0028, 0.0030, 0.0030, 0.0030,
         0.0030]], grad_fn=<ToCopyBackward0>)
targets tensor([[10.9201, 10.9205, 10.9210, 10.9204, 10.9211, 10.9208, 10.9188, 10.9181,
         10.9185, 10.9181]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0958e+01,  1.0959e+01,  1.0959e+01,  1.0959e+01,  1.0959e+01,
          1.0959e+01,  1.0960e+01,  1.0959e+01,  1.0959e+01,  1.0960e+01],
        [ 1.7489e+01,  1.9486e+01,  1.9945e+01,  2.2208e+01,  2.1573e+01,
          2.3830e+01,  2.6826e+01,  2.7781e+01,  2.8103e+01,  2.9922e+01],
        [ 1.2169e+01,  1.3632e+01,  1.4895e+01,  1.6358e+01,  1.7401e+01,
          1.8687e+01,  2.0315e+01,  2.1808e+01,  2.3067e+01,  2.4438e+01],
        [ 5.3205e+00,  5.8538e+00,  5.0505e+00,  5.8504e+00,  4.1722e+00,
          5.1438e+00,  6.5119e+00,  5.9730e+00,  5.0359e+00,  5.4841e+00],
        [ 5.7910e+01,  6.1524e+01,  5.9932e+01,  5.8690e+01,  5.5137e+01,
          5.6643e+01,  5.3310e+01,  5.8580e+01,  5.9231e+01,  5.4949e+01],
        [ 3.8850e-01,  4.9130e-01,  3.6130e-01,  3.6300e-02, -1.2900e-01,
          6.2100e-02, -7.5300e-02,  2.5810e-01,  2.9000e-01,  8.0300e-02],
        [ 2.2921e+01,  3.6919e+01,  8.4788e+01,  2.2201e+01,  7.3019e+00,
          6.4896e+01,  9.5320e+01,  2.4219e+01, -3.0184e+01, -2.6795e+01],
        [ 4.9000e-03,  4.2000e-03,  3.9000e-03,  3.5000e-03,  3.0000e-03,
          2.6000e-03,  2.4000e-03,  2.0000e-03,  1.7000e-03,  1.7000e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.9589, 10.9587, 10.9591, 10.9587, 10.9593, 10.9596, 10.9594, 10.9594,
         10.9598, 10.9603]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0971e+01,  1.0972e+01,  1.0972e+01,  1.0971e+01,  1.0972e+01,
          1.0972e+01,  1.0972e+01,  1.0971e+01,  1.0972e+01,  1.0972e+01],
        [ 1.0421e+01,  1.1343e+01,  1.1916e+01,  7.9837e+00,  5.9993e+00,
          4.1035e+00,  2.2323e+00, -1.3045e+00, -1.7001e+00, -2.3194e+00],
        [ 1.8974e+01,  1.7448e+01,  1.6341e+01,  1.4670e+01,  1.2936e+01,
          1.1169e+01,  9.3819e+00,  7.2446e+00,  5.4556e+00,  3.9006e+00],
        [-8.5525e+00, -6.1048e+00, -4.4249e+00, -6.6861e+00, -6.9363e+00,
         -7.0657e+00, -7.1495e+00, -8.5491e+00, -7.1558e+00, -6.2201e+00],
        [ 4.9104e+01,  5.7293e+01,  5.0490e+01,  4.4819e+01,  4.5272e+01,
          3.9582e+01,  4.1190e+01,  3.6975e+01,  4.2713e+01,  4.8811e+01],
        [ 4.8600e-02,  8.1100e-01,  1.7760e-01, -3.5030e-01,  3.1300e-02,
         -3.6100e-01,  8.1500e-02, -1.3200e-01,  2.7110e-01,  5.5920e-01],
        [ 2.3193e+01,  5.9064e+01,  3.7581e+01,  4.1046e+01,  3.3111e+01,
         -2.2512e+01,  4.2713e+01,  1.5339e+01, -7.7110e+00, -2.6994e+01],
        [ 1.2000e-03,  7.0000e-04,  7.0000e-04,  3.0000e-04, -2.0000e-04,
         -6.0000e-04, -1.0000e-03, -1.2000e-03, -1.7000e-03, -1.8000e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.9723, 10.9723, 10.9714, 10.9717, 10.9716, 10.9715, 10.9711, 10.9716,
         10.9715, 10.9717]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0746e+01,  1.0746e+01,  1.0746e+01,  1.0746e+01,  1.0745e+01,
          1.0745e+01,  1.0744e+01,  1.0743e+01,  1.0743e+01,  1.0744e+01],
        [ 5.9254e+01,  5.6651e+01,  5.4394e+01,  5.1270e+01,  4.5078e+01,
          3.9080e+01,  3.1276e+01,  2.1738e+01,  1.5231e+01,  1.0981e+01],
        [ 5.5903e+01,  5.6053e+01,  5.5721e+01,  5.4831e+01,  5.2880e+01,
          5.0120e+01,  4.6352e+01,  4.1429e+01,  3.6189e+01,  3.1147e+01],
        [ 3.3505e+00,  5.9840e-01, -1.3269e+00, -3.5611e+00, -7.8025e+00,
         -1.1040e+01, -1.5076e+01, -1.9691e+01, -2.0958e+01, -2.0167e+01],
        [ 7.3043e+01,  7.4831e+01,  7.2774e+01,  7.4529e+01,  6.3673e+01,
          5.1842e+01,  4.3277e+01,  3.3800e+01,  3.2535e+01,  2.6695e+01],
        [ 7.2750e-01,  7.7120e-01,  7.2090e-01,  7.6380e-01,  4.9850e-01,
          1.1500e-02, -2.6470e-01, -2.3160e-01, -2.5100e-02, -1.1300e-01],
        [-4.7787e+01,  1.7416e+01,  2.5406e+01,  3.7374e+01,  4.9436e+01,
          7.9956e+01,  7.0162e+01,  4.7877e+01,  4.9496e+01,  8.1040e+01],
        [ 6.3000e-03,  6.6000e-03,  6.7000e-03,  6.4000e-03,  6.0000e-03,
          5.1000e-03,  3.9000e-03,  2.3000e-03,  7.0000e-04, -7.0000e-04]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.7458, 10.7459, 10.7457, 10.7449, 10.7447, 10.7440, 10.7431, 10.7435,
         10.7437, 10.7428]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0823e+01,  1.0823e+01,  1.0823e+01,  1.0824e+01,  1.0824e+01,
          1.0824e+01,  1.0824e+01,  1.0824e+01,  1.0824e+01,  1.0823e+01],
        [ 6.1436e+01,  6.3775e+01,  6.5050e+01,  6.5663e+01,  6.8231e+01,
          7.0288e+01,  6.7904e+01,  6.5262e+01,  6.2123e+01,  5.6237e+01],
        [ 4.7802e+01,  5.0996e+01,  5.3807e+01,  5.6178e+01,  5.8589e+01,
          6.0929e+01,  6.2324e+01,  6.2911e+01,  6.2754e+01,  6.1450e+01],
        [ 1.3634e+01,  1.2779e+01,  1.1243e+01,  9.4851e+00,  9.6422e+00,
          9.3590e+00,  5.5802e+00,  2.3510e+00, -6.3090e-01, -5.2131e+00],
        [ 5.8825e+01,  6.4290e+01,  6.0589e+01,  6.3089e+01,  6.5146e+01,
          6.3530e+01,  6.4484e+01,  7.1197e+01,  8.3159e+01,  5.9349e+01],
        [ 6.1980e-01,  8.9090e-01,  7.0730e-01,  8.3130e-01,  9.3330e-01,
          8.5320e-01,  9.6480e-01,  1.3215e+00,  1.4810e+00,  1.0420e-01],
        [ 1.4552e+00,  2.8731e+01, -3.2546e+01, -1.0124e+02, -1.9330e+02,
          1.6120e+01,  5.6385e+01,  5.5445e+01,  6.5627e+01,  2.3396e+01],
        [ 4.5000e-03,  4.8000e-03,  5.2000e-03,  5.3000e-03,  5.7000e-03,
          6.5000e-03,  7.2000e-03,  7.0000e-03,  6.7000e-03,  6.8000e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.8234, 10.8235, 10.8235, 10.8243, 10.8245, 10.8237, 10.8237, 10.8236,
         10.8229, 10.8233]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0489e+01,  1.0488e+01,  1.0488e+01,  1.0490e+01,  1.0490e+01,
          1.0491e+01,  1.0490e+01,  1.0489e+01,  1.0489e+01,  1.0489e+01],
        [ 2.4776e+01,  2.3182e+01,  2.1746e+01,  2.5858e+01,  2.8481e+01,
          3.1823e+01,  3.0872e+01,  2.9488e+01,  2.7365e+01,  2.5742e+01],
        [ 2.0693e+01,  2.1191e+01,  2.1302e+01,  2.2213e+01,  2.3466e+01,
          2.5138e+01,  2.6285e+01,  2.6925e+01,  2.7013e+01,  2.6759e+01],
        [ 4.0838e+00,  1.9916e+00,  4.4460e-01,  3.6449e+00,  5.0147e+00,
          6.6849e+00,  4.5873e+00,  2.5628e+00,  3.5180e-01, -1.0167e+00],
        [ 6.2204e+01,  6.0324e+01,  6.7545e+01,  6.4855e+01,  6.2727e+01,
          6.2984e+01,  5.3804e+01,  5.1730e+01,  5.3246e+01,  5.4627e+01],
        [ 6.8980e-01,  5.9300e-01,  9.6470e-01,  6.8900e-01,  4.9290e-01,
          5.1660e-01, -3.2920e-01, -1.4380e-01,  9.1900e-02,  1.7560e-01],
        [ 2.3491e+01,  3.7937e+01,  4.9582e+01,  5.5881e+01,  3.0769e+01,
          1.8487e+01, -1.2436e+01,  1.7913e+01, -2.2469e+01, -1.1405e+00],
        [ 5.1000e-03,  4.9000e-03,  4.4000e-03,  4.1000e-03,  4.0000e-03,
          3.8000e-03,  3.8000e-03,  3.4000e-03,  3.0000e-03,  2.6000e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.4883, 10.4883, 10.4902, 10.4901, 10.4907, 10.4895, 10.4894, 10.4892,
         10.4893, 10.4896]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0412e+01,  1.0410e+01,  1.0408e+01,  1.0408e+01,  1.0408e+01,
          1.0408e+01,  1.0410e+01,  1.0410e+01,  1.0411e+01,  1.0412e+01],
        [-1.2520e+01, -2.5344e+01, -3.9398e+01, -4.9960e+01, -5.7666e+01,
         -6.2833e+01, -6.0820e+01, -5.9827e+01, -5.6486e+01, -5.0635e+01],
        [ 9.6532e+00,  2.6538e+00, -5.7565e+00, -1.4597e+01, -2.3211e+01,
         -3.1135e+01, -3.7072e+01, -4.1623e+01, -4.4596e+01, -4.5804e+01],
        [-2.2173e+01, -2.7997e+01, -3.3641e+01, -3.5363e+01, -3.4455e+01,
         -3.1698e+01, -2.3748e+01, -1.8204e+01, -1.1890e+01, -4.8313e+00],
        [ 3.7221e+01,  2.5553e+01,  2.4602e+01,  2.1907e+01,  2.3432e+01,
          1.6311e+01,  3.0362e+01,  3.0265e+01,  3.1072e+01,  3.3205e+01],
        [ 8.5700e-02, -2.1550e-01, -2.3800e-02, -6.9000e-02,  3.7700e-02,
         -1.3830e-01,  3.6320e-01,  3.6080e-01,  3.8160e-01,  4.3670e-01],
        [ 1.5684e+01,  7.0705e+01,  3.2371e+00,  5.7140e-01,  2.8786e+01,
          6.1477e+01,  6.5473e+01,  1.1285e+02, -4.1668e+01, -2.1169e+01],
        [-3.5000e-03, -5.1000e-03, -7.4000e-03, -1.0100e-02, -1.2000e-02,
         -1.3400e-02, -1.4800e-02, -1.4900e-02, -1.4800e-02, -1.4400e-02]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.4098, 10.4082, 10.4082, 10.4082, 10.4083, 10.4103, 10.4098, 10.4105,
         10.4115, 10.4106]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0439e+01,  1.0437e+01,  1.0435e+01,  1.0430e+01,  1.0429e+01,
          1.0427e+01,  1.0428e+01,  1.0427e+01,  1.0428e+01,  1.0428e+01],
        [-1.1516e+02, -1.1843e+02, -1.2358e+02, -1.3900e+02, -1.5297e+02,
         -1.6682e+02, -1.7320e+02, -1.7930e+02, -1.7952e+02, -1.7860e+02],
        [-9.0609e+01, -9.6174e+01, -1.0165e+02, -1.0912e+02, -1.1789e+02,
         -1.2768e+02, -1.3678e+02, -1.4529e+02, -1.5213e+02, -1.5743e+02],
        [-2.4552e+01, -2.2257e+01, -2.1923e+01, -2.9877e+01, -3.5076e+01,
         -3.9146e+01, -3.6418e+01, -3.4010e+01, -2.7388e+01, -2.1171e+01],
        [ 2.1167e+01,  2.1358e+01,  2.3083e+01,  2.1950e+01,  1.8520e+01,
          1.9456e+01,  1.8352e+01,  2.1736e+01,  2.5278e+01,  2.5205e+01],
        [ 9.1500e-02,  1.0400e-01,  1.7340e-01,  1.6480e-01,  1.5400e-02,
          6.7800e-02,  6.4000e-03,  3.7890e-01,  7.6260e-01,  7.5470e-01],
        [-2.3781e+01, -9.9910e+01, -3.1543e+01, -1.6813e+02, -1.3390e+02,
         -1.0446e+02, -9.8026e+01, -2.6743e+01,  5.7218e+01,  1.6253e+01],
        [-2.6000e-02, -2.5400e-02, -2.5100e-02, -2.4100e-02, -2.4400e-02,
         -2.4500e-02, -2.4600e-02, -2.4700e-02, -2.4200e-02, -2.3600e-02]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.4366, 10.4351, 10.4304, 10.4291, 10.4274, 10.4284, 10.4272, 10.4282,
         10.4278, 10.4287]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0775e+01,  1.0775e+01,  1.0776e+01,  1.0775e+01,  1.0775e+01,
          1.0774e+01,  1.0774e+01,  1.0774e+01,  1.0775e+01,  1.0775e+01],
        [ 3.5432e+01,  2.7329e+01,  2.3596e+01,  1.7518e+01,  1.0874e+01,
          3.3637e+00, -3.6612e+00, -6.8148e+00, -8.4540e+00, -6.5133e+00],
        [ 4.7294e+01,  4.3301e+01,  3.9360e+01,  3.4992e+01,  3.0168e+01,
          2.4807e+01,  1.9114e+01,  1.3928e+01,  9.4514e+00,  6.2585e+00],
        [-1.1862e+01, -1.5972e+01, -1.5764e+01, -1.7473e+01, -1.9294e+01,
         -2.1443e+01, -2.2775e+01, -2.0743e+01, -1.7906e+01, -1.2772e+01],
        [ 5.3182e+01,  4.8163e+01,  5.2140e+01,  4.4645e+01,  3.2885e+01,
          3.2642e+01,  3.3058e+01,  3.1383e+01,  2.8065e+01,  3.5963e+01],
        [-5.0200e-02, -1.8610e-01,  1.2430e-01, -1.1000e-01, -3.3120e-01,
         -5.8000e-03,  9.9000e-03, -2.9800e-02, -7.6400e-02,  1.6890e-01],
        [ 6.8473e+01,  4.0695e+01,  2.1104e+01,  5.9088e+01,  8.6387e+01,
          7.3617e+01,  1.0802e+02,  3.4195e+01,  2.8359e+01, -4.2971e+00],
        [ 4.2000e-03,  3.2000e-03,  2.0000e-03,  1.3000e-03,  3.0000e-04,
         -1.1000e-03, -2.5000e-03, -3.7000e-03, -4.6000e-03, -5.1000e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.7751, 10.7759, 10.7751, 10.7747, 10.7741, 10.7738, 10.7744, 10.7746,
         10.7755, 10.7737]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0541e+01,  1.0541e+01,  1.0542e+01,  1.0542e+01,  1.0540e+01,
          1.0540e+01,  1.0537e+01,  1.0537e+01,  1.0538e+01,  1.0538e+01],
        [ 7.9368e+00,  1.3037e+01,  1.9024e+01,  2.4492e+01,  2.2881e+01,
          2.1056e+01,  1.1667e+01,  3.9749e+00, -1.4685e+00, -5.6759e+00],
        [-5.6232e+00, -1.8911e+00,  2.2920e+00,  6.7321e+00,  9.9618e+00,
          1.2181e+01,  1.2078e+01,  1.0457e+01,  8.0722e+00,  5.3226e+00],
        [ 1.3560e+01,  1.4928e+01,  1.6732e+01,  1.7760e+01,  1.2919e+01,
          8.8754e+00, -4.1070e-01, -6.4824e+00, -9.5407e+00, -1.0998e+01],
        [ 7.6590e+01,  7.8499e+01,  7.9926e+01,  8.1572e+01,  6.5972e+01,
          6.3237e+01,  4.5772e+01,  4.6946e+01,  4.8475e+01,  4.8314e+01],
        [ 1.1139e+00,  1.0319e+00,  1.0247e+00,  1.0278e+00,  7.4400e-01,
          6.4970e-01,  3.1610e-01,  3.3850e-01,  3.6780e-01,  2.7600e-01],
        [-3.8483e+01, -2.3826e+01, -8.3976e+00, -2.5247e+01, -3.3689e+01,
         -3.5254e+01, -4.0267e+00, -2.2034e+01,  2.5299e+01,  4.4680e+01],
        [ 8.0000e-04,  2.1000e-03,  3.3000e-03,  4.5000e-03,  5.5000e-03,
          5.7000e-03,  5.7000e-03,  4.6000e-03,  3.3000e-03,  2.3000e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.5409, 10.5416, 10.5419, 10.5401, 10.5400, 10.5374, 10.5373, 10.5376,
         10.5376, 10.5380]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0562e+01,  1.0560e+01,  1.0560e+01,  1.0560e+01,  1.0559e+01,
          1.0559e+01,  1.0561e+01,  1.0560e+01,  1.0560e+01,  1.0560e+01],
        [-1.7495e+01, -2.2152e+01, -2.7090e+01, -3.1191e+01, -3.4435e+01,
         -3.7691e+01, -3.4129e+01, -3.3222e+01, -3.1715e+01, -3.0637e+01],
        [-1.5763e+01, -1.7041e+01, -1.9051e+01, -2.1479e+01, -2.4070e+01,
         -2.6794e+01, -2.8261e+01, -2.9253e+01, -2.9746e+01, -2.9924e+01],
        [-1.7315e+00, -5.1115e+00, -8.0397e+00, -9.7119e+00, -1.0365e+01,
         -1.0896e+01, -5.8675e+00, -3.9691e+00, -1.9694e+00, -7.1300e-01],
        [ 3.8370e+01,  3.2914e+01,  3.5098e+01,  3.7673e+01,  3.7384e+01,
          4.0054e+01,  4.9461e+01,  3.3995e+01,  3.3284e+01,  3.6570e+01],
        [ 2.3620e-01,  1.2800e-02,  1.5770e-01,  3.2660e-01,  3.0760e-01,
          4.7510e-01,  1.1011e+00,  6.5300e-02,  2.2300e-02,  2.2090e-01],
        [-4.4352e+01, -7.7588e+01, -5.7991e+01,  2.3168e+01,  3.8994e+01,
          1.2629e+01,  1.0250e+01,  5.3395e+00,  4.4720e+01,  2.4604e+01],
        [-3.5000e-03, -3.2000e-03, -3.5000e-03, -3.6000e-03, -3.6000e-03,
         -4.0000e-03, -4.4000e-03, -3.9000e-03, -4.0000e-03, -4.1000e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.5603, 10.5598, 10.5596, 10.5595, 10.5591, 10.5610, 10.5602, 10.5604,
         10.5602, 10.5592]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0742e+01,  1.0741e+01,  1.0741e+01,  1.0740e+01,  1.0742e+01,
          1.0742e+01,  1.0742e+01,  1.0742e+01,  1.0743e+01,  1.0742e+01],
        [ 2.4833e+01,  1.9884e+01,  1.5225e+01,  9.3165e+00,  1.1561e+01,
          1.3106e+01,  1.4907e+01,  1.4261e+01,  1.6955e+01,  1.5753e+01],
        [ 3.4823e+01,  3.1835e+01,  2.8513e+01,  2.4674e+01,  2.2051e+01,
          2.0262e+01,  1.9191e+01,  1.8205e+01,  1.7955e+01,  1.7515e+01],
        [-9.9902e+00, -1.1951e+01, -1.3288e+01, -1.5357e+01, -1.0491e+01,
         -7.1559e+00, -4.2838e+00, -3.9439e+00, -1.0002e+00, -1.7617e+00],
        [ 5.2281e+01,  4.8796e+01,  5.2465e+01,  4.3449e+01,  4.7367e+01,
          4.4475e+01,  3.9091e+01,  4.1833e+01,  4.8826e+01,  4.5563e+01],
        [ 8.1100e-02, -8.4500e-02,  1.9520e-01, -2.8450e-01,  1.6230e-01,
          4.2500e-02, -1.8050e-01,  1.0180e-01,  3.6120e-01,  2.4010e-01],
        [ 5.0177e+01,  6.9341e+01,  1.1332e+02,  6.4139e+01,  6.0375e+01,
          4.2417e+01,  2.7919e+01,  1.6922e+01, -2.4989e+01, -6.0479e+01],
        [ 3.2000e-03,  2.6000e-03,  1.6000e-03,  7.0000e-04, -5.0000e-04,
         -1.0000e-03, -1.4000e-03, -1.7000e-03, -1.9000e-03, -1.6000e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.7410, 10.7408, 10.7402, 10.7421, 10.7421, 10.7423, 10.7418, 10.7427,
         10.7419, 10.7406]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0667e+01,  1.0667e+01,  1.0667e+01,  1.0667e+01,  1.0666e+01,
          1.0666e+01,  1.0666e+01,  1.0667e+01,  1.0668e+01,  1.0668e+01],
        [-2.8040e+00, -1.2277e+00,  1.8648e+00,  1.8717e+00, -1.4730e-01,
         -1.0032e+00, -7.7600e-01,  1.1012e+00,  4.9597e+00,  7.4931e+00],
        [-3.9931e+00, -3.4400e+00, -2.3790e+00, -1.5289e+00, -1.2526e+00,
         -1.2027e+00, -1.1174e+00, -6.7370e-01,  4.5300e-01,  1.8610e+00],
        [ 1.1891e+00,  2.2123e+00,  4.2438e+00,  3.4006e+00,  1.1052e+00,
          1.9950e-01,  3.4140e-01,  1.7749e+00,  4.5067e+00,  5.6321e+00],
        [ 5.3383e+01,  4.9053e+01,  4.8863e+01,  4.4617e+01,  4.5652e+01,
          5.0794e+01,  5.7027e+01,  5.9120e+01,  5.7924e+01,  5.9188e+01],
        [ 5.4090e-01,  3.9520e-01,  3.8880e-01,  2.8430e-01,  4.0870e-01,
          8.3890e-01,  1.2267e+00,  1.1062e+00,  9.4520e-01,  1.0031e+00],
        [ 3.4319e+00, -1.5229e+01, -3.5869e+01, -2.9419e+01,  7.8000e+00,
         -1.8348e+00, -3.4251e+01, -3.6730e+01, -3.0916e+01,  1.4894e+01],
        [-1.3000e-03, -1.1000e-03, -9.0000e-04, -5.0000e-04, -3.0000e-04,
         -3.0000e-04, -2.0000e-04,  0.0000e+00,  5.0000e-04,  1.1000e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.6667, 10.6673, 10.6666, 10.6660, 10.6662, 10.6665, 10.6670, 10.6677,
         10.6675, 10.6679]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0926e+01,  1.0931e+01,  1.0933e+01,  1.0932e+01,  1.0934e+01,
          1.0933e+01,  1.0936e+01,  1.0940e+01,  1.0940e+01,  1.0939e+01],
        [ 2.9317e+01,  4.5589e+01,  6.6227e+01,  7.7279e+01,  9.5952e+01,
          1.0532e+02,  1.2074e+02,  1.5130e+02,  1.7344e+02,  1.8600e+02],
        [ 3.0278e+01,  3.3340e+01,  3.9918e+01,  4.7390e+01,  5.7102e+01,
          6.6746e+01,  7.7544e+01,  9.2295e+01,  1.0852e+02,  1.2402e+02],
        [-9.6090e-01,  1.2249e+01,  2.6309e+01,  2.9889e+01,  3.8849e+01,
          3.8575e+01,  4.3193e+01,  5.9002e+01,  6.4913e+01,  6.1984e+01],
        [ 4.8048e+01,  5.0988e+01,  5.4835e+01,  4.9973e+01,  5.6214e+01,
          5.8967e+01,  6.9758e+01,  7.3338e+01,  7.4230e+01,  7.7235e+01],
        [ 1.3820e-01,  2.5100e-01,  3.9860e-01,  2.1210e-01,  5.1250e-01,
          6.3240e-01,  1.3013e+00,  1.1414e+00,  1.0309e+00,  1.1009e+00],
        [ 2.2708e+02,  7.8512e+01, -1.3418e+02, -1.0212e+02, -1.3992e+02,
         -2.6471e+02, -2.6359e+02, -1.3885e+02, -7.8851e+01, -2.0320e+01],
        [ 1.4000e-03, -7.0000e-04, -8.0000e-04,  4.0000e-04,  1.6000e-03,
          3.7000e-03,  5.8000e-03,  9.3000e-03,  1.3700e-02,  1.7200e-02]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.9310, 10.9329, 10.9319, 10.9344, 10.9334, 10.9355, 10.9399, 10.9399,
         10.9393, 10.9387]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0814e+01,  1.0812e+01,  1.0809e+01,  1.0809e+01,  1.0809e+01,
          1.0808e+01,  1.0808e+01,  1.0808e+01,  1.0809e+01,  1.0808e+01],
        [ 4.5829e+01,  3.9756e+01,  2.3673e+01,  8.4568e+00, -3.3122e+00,
         -1.4860e+01, -2.2921e+01, -2.8892e+01, -3.0665e+01, -3.5122e+01],
        [ 3.6160e+01,  3.6879e+01,  3.4238e+01,  2.9082e+01,  2.2603e+01,
          1.5110e+01,  7.5040e+00,  2.2490e-01, -5.9531e+00, -1.1787e+01],
        [ 9.6689e+00,  2.8766e+00, -1.0565e+01, -2.0625e+01, -2.5915e+01,
         -2.9970e+01, -3.0426e+01, -2.9117e+01, -2.4712e+01, -2.3335e+01],
        [ 5.1925e+01,  4.6838e+01,  4.1831e+01,  4.2330e+01,  4.3154e+01,
          4.4782e+01,  4.7865e+01,  4.2237e+01,  3.9315e+01,  3.8357e+01],
        [ 3.4520e-01,  2.8670e-01,  1.5960e-01,  2.0100e-01,  2.4080e-01,
          3.1950e-01,  4.6850e-01,  1.9650e-01,  5.5200e-02,  8.9000e-03],
        [-6.2647e+01, -1.2774e+02, -1.6662e+02, -8.1303e+01, -5.4776e+00,
         -2.3998e+01,  3.6183e+01,  1.6113e+02,  1.2207e+02,  1.5584e+02],
        [-4.0000e-04,  5.0000e-04,  7.0000e-04,  3.0000e-04, -2.0000e-04,
         -9.0000e-04, -1.8000e-03, -2.3000e-03, -3.2000e-03, -4.4000e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.8121, 10.8094, 10.8088, 10.8088, 10.8082, 10.8084, 10.8085, 10.8091,
         10.8083, 10.8085]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0742e+01,  1.0742e+01,  1.0742e+01,  1.0741e+01,  1.0741e+01,
          1.0741e+01,  1.0741e+01,  1.0741e+01,  1.0740e+01,  1.0741e+01],
        [-2.5592e+00,  6.4560e+00,  1.4919e+01,  1.8244e+01,  1.9389e+01,
          1.8454e+01,  1.7481e+01,  1.7861e+01,  1.3748e+01,  1.3457e+01],
        [-3.8647e+01, -2.9626e+01, -2.0717e+01, -1.2925e+01, -6.4622e+00,
         -1.4790e+00,  2.3130e+00,  5.4226e+00,  7.0876e+00,  8.3615e+00],
        [ 3.6088e+01,  3.6082e+01,  3.5636e+01,  3.1169e+01,  2.5851e+01,
          1.9933e+01,  1.5168e+01,  1.2438e+01,  6.6603e+00,  5.0954e+00],
        [ 7.6010e+01,  7.6344e+01,  7.6673e+01,  6.4926e+01,  5.6330e+01,
          5.3162e+01,  5.3612e+01,  6.6653e+01,  6.1801e+01,  5.9719e+01],
        [ 1.1770e+00,  1.0071e+00,  1.0070e+00,  6.1560e-01,  2.6620e-01,
         -2.5600e-02,  1.9200e-02,  5.7380e-01,  3.6740e-01,  2.7890e-01],
        [ 1.1548e+02,  1.0954e+02,  9.2147e+01, -5.7200e+00, -4.5209e+01,
          3.0433e+00, -4.2926e+01,  3.0067e+01,  2.8680e+01,  4.4067e+01],
        [ 8.4000e-03,  9.0000e-03,  9.1000e-03,  9.2000e-03,  8.6000e-03,
          7.8000e-03,  7.0000e-03,  6.0000e-03,  5.6000e-03,  4.7000e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.7419, 10.7423, 10.7415, 10.7411, 10.7407, 10.7407, 10.7411, 10.7399,
         10.7407, 10.7411]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0560e+01,  1.0559e+01,  1.0559e+01,  1.0559e+01,  1.0559e+01,
          1.0559e+01,  1.0559e+01,  1.0560e+01,  1.0559e+01,  1.0559e+01],
        [-7.4682e+01, -7.9194e+01, -8.1640e+01, -8.1555e+01, -8.2135e+01,
         -8.0879e+01, -7.9234e+01, -7.5713e+01, -7.2627e+01, -6.9989e+01],
        [-4.9099e+01, -5.5118e+01, -6.0422e+01, -6.4649e+01, -6.8146e+01,
         -7.0693e+01, -7.2401e+01, -7.3063e+01, -7.2976e+01, -7.2379e+01],
        [-2.5583e+01, -2.4076e+01, -2.1218e+01, -1.6906e+01, -1.3989e+01,
         -1.0187e+01, -6.8332e+00, -2.6499e+00,  3.4960e-01,  2.3897e+00],
        [ 2.1032e+01,  1.2293e+01,  1.0437e+01,  1.5740e+01,  1.2327e+01,
          1.4592e+01,  1.5790e+01,  2.3218e+01,  3.8729e+01,  3.8517e+01],
        [-4.4000e-03, -1.5100e-01, -2.7900e-02,  1.1120e-01,  4.0600e-02,
          9.7000e-02,  1.5610e-01,  4.9710e-01,  1.7548e+00,  9.9250e-01],
        [ 7.5996e+01,  7.9054e+01,  5.9402e+01,  2.1171e+00, -1.2628e+02,
         -1.1812e+02, -1.3050e+02, -9.1813e+01, -8.3104e+01, -4.9383e+01],
        [-1.3300e-02, -1.4200e-02, -1.5500e-02, -1.6400e-02, -1.6200e-02,
         -1.5900e-02, -1.4700e-02, -1.3400e-02, -1.1700e-02, -9.6000e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.5591, 10.5591, 10.5595, 10.5590, 10.5592, 10.5591, 10.5596, 10.5594,
         10.5592, 10.5582]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0937e+01,  1.0937e+01,  1.0937e+01,  1.0938e+01,  1.0937e+01,
          1.0938e+01,  1.0939e+01,  1.0937e+01,  1.0938e+01,  1.0937e+01],
        [ 9.4204e+01,  9.6555e+01,  9.6757e+01,  9.8610e+01,  9.6112e+01,
          9.6400e+01,  1.0135e+02,  9.5141e+01,  9.2428e+01,  8.4198e+01],
        [ 8.5311e+01,  8.7560e+01,  8.9399e+01,  9.1242e+01,  9.2216e+01,
          9.3053e+01,  9.4712e+01,  9.4798e+01,  9.4324e+01,  9.2299e+01],
        [ 8.8928e+00,  8.9950e+00,  7.3579e+00,  7.3685e+00,  3.8960e+00,
          3.3479e+00,  6.6385e+00,  3.4320e-01, -1.8957e+00, -8.1011e+00],
        [ 7.0348e+01,  7.1487e+01,  6.7685e+01,  6.9084e+01,  6.8815e+01,
          6.8411e+01,  7.1866e+01,  5.5966e+01,  5.8261e+01,  5.5945e+01],
        [ 3.7460e-01,  2.5970e-01,  2.9700e-02,  1.1430e-01,  9.8100e-02,
          4.5300e-02,  2.6060e-01, -7.3040e-01,  8.2700e-02, -8.0000e-04],
        [ 4.5145e+01,  7.1139e+01,  6.2678e+01,  9.1229e+01,  7.9462e+01,
          2.3038e+01, -5.2236e+01, -5.2348e+01,  3.4910e+00,  4.3025e+01],
        [ 9.9000e-03,  9.1000e-03,  8.5000e-03,  7.8000e-03,  7.2000e-03,
          6.5000e-03,  6.0000e-03,  6.2000e-03,  5.8000e-03,  5.5000e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.9374, 10.9372, 10.9379, 10.9372, 10.9380, 10.9393, 10.9373, 10.9380,
         10.9369, 10.9356]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0552e+01,  1.0552e+01,  1.0555e+01,  1.0556e+01,  1.0555e+01,
          1.0555e+01,  1.0556e+01,  1.0557e+01,  1.0557e+01,  1.0556e+01],
        [-9.0673e+01, -9.3162e+01, -8.4158e+01, -7.4123e+01, -6.6701e+01,
         -5.9527e+01, -5.1338e+01, -4.1202e+01, -3.4037e+01, -3.0009e+01],
        [-5.7632e+01, -6.4738e+01, -6.8622e+01, -6.9722e+01, -6.9118e+01,
         -6.7200e+01, -6.4027e+01, -5.9462e+01, -5.4377e+01, -4.9504e+01],
        [-3.3041e+01, -2.8424e+01, -1.5536e+01, -4.4006e+00,  2.4169e+00,
          7.6728e+00,  1.2689e+01,  1.8260e+01,  2.0340e+01,  1.9494e+01],
        [ 2.3221e+01,  1.3497e+01,  2.7267e+01,  3.7695e+01,  3.6911e+01,
          3.9213e+01,  3.9080e+01,  4.9977e+01,  5.7673e+01,  5.6137e+01],
        [ 1.1150e-01, -1.4820e-01,  3.3840e-01,  9.1610e-01,  9.6760e-01,
          1.0627e+00,  9.9480e-01,  1.4185e+00,  1.2110e+00,  9.6520e-01],
        [ 1.5242e+01,  1.6111e+01,  6.0876e+01, -3.1086e+00, -7.2613e+01,
         -7.2976e+01, -1.1739e+02, -1.5111e+02, -1.7521e+02, -1.3730e+02],
        [-1.6000e-02, -1.6400e-02, -1.6900e-02, -1.6100e-02, -1.4500e-02,
         -1.2700e-02, -1.0600e-02, -8.4000e-03, -5.6000e-03, -2.7000e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.5516, 10.5549, 10.5555, 10.5551, 10.5553, 10.5559, 10.5569, 10.5565,
         10.5559, 10.5551]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0640e+01,  1.0640e+01,  1.0640e+01,  1.0640e+01,  1.0639e+01,
          1.0638e+01,  1.0638e+01,  1.0641e+01,  1.0642e+01,  1.0642e+01],
        [-3.8232e+01, -3.9090e+01, -4.0048e+01, -4.1628e+01, -4.3870e+01,
         -4.9425e+01, -5.3785e+01, -4.5028e+01, -3.4718e+01, -2.6487e+01],
        [-2.7356e+01, -2.9703e+01, -3.1772e+01, -3.3743e+01, -3.5768e+01,
         -3.8500e+01, -4.1557e+01, -4.2251e+01, -4.0744e+01, -3.7893e+01],
        [-1.0876e+01, -9.3879e+00, -8.2760e+00, -7.8850e+00, -8.1021e+00,
         -1.0925e+01, -1.2229e+01, -2.7771e+00,  6.0268e+00,  1.1406e+01],
        [ 3.2701e+01,  3.4408e+01,  3.9919e+01,  3.0887e+01,  2.4653e+01,
          1.9955e+01,  7.3862e+00,  3.9105e+01,  4.7379e+01,  5.2037e+01],
        [ 2.5380e-01,  3.2750e-01,  5.6540e-01,  9.7600e-02, -1.9690e-01,
         -1.8540e-01, -4.1850e-01,  7.4450e-01,  1.1750e+00,  1.1165e+00],
        [ 2.1295e+00,  1.0650e+01,  6.0501e+01,  6.4311e+01,  3.6851e+01,
          3.4024e+00, -1.8711e+01, -8.7190e+00, -5.0017e+01, -3.6634e+01],
        [-3.9000e-03, -4.1000e-03, -4.3000e-03, -4.4000e-03, -4.8000e-03,
         -5.4000e-03, -6.1000e-03, -6.9000e-03, -6.1000e-03, -4.9000e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.6403, 10.6400, 10.6396, 10.6392, 10.6379, 10.6377, 10.6412, 10.6421,
         10.6420, 10.6422]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0671e+01,  1.0674e+01,  1.0674e+01,  1.0674e+01,  1.0674e+01,
          1.0673e+01,  1.0675e+01,  1.0676e+01,  1.0677e+01,  1.0678e+01],
        [ 1.1354e+02,  1.2867e+02,  1.3797e+02,  1.4561e+02,  1.4900e+02,
          1.4749e+02,  1.4959e+02,  1.5430e+02,  1.6098e+02,  1.6768e+02],
        [ 8.0004e+01,  8.9738e+01,  9.9385e+01,  1.0863e+02,  1.1670e+02,
          1.2286e+02,  1.2821e+02,  1.3343e+02,  1.3894e+02,  1.4468e+02],
        [ 3.3538e+01,  3.8937e+01,  3.8588e+01,  3.6984e+01,  3.2296e+01,
          2.4628e+01,  2.1383e+01,  2.0872e+01,  2.2040e+01,  2.2994e+01],
        [ 7.7880e+01,  8.2133e+01,  7.7663e+01,  7.7805e+01,  8.4231e+01,
          8.9834e+01,  9.0381e+01,  9.0560e+01,  9.0482e+01,  8.9518e+01],
        [ 1.0326e+00,  1.1252e+00,  8.8310e-01,  8.8680e-01,  1.0549e+00,
          1.1389e+00,  1.0128e+00,  1.0041e+00,  9.9780e-01,  9.6650e-01],
        [-7.4228e+01, -1.6517e+02, -1.6338e+02, -1.3814e+02, -9.3545e+01,
         -5.8243e+00,  8.4252e+01,  5.0440e+01,  2.0322e+01,  8.6153e+01],
        [ 8.3000e-03,  1.0500e-02,  1.3700e-02,  1.6100e-02,  1.8000e-02,
          1.9500e-02,  2.0400e-02,  2.1000e-02,  2.1200e-02,  2.1500e-02]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.6740, 10.6737, 10.6742, 10.6739, 10.6732, 10.6747, 10.6761, 10.6774,
         10.6784, 10.6791]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0435e+01,  1.0434e+01,  1.0437e+01,  1.0439e+01,  1.0439e+01,
          1.0439e+01,  1.0438e+01,  1.0438e+01,  1.0438e+01,  1.0438e+01],
        [-1.4504e+01, -2.2134e+01, -1.8770e+01, -1.0661e+01, -3.3933e+00,
          6.2460e-01,  1.9051e+00,  3.8152e+00,  5.8442e+00,  5.0873e+00],
        [ 3.8127e+00, -1.3767e+00, -4.8553e+00, -6.0165e+00, -5.4919e+00,
         -4.2686e+00, -3.0338e+00, -1.6640e+00, -1.6240e-01,  8.8760e-01],
        [-1.8317e+01, -2.0758e+01, -1.3915e+01, -4.6448e+00,  2.0986e+00,
          4.8932e+00,  4.9389e+00,  5.4792e+00,  6.0066e+00,  4.1998e+00],
        [ 3.2277e+01,  2.5610e+01,  4.3551e+01,  4.9027e+01,  4.6827e+01,
          4.9582e+01,  4.7183e+01,  4.8901e+01,  4.8491e+01,  4.2894e+01],
        [ 4.7500e-02, -1.3280e-01,  4.2840e-01,  5.5920e-01,  5.0660e-01,
          5.7240e-01,  5.1510e-01,  5.5620e-01,  5.4640e-01,  4.1270e-01],
        [ 8.1899e+01,  3.3709e+01,  4.2638e+01,  3.3853e+01,  3.9639e+01,
          6.7756e+01, -5.2227e+01, -7.6947e+01, -9.8476e+01, -1.0603e+02],
        [-2.1000e-03, -3.7000e-03, -5.8000e-03, -6.0000e-03, -5.5000e-03,
         -4.8000e-03, -4.1000e-03, -3.8000e-03, -2.6000e-03, -1.3000e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.4336, 10.4369, 10.4388, 10.4391, 10.4385, 10.4378, 10.4382, 10.4384,
         10.4375, 10.4395]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0991e+01,  1.0990e+01,  1.0991e+01,  1.0991e+01,  1.0992e+01,
          1.0990e+01,  1.0990e+01,  1.0990e+01,  1.0987e+01,  1.0985e+01],
        [ 4.7394e+01,  4.9187e+01,  5.3862e+01,  5.5562e+01,  5.9333e+01,
          5.4414e+01,  4.8795e+01,  4.2405e+01,  2.5478e+01,  2.7607e+00],
        [ 5.6956e+01,  5.5402e+01,  5.5094e+01,  5.5188e+01,  5.6017e+01,
          5.5696e+01,  5.4316e+01,  5.1934e+01,  4.6643e+01,  3.7866e+01],
        [-9.5617e+00, -6.2155e+00, -1.2323e+00,  3.7430e-01,  3.3167e+00,
         -1.2818e+00, -5.5211e+00, -9.5289e+00, -2.1164e+01, -3.5106e+01],
        [ 5.1317e+01,  4.4438e+01,  5.0139e+01,  5.3558e+01,  5.3892e+01,
          4.8126e+01,  5.0631e+01,  4.9390e+01,  4.2623e+01,  3.5855e+01],
        [-7.2400e-02, -2.9380e-01,  1.8820e-01,  3.0100e-01,  3.5290e-01,
          1.8000e-01,  3.3270e-01,  3.2030e-01, -1.4420e-01, -4.6990e-01],
        [ 1.0689e+02,  7.2477e+01,  2.1829e+01,  7.8190e+00, -5.0481e+01,
         -5.6465e+01, -7.1358e+01, -1.5815e+02, -7.4970e+01, -6.9186e+00],
        [ 9.0000e-04,  6.0000e-04, -0.0000e+00, -1.0000e-04,  2.0000e-04,
          6.0000e-04,  7.0000e-04,  8.0000e-04,  9.0000e-04,  4.0000e-04]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.9904, 10.9912, 10.9909, 10.9916, 10.9901, 10.9898, 10.9895, 10.9871,
         10.9852, 10.9846]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0942e+01,  1.0942e+01,  1.0942e+01,  1.0942e+01,  1.0941e+01,
          1.0942e+01,  1.0941e+01,  1.0940e+01,  1.0941e+01,  1.0941e+01],
        [-4.6647e+00, -6.1288e+00, -6.0015e+00, -7.3873e+00, -1.1134e+01,
         -1.1453e+01, -1.4141e+01, -1.8852e+01, -2.1288e+01, -2.2748e+01],
        [-1.4347e+01, -1.2703e+01, -1.1363e+01, -1.0568e+01, -1.0681e+01,
         -1.0835e+01, -1.1497e+01, -1.2968e+01, -1.4632e+01, -1.6255e+01],
        [ 9.6818e+00,  6.5742e+00,  5.3612e+00,  3.1803e+00, -4.5300e-01,
         -6.1800e-01, -2.6446e+00, -5.8845e+00, -6.6564e+00, -6.4932e+00],
        [ 4.9104e+01,  5.1903e+01,  5.3111e+01,  5.5111e+01,  5.1878e+01,
          5.1640e+01,  4.9587e+01,  4.8551e+01,  4.5207e+01,  3.6122e+01],
        [ 5.1950e-01,  6.1680e-01,  6.5880e-01,  7.2830e-01,  6.1590e-01,
          5.0080e-01,  3.9230e-01,  3.4510e-01, -6.3500e-02, -5.1270e-01],
        [-6.8234e+01, -3.4902e+01, -4.0992e+01, -6.2626e+01, -6.6924e+00,
          9.1743e+01,  4.3548e+01,  1.3639e+01,  1.2540e+02,  3.6348e+00],
        [ 5.0000e-04,  8.0000e-04,  1.0000e-03,  1.2000e-03,  1.3000e-03,
          1.2000e-03,  1.1000e-03,  4.0000e-04, -2.0000e-04, -7.0000e-04]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.9417, 10.9420, 10.9416, 10.9410, 10.9416, 10.9410, 10.9404, 10.9406,
         10.9407, 10.9406]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0701e+01,  1.0699e+01,  1.0699e+01,  1.0699e+01,  1.0700e+01,
          1.0700e+01,  1.0702e+01,  1.0699e+01,  1.0699e+01,  1.0701e+01],
        [-7.6226e+01, -8.2214e+01, -8.9151e+01, -9.2661e+01, -8.9002e+01,
         -8.5451e+01, -7.6153e+01, -7.7502e+01, -7.6618e+01, -6.8507e+01],
        [-7.4750e+01, -7.6243e+01, -7.8825e+01, -8.1592e+01, -8.3074e+01,
         -8.3549e+01, -8.2070e+01, -8.1156e+01, -8.0249e+01, -7.7900e+01],
        [-1.4756e+00, -5.9706e+00, -1.0326e+01, -1.1069e+01, -5.9281e+00,
         -1.9020e+00,  5.9170e+00,  3.6545e+00,  3.6309e+00,  9.3936e+00],
        [ 4.2832e+01,  4.3948e+01,  4.4364e+01,  4.5313e+01,  4.9890e+01,
          4.4295e+01,  4.9567e+01,  3.6077e+01,  3.0413e+01,  3.5385e+01],
        [ 7.1140e-01,  7.5590e-01,  7.7250e-01,  8.1030e-01,  9.9280e-01,
          7.5490e-01,  9.7860e-01, -1.5600e-01, -4.0470e-01,  2.5290e-01],
        [-1.5372e+02, -4.4577e+01, -4.3461e+01,  9.9299e+01,  2.0132e+02,
          2.2794e+02,  1.8891e+02, -3.9222e+01, -1.5420e+01, -8.0971e+01],
        [-2.9000e-03, -2.4000e-03, -2.3000e-03, -2.9000e-03, -3.4000e-03,
         -3.9000e-03, -5.0000e-03, -5.3000e-03, -6.7000e-03, -7.3000e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.6995, 10.6986, 10.6988, 10.7003, 10.7002, 10.7018, 10.6991, 10.6994,
         10.7013, 10.7020]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0773e+01,  1.0774e+01,  1.0774e+01,  1.0773e+01,  1.0774e+01,
          1.0773e+01,  1.0772e+01,  1.0771e+01,  1.0771e+01,  1.0771e+01],
        [ 7.7000e+01,  7.7104e+01,  7.3925e+01,  6.6768e+01,  6.4182e+01,
          5.7690e+01,  4.8531e+01,  3.8489e+01,  2.8104e+01,  1.9781e+01],
        [ 9.2682e+01,  8.9567e+01,  8.6438e+01,  8.2504e+01,  7.8840e+01,
          7.4610e+01,  6.9394e+01,  6.3213e+01,  5.6191e+01,  4.8909e+01],
        [-1.5682e+01, -1.2462e+01, -1.2513e+01, -1.5736e+01, -1.4658e+01,
         -1.6920e+01, -2.0863e+01, -2.4724e+01, -2.8087e+01, -2.9128e+01],
        [ 4.9832e+01,  5.1725e+01,  5.7019e+01,  4.9898e+01,  5.0579e+01,
          4.2544e+01,  3.9204e+01,  3.8109e+01,  3.8099e+01,  3.3181e+01],
        [-8.7200e-02,  6.6800e-02,  2.5350e-01,  2.3000e-03,  2.6300e-02,
         -2.5710e-01, -9.3700e-02, -2.8100e-02, -3.0000e-04, -1.2270e-01],
        [ 8.0729e+01,  9.0856e+01,  7.0818e+01,  3.8085e+01,  3.6819e+00,
          2.9166e+01,  1.4747e+01, -1.9337e+01, -3.2974e+01,  6.6014e+00],
        [ 5.7000e-03,  4.2000e-03,  3.1000e-03,  2.2000e-03,  1.2000e-03,
          7.0000e-04, -0.0000e+00, -9.0000e-04, -1.8000e-03, -2.4000e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.7744, 10.7737, 10.7727, 10.7737, 10.7727, 10.7718, 10.7712, 10.7707,
         10.7707, 10.7707]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0550e+01,  1.0553e+01,  1.0554e+01,  1.0557e+01,  1.0555e+01,
          1.0556e+01,  1.0558e+01,  1.0558e+01,  1.0562e+01,  1.0563e+01],
        [ 6.1430e+00,  9.3438e+00,  1.4401e+01,  2.6251e+01,  2.9648e+01,
          3.4225e+01,  4.4846e+01,  5.3209e+01,  7.1595e+01,  8.6661e+01],
        [ 2.4426e+01,  2.1409e+01,  2.0008e+01,  2.1256e+01,  2.2935e+01,
          2.5193e+01,  2.9124e+01,  3.3941e+01,  4.1471e+01,  5.0509e+01],
        [-1.8283e+01, -1.2066e+01, -5.6069e+00,  4.9951e+00,  6.7136e+00,
          9.0325e+00,  1.5723e+01,  1.9268e+01,  3.0123e+01,  3.6152e+01],
        [ 5.4415e+01,  4.9409e+01,  4.6300e+01,  5.0060e+01,  5.6271e+01,
          5.5675e+01,  6.1327e+01,  6.1860e+01,  6.5382e+01,  6.1800e+01],
        [ 8.5560e-01,  4.5380e-01,  2.7370e-01,  4.9160e-01,  8.5140e-01,
          7.7290e-01,  1.1808e+00,  1.0328e+00,  1.2264e+00,  8.1230e-01],
        [-1.4041e+01,  3.7159e+01,  9.1586e+00,  4.7171e+00,  4.1681e+01,
          1.5732e+02, -2.0278e+01,  1.6299e+01, -7.1095e+01, -1.6330e+02],
        [ 4.5000e-03,  3.3000e-03,  3.1000e-03,  2.4000e-03,  2.6000e-03,
          3.0000e-03,  3.2000e-03,  3.9000e-03,  5.5000e-03,  8.0000e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.5534, 10.5543, 10.5569, 10.5551, 10.5558, 10.5582, 10.5584, 10.5625,
         10.5629, 10.5577]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.1113e+01,  1.1112e+01,  1.1113e+01,  1.1113e+01,  1.1114e+01,
          1.1114e+01,  1.1115e+01,  1.1115e+01,  1.1116e+01,  1.1115e+01],
        [-1.1503e+01, -1.5148e+01, -1.3777e+01, -1.1703e+01, -7.6820e+00,
         -8.7330e-01,  6.9160e+00,  1.5199e+01,  2.3131e+01,  2.7344e+01],
        [ 2.9003e+00, -7.0940e-01, -3.3229e+00, -4.9990e+00, -5.5356e+00,
         -4.6031e+00, -2.2993e+00,  1.2004e+00,  5.5865e+00,  9.9379e+00],
        [-1.4404e+01, -1.4439e+01, -1.0454e+01, -6.7042e+00, -2.1464e+00,
          3.7298e+00,  9.2153e+00,  1.3999e+01,  1.7545e+01,  1.7406e+01],
        [ 3.1983e+01,  2.3371e+01,  3.5255e+01,  3.7558e+01,  4.2815e+01,
          5.1517e+01,  5.5034e+01,  7.0897e+01,  7.9924e+01,  7.2658e+01],
        [ 1.6600e-02, -1.9410e-01,  2.4340e-01,  2.9060e-01,  4.6950e-01,
          7.8980e-01,  8.8850e-01,  1.5010e+00,  1.1899e+00,  8.7150e-01],
        [ 4.6664e+01,  2.8910e+01,  3.4124e+01, -4.6322e+01, -8.0141e+01,
         -4.2074e+01, -3.4848e+01, -3.1640e+01, -6.6069e+01, -4.8466e+01],
        [-2.5000e-03, -2.8000e-03, -3.2000e-03, -3.2000e-03, -3.1000e-03,
         -2.5000e-03, -1.6000e-03, -8.0000e-04,  4.0000e-04,  1.6000e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[11.1124, 11.1132, 11.1134, 11.1138, 11.1145, 11.1149, 11.1153, 11.1156,
         11.1153, 11.1164]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0984e+01,  1.0986e+01,  1.0986e+01,  1.0985e+01,  1.0984e+01,
          1.0984e+01,  1.0986e+01,  1.0985e+01,  1.0984e+01,  1.0985e+01],
        [-4.0253e+01, -3.5181e+01, -3.0595e+01, -2.8962e+01, -3.0829e+01,
         -3.4778e+01, -2.7220e+01, -2.5516e+01, -2.7585e+01, -2.5371e+01],
        [-3.7596e+01, -3.7113e+01, -3.5809e+01, -3.4440e+01, -3.3717e+01,
         -3.3930e+01, -3.2588e+01, -3.1173e+01, -3.0456e+01, -2.9439e+01],
        [-2.6570e+00,  1.9321e+00,  5.2140e+00,  5.4779e+00,  2.8883e+00,
         -8.4880e-01,  5.3677e+00,  5.6575e+00,  2.8708e+00,  4.0682e+00],
        [ 4.0732e+01,  5.3576e+01,  5.1000e+01,  4.0852e+01,  3.6782e+01,
          3.4547e+01,  4.7235e+01,  4.4422e+01,  4.4034e+01,  5.2707e+01],
        [ 5.0770e-01,  1.3002e+00,  8.7240e-01,  3.0190e-01,  7.8600e-02,
         -1.3310e-01,  6.6680e-01,  5.1900e-01,  4.9860e-01,  9.5430e-01],
        [ 4.4602e+01,  4.2901e+01,  6.2265e+01,  4.1299e+01,  1.4414e+00,
         -5.5578e+01, -1.4553e+01, -5.9548e+01, -2.5193e+01, -2.8389e+01],
        [-1.3000e-03, -1.7000e-03, -1.5000e-03, -1.3000e-03, -1.6000e-03,
         -2.0000e-03, -2.4000e-03, -1.8000e-03, -1.7000e-03, -1.6000e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.9855, 10.9856, 10.9851, 10.9843, 10.9837, 10.9859, 10.9850, 10.9842,
         10.9849, 10.9851]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0360e+01,  1.0359e+01,  1.0358e+01,  1.0357e+01,  1.0355e+01,
          1.0350e+01,  1.0350e+01,  1.0349e+01,  1.0347e+01,  1.0346e+01],
        [ 3.8023e+01,  3.5205e+01,  3.2241e+01,  2.4874e+01,  1.4307e+01,
         -6.5858e+00, -2.2788e+01, -3.8281e+01, -5.2722e+01, -6.7014e+01],
        [ 3.8461e+01,  3.7810e+01,  3.6696e+01,  3.4331e+01,  3.0326e+01,
          2.2944e+01,  1.3798e+01,  3.3820e+00, -7.8387e+00, -1.9674e+01],
        [-4.3710e-01, -2.6044e+00, -4.4550e+00, -9.4576e+00, -1.6019e+01,
         -2.9530e+01, -3.6586e+01, -4.1662e+01, -4.4883e+01, -4.7340e+01],
        [ 6.3112e+01,  6.5120e+01,  5.9546e+01,  4.4349e+01,  3.7923e+01,
          2.7338e+01,  2.5156e+01,  2.3885e+01,  2.3356e+01,  2.0799e+01],
        [ 1.1689e+00,  1.0839e+00,  7.8500e-01,  1.9870e-01, -4.9100e-02,
         -3.8920e-01, -5.7800e-02, -3.1800e-02, -1.2800e-02, -6.1200e-02],
        [ 2.0410e+00, -3.7852e+00,  1.0826e+01, -1.5633e+00, -2.3331e+01,
         -1.1357e+01,  1.2646e+01,  1.1458e+02,  7.4772e+01,  7.3392e+01],
        [ 1.7000e-03,  2.2000e-03,  2.5000e-03,  2.5000e-03,  1.5000e-03,
          1.0000e-04, -2.9000e-03, -5.8000e-03, -8.9000e-03, -1.2200e-02]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.3585, 10.3584, 10.3565, 10.3547, 10.3498, 10.3498, 10.3486, 10.3475,
         10.3460, 10.3460]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0775e+01,  1.0776e+01,  1.0777e+01,  1.0777e+01,  1.0777e+01,
          1.0777e+01,  1.0777e+01,  1.0777e+01,  1.0777e+01,  1.0776e+01],
        [-3.2202e+01, -2.7319e+01, -2.1244e+01, -1.5341e+01, -1.1241e+01,
         -8.8643e+00, -4.5036e+00, -2.7325e+00, -1.8818e+00, -3.7784e+00],
        [-3.3074e+01, -3.1923e+01, -2.9787e+01, -2.6898e+01, -2.3766e+01,
         -2.0786e+01, -1.7529e+01, -1.4570e+01, -1.2032e+01, -1.0382e+01],
        [ 8.7180e-01,  4.6043e+00,  8.5429e+00,  1.1557e+01,  1.2526e+01,
          1.1922e+01,  1.3026e+01,  1.1838e+01,  1.0151e+01,  6.6032e+00],
        [ 4.1573e+01,  5.0290e+01,  6.4345e+01,  7.1203e+01,  6.1699e+01,
          6.5868e+01,  6.6968e+01,  6.3943e+01,  6.3398e+01,  5.4229e+01],
        [ 1.1982e+00,  1.3222e+00,  1.3929e+00,  1.1376e+00,  7.9830e-01,
          8.8680e-01,  9.1010e-01,  8.4590e-01,  8.3430e-01,  6.0920e-01],
        [-4.0529e+01, -6.0247e+01, -3.2021e+01, -3.7168e+01, -3.8233e+01,
         -2.0721e+01, -1.0111e+01, -2.5869e+01, -2.7400e+01, -1.8190e-01],
        [-4.6000e-03, -3.7000e-03, -2.7000e-03, -1.3000e-03,  1.0000e-04,
          9.0000e-04,  1.6000e-03,  2.3000e-03,  2.6000e-03,  2.8000e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.7765, 10.7770, 10.7772, 10.7771, 10.7768, 10.7774, 10.7770, 10.7768,
         10.7762, 10.7759]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0447e+01,  1.0447e+01,  1.0446e+01,  1.0447e+01,  1.0448e+01,
          1.0448e+01,  1.0449e+01,  1.0449e+01,  1.0449e+01,  1.0449e+01],
        [-1.0849e+01, -6.6217e+00, -7.3790e+00, -3.9970e+00, -3.0060e-01,
          3.2179e+00,  9.3282e+00,  1.4458e+01,  1.8501e+01,  2.0270e+01],
        [-1.2461e+01, -1.1293e+01, -1.0510e+01, -9.2076e+00, -7.4262e+00,
         -5.2974e+00, -2.3723e+00,  9.9370e-01,  4.4952e+00,  7.6502e+00],
        [ 1.6118e+00,  4.6714e+00,  3.1313e+00,  5.2106e+00,  7.1256e+00,
          8.5153e+00,  1.1700e+01,  1.3464e+01,  1.4006e+01,  1.2620e+01],
        [ 5.0618e+01,  7.8538e+01,  5.6504e+01,  6.2111e+01,  6.3556e+01,
          5.6609e+01,  6.1486e+01,  6.5042e+01,  6.7988e+01,  6.8500e+01],
        [ 1.1351e+00,  1.8773e+00,  4.8880e-01,  6.1390e-01,  6.3480e-01,
          4.6550e-01,  5.8430e-01,  6.7100e-01,  7.4280e-01,  7.5530e-01],
        [-4.7104e+01,  1.5475e+01,  2.3867e+01,  1.2601e+01,  2.7638e+00,
         -1.3775e+01, -1.9891e+01, -3.9950e+01, -3.5727e+01, -5.7324e+00],
        [-2.5000e-03, -1.6000e-03,  2.0000e-04,  4.0000e-04,  1.1000e-03,
          1.8000e-03,  2.2000e-03,  3.1000e-03,  3.8000e-03,  4.6000e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.4472, 10.4457, 10.4471, 10.4475, 10.4477, 10.4490, 10.4491, 10.4492,
         10.4488, 10.4491]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0965e+01,  1.0965e+01,  1.0965e+01,  1.0965e+01,  1.0965e+01,
          1.0966e+01,  1.0965e+01,  1.0965e+01,  1.0965e+01,  1.0966e+01],
        [ 4.6083e+01,  5.2909e+01,  5.9099e+01,  6.2249e+01,  6.6774e+01,
          7.3026e+01,  7.2039e+01,  7.3051e+01,  7.0176e+01,  7.1320e+01],
        [ 2.6061e+01,  3.1430e+01,  3.6964e+01,  4.2021e+01,  4.6972e+01,
          5.2183e+01,  5.6154e+01,  5.9533e+01,  6.1662e+01,  6.3594e+01],
        [ 2.0022e+01,  2.1479e+01,  2.2135e+01,  2.0228e+01,  1.9802e+01,
          2.0844e+01,  1.5885e+01,  1.3518e+01,  8.5144e+00,  7.7265e+00],
        [ 6.7075e+01,  6.3504e+01,  6.7538e+01,  6.0783e+01,  6.6367e+01,
          7.4876e+01,  6.9938e+01,  7.2151e+01,  6.6791e+01,  7.7939e+01],
        [ 1.0062e+00,  8.2520e-01,  1.0227e+00,  6.7660e-01,  9.4390e-01,
          1.3512e+00,  8.2510e-01,  9.0350e-01,  7.1360e-01,  1.1085e+00],
        [ 4.7272e+01, -1.4695e+01, -5.1028e+01, -6.8407e+01, -5.3199e+01,
         -1.3905e+02, -8.6955e+01, -2.3623e+01, -5.1286e+00,  6.5744e+01],
        [ 2.6000e-03,  3.3000e-03,  3.8000e-03,  4.7000e-03,  5.1000e-03,
          5.8000e-03,  6.8000e-03,  7.4000e-03,  7.9000e-03,  7.7000e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.9646, 10.9649, 10.9647, 10.9653, 10.9660, 10.9649, 10.9655, 10.9649,
         10.9658, 10.9650]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0581e+01,  1.0581e+01,  1.0580e+01,  1.0580e+01,  1.0580e+01,
          1.0580e+01,  1.0581e+01,  1.0582e+01,  1.0582e+01,  1.0583e+01],
        [ 2.7808e+00, -1.8142e+00, -6.6475e+00, -9.8856e+00, -1.3430e+01,
         -1.7260e+01, -1.5955e+01, -1.2420e+01, -9.6011e+00, -2.1442e+00],
        [-2.1939e+00, -2.1180e+00, -3.0239e+00, -4.3962e+00, -6.2030e+00,
         -8.4143e+00, -9.9226e+00, -1.0422e+01, -1.0258e+01, -8.6352e+00],
        [ 4.9747e+00,  3.0380e-01, -3.6237e+00, -5.4893e+00, -7.2269e+00,
         -8.8455e+00, -6.0330e+00, -1.9980e+00,  6.5670e-01,  6.4909e+00],
        [ 5.7682e+01,  5.7594e+01,  5.3754e+01,  5.2040e+01,  4.2115e+01,
          3.7117e+01,  3.6995e+01,  4.3839e+01,  3.8614e+01,  4.7091e+01],
        [ 6.9250e-01,  6.8970e-01,  4.8190e-01,  3.0520e-01, -6.4610e-01,
         -1.9760e-01, -4.0000e-03,  2.2510e-01,  5.3200e-02,  3.3200e-01],
        [ 1.4041e+01,  3.9595e+01,  9.4786e+01,  6.9939e+01,  1.0534e+02,
          1.0875e+02,  2.2583e+01,  4.7954e+01,  7.1009e+01,  2.6592e+01],
        [ 5.9000e-03,  5.4000e-03,  4.7000e-03,  3.6000e-03,  2.3000e-03,
          8.0000e-04, -1.0000e-03, -2.3000e-03, -2.6000e-03, -3.1000e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.5806, 10.5802, 10.5804, 10.5800, 10.5796, 10.5809, 10.5817, 10.5816,
         10.5833, 10.5827]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0477e+01,  1.0477e+01,  1.0477e+01,  1.0475e+01,  1.0476e+01,
          1.0476e+01,  1.0476e+01,  1.0474e+01,  1.0475e+01,  1.0475e+01],
        [-2.9397e+01, -3.1521e+01, -3.2095e+01, -3.8255e+01, -4.0013e+01,
         -4.0581e+01, -4.0319e+01, -4.5281e+01, -4.5944e+01, -4.7526e+01],
        [-3.2771e+01, -3.2521e+01, -3.2436e+01, -3.3600e+01, -3.4883e+01,
         -3.6022e+01, -3.6882e+01, -3.8562e+01, -4.0038e+01, -4.1536e+01],
        [ 3.3748e+00,  1.0001e+00,  3.4100e-01, -4.6547e+00, -5.1308e+00,
         -4.5589e+00, -3.4378e+00, -6.7197e+00, -5.9056e+00, -5.9902e+00],
        [ 3.9120e+01,  4.7422e+01,  4.3647e+01,  3.6203e+01,  4.0565e+01,
          3.6036e+01,  3.1407e+01,  2.0703e+01,  2.6973e+01,  2.5946e+01],
        [ 7.8000e-03,  3.8820e-01,  2.1520e-01, -1.2590e-01,  1.7750e-01,
         -6.8000e-03, -1.8710e-01, -3.6450e-01,  1.5650e-01,  1.4280e-01],
        [-3.5179e+01, -6.1262e+00,  1.8546e+01,  3.9150e+01,  5.1752e+01,
          5.2106e+01,  6.7521e+01,  1.9321e+01,  1.0636e+01,  1.6102e+01],
        [ 1.0000e-04, -4.0000e-04, -6.0000e-04, -1.0000e-03, -2.1000e-03,
         -2.8000e-03, -3.6000e-03, -4.3000e-03, -5.7000e-03, -6.3000e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.4771, 10.4774, 10.4752, 10.4762, 10.4763, 10.4764, 10.4744, 10.4754,
         10.4748, 10.4755]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0781e+01,  1.0782e+01,  1.0782e+01,  1.0782e+01,  1.0783e+01,
          1.0783e+01,  1.0783e+01,  1.0783e+01,  1.0782e+01,  1.0783e+01],
        [-9.9620e+00, -8.0512e+00, -7.0169e+00, -3.3544e+00,  9.3250e-01,
          5.3264e+00,  8.4673e+00,  1.1673e+01,  1.0334e+01,  1.0177e+01],
        [-1.0635e+01, -1.0118e+01, -9.4982e+00, -8.2694e+00, -6.4290e+00,
         -4.0779e+00, -1.5689e+00,  1.0795e+00,  2.9304e+00,  4.3798e+00],
        [ 6.7330e-01,  2.0673e+00,  2.4813e+00,  4.9150e+00,  7.3616e+00,
          9.4044e+00,  1.0036e+01,  1.0594e+01,  7.4034e+00,  5.7975e+00],
        [ 4.5930e+01,  4.8538e+01,  4.4813e+01,  5.1744e+01,  6.0483e+01,
          6.8246e+01,  7.1416e+01,  7.5544e+01,  5.5754e+01,  6.3607e+01],
        [ 3.2610e-01,  4.2490e-01,  2.8370e-01,  5.4640e-01,  1.4265e+00,
          1.3352e+00,  1.1025e+00,  1.1266e+00,  3.9930e-01,  6.3770e-01],
        [ 1.0551e+01, -3.8719e+00, -1.5130e+01, -2.1116e+01,  1.2100e+00,
         -1.9575e+01, -2.2542e+01, -2.8497e+01, -1.9192e+01, -1.5619e+01],
        [-8.0000e-04, -9.0000e-04, -8.0000e-04, -7.0000e-04, -3.0000e-04,
          2.0000e-04,  7.0000e-04,  1.3000e-03,  1.9000e-03,  2.0000e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.7819, 10.7817, 10.7824, 10.7828, 10.7831, 10.7830, 10.7832, 10.7823,
         10.7825, 10.7824]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0473e+01,  1.0473e+01,  1.0472e+01,  1.0472e+01,  1.0472e+01,
          1.0472e+01,  1.0475e+01,  1.0473e+01,  1.0472e+01,  1.0473e+01],
        [ 2.5783e+01,  2.2057e+01,  1.6974e+01,  1.2644e+01,  7.5089e+00,
          5.1167e+00,  1.1180e+01,  8.7500e+00,  3.9242e+00,  3.2696e+00],
        [ 2.7918e+01,  2.6746e+01,  2.4791e+01,  2.2362e+01,  1.9391e+01,
          1.6536e+01,  1.5465e+01,  1.4122e+01,  1.2083e+01,  1.0320e+01],
        [-2.1347e+00, -4.6883e+00, -7.8172e+00, -9.7178e+00, -1.1882e+01,
         -1.1420e+01, -4.2853e+00, -5.3721e+00, -8.1583e+00, -7.0503e+00],
        [ 4.4001e+01,  4.7549e+01,  3.9355e+01,  3.6399e+01,  3.7473e+01,
          4.1736e+01,  5.6926e+01,  4.5461e+01,  4.5873e+01,  4.7336e+01],
        [-5.0570e-01,  1.0290e-01, -1.3470e-01, -7.8300e-02,  2.6800e-02,
          1.3490e-01,  5.1860e-01,  2.3190e-01,  2.9520e-01,  3.4080e-01],
        [ 3.1878e+01,  2.3960e+01,  4.1495e+00,  1.5871e+01, -2.6983e+01,
         -8.3190e-01,  2.1113e+01, -8.4000e-01,  3.1397e+01,  5.8121e+01],
        [ 3.6000e-03,  2.1000e-03,  1.2000e-03,  0.0000e+00, -1.0000e-03,
         -1.9000e-03, -2.2000e-03, -1.4000e-03, -1.8000e-03, -2.1000e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.4730, 10.4723, 10.4723, 10.4717, 10.4723, 10.4752, 10.4727, 10.4717,
         10.4728, 10.4725]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0524e+01,  1.0528e+01,  1.0525e+01,  1.0523e+01,  1.0523e+01,
          1.0529e+01,  1.0529e+01,  1.0527e+01,  1.0527e+01,  1.0526e+01],
        [ 1.0210e+01,  2.3095e+01,  2.5002e+01,  2.1296e+01,  1.8682e+01,
          3.1669e+01,  4.2529e+01,  4.4530e+01,  4.5833e+01,  4.3916e+01],
        [ 7.0572e+00,  1.0265e+01,  1.3212e+01,  1.4829e+01,  1.5599e+01,
          1.8813e+01,  2.3556e+01,  2.7751e+01,  3.1368e+01,  3.3877e+01],
        [ 3.1524e+00,  1.2831e+01,  1.1790e+01,  6.4668e+00,  3.0821e+00,
          1.2856e+01,  1.8973e+01,  1.6778e+01,  1.4465e+01,  1.0039e+01],
        [ 4.5851e+01,  5.5083e+01,  4.7273e+01,  5.1569e+01,  5.3141e+01,
          6.8886e+01,  6.9003e+01,  6.3527e+01,  6.5970e+01,  6.0609e+01],
        [ 4.8760e-01,  7.9660e-01,  5.3520e-01,  8.5230e-01,  9.1840e-01,
          1.5799e+00,  1.0031e+00,  8.5480e-01,  9.1670e-01,  7.3960e-01],
        [-4.4562e+01, -1.2071e+02, -1.1584e+02, -1.1735e+02, -1.4628e+02,
         -7.2967e+01, -7.2062e+00,  3.8582e+01, -2.9019e+01, -1.3971e+00],
        [-4.5000e-03, -3.4000e-03, -1.2000e-03,  2.0000e-04,  1.3000e-03,
          2.2000e-03,  5.4000e-03,  7.8000e-03,  8.8000e-03,  9.5000e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.5276, 10.5249, 10.5232, 10.5234, 10.5285, 10.5289, 10.5269, 10.5270,
         10.5261, 10.5270]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.1009e+01,  1.1009e+01,  1.1009e+01,  1.1010e+01,  1.1010e+01,
          1.1009e+01,  1.1008e+01,  1.1008e+01,  1.1009e+01,  1.1009e+01],
        [-2.2363e+00, -6.0020e-01,  1.9513e+00,  8.9250e+00,  1.4208e+01,
          1.3739e+01,  9.1111e+00,  5.0306e+00,  5.0063e+00,  4.4140e+00],
        [-3.1448e+00, -2.6358e+00, -1.7184e+00,  4.1030e-01,  3.1698e+00,
          5.2836e+00,  6.0491e+00,  5.8454e+00,  5.6776e+00,  5.4249e+00],
        [ 9.0840e-01,  2.0357e+00,  3.6697e+00,  8.5148e+00,  1.1038e+01,
          8.4552e+00,  3.0620e+00, -8.1480e-01, -6.7130e-01, -1.0109e+00],
        [ 5.7313e+01,  5.3548e+01,  5.0803e+01,  6.2083e+01,  5.8667e+01,
          4.9638e+01,  4.6747e+01,  4.9433e+01,  5.9639e+01,  5.9536e+01],
        [ 7.3700e-01,  6.3890e-01,  5.6750e-01,  8.6120e-01,  7.7220e-01,
          5.3710e-01,  5.3640e-01,  6.1760e-01,  9.2610e-01,  9.2300e-01],
        [ 3.8081e+01,  3.4118e+01,  4.2986e+00, -1.9465e+01, -5.5860e+01,
         -6.5271e+01, -6.8038e+01, -2.7239e+01, -3.2813e+01,  4.8652e+00],
        [-1.1000e-03, -8.0000e-04, -7.0000e-04, -5.0000e-04,  1.0000e-04,
          7.0000e-04,  1.0000e-03,  1.0000e-03,  1.0000e-03,  1.2000e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[11.0087, 11.0090, 11.0100, 11.0100, 11.0091, 11.0083, 11.0082, 11.0089,
         11.0087, 11.0081]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0571e+01,  1.0572e+01,  1.0571e+01,  1.0572e+01,  1.0572e+01,
          1.0570e+01,  1.0568e+01,  1.0569e+01,  1.0568e+01,  1.0567e+01],
        [-1.0003e+02, -9.4790e+01, -9.1678e+01, -8.6084e+01, -8.1471e+01,
         -8.3032e+01, -8.9523e+01, -9.1266e+01, -9.3160e+01, -9.7947e+01],
        [-1.0328e+02, -1.0158e+02, -9.9600e+01, -9.6897e+01, -9.3812e+01,
         -9.1656e+01, -9.1229e+01, -9.1237e+01, -9.1621e+01, -9.2886e+01],
        [ 3.2524e+00,  6.7902e+00,  7.9216e+00,  1.0813e+01,  1.2340e+01,
          8.6235e+00,  1.7060e+00, -2.9100e-02, -1.5386e+00, -5.0609e+00],
        [ 3.6442e+01,  4.0813e+01,  3.8173e+01,  4.1172e+01,  4.4164e+01,
          4.3013e+01,  3.9400e+01,  4.3003e+01,  3.1679e+01,  3.3071e+01],
        [ 9.3960e-01,  1.0754e+00,  9.2380e-01,  1.0104e+00,  1.0855e+00,
          9.6970e-01,  8.7460e-01,  9.6940e-01,  3.9680e-01,  4.6400e-01],
        [-4.7740e+01, -8.4075e+01, -8.6155e+01, -9.0148e+01,  2.6577e+01,
         -4.5516e+01, -1.5180e+01, -4.6737e+01,  3.9689e+01, -3.7120e+01],
        [-1.0500e-02, -9.7000e-03, -8.5000e-03, -7.4000e-03, -6.3000e-03,
         -5.2000e-03, -5.1000e-03, -5.4000e-03, -5.5000e-03, -6.1000e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.5721, 10.5714, 10.5721, 10.5719, 10.5699, 10.5679, 10.5687, 10.5681,
         10.5667, 10.5658]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0455e+01,  1.0456e+01,  1.0455e+01,  1.0456e+01,  1.0456e+01,
          1.0457e+01,  1.0456e+01,  1.0456e+01,  1.0457e+01,  1.0457e+01],
        [ 3.1388e+00,  5.2059e+00,  4.0777e+00,  7.0738e+00,  1.0187e+01,
          1.3202e+01,  1.4267e+01,  1.4404e+01,  1.6167e+01,  1.8175e+01],
        [-6.8222e+00, -4.4166e+00, -2.7177e+00, -7.5940e-01,  1.4298e+00,
          3.7843e+00,  5.8809e+00,  7.5856e+00,  9.3019e+00,  1.1076e+01],
        [ 9.9610e+00,  9.6225e+00,  6.7955e+00,  7.8332e+00,  8.7570e+00,
          9.4179e+00,  8.3862e+00,  6.8188e+00,  6.8654e+00,  7.0983e+00],
        [ 6.5213e+01,  6.7122e+01,  6.3104e+01,  6.8754e+01,  6.8578e+01,
          7.4812e+01,  7.0957e+01,  6.7097e+01,  6.5303e+01,  6.6826e+01],
        [ 9.3120e-01,  9.8240e-01,  8.7470e-01,  1.0262e+00,  9.9540e-01,
          1.1584e+00,  9.1300e-01,  8.2590e-01,  6.5630e-01,  7.1130e-01],
        [-2.2944e+01, -4.0895e+01, -4.3287e+01, -2.6137e+01,  6.8876e+00,
          3.2752e+00,  3.6197e+01,  2.6808e+01,  2.5160e+01,  2.5287e+01],
        [ 1.7000e-03,  2.3000e-03,  2.8000e-03,  3.1000e-03,  3.8000e-03,
          4.2000e-03,  4.6000e-03,  4.7000e-03,  4.4000e-03,  4.3000e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.4557, 10.4548, 10.4562, 10.4565, 10.4567, 10.4563, 10.4561, 10.4568,
         10.4571, 10.4572]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal
  0%|          | 0/350 [00:02<?, ?it/s]
Traceback (most recent call last):
  File "C:\Users\dadou\Documents\Github\Advanced-Programming\Strategies\Transformer_strategy.py", line 417, in <module>
    trainer.train()
  File "C:\Users\dadou\Documents\Github\Advanced-Programming\utils\trainer.py", line 106, in train
    total_norm = log_gradient_norms(self.model)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\dadou\Documents\Github\Advanced-Programming\utils\utils.py", line 58, in log_gradient_norms
    total_norm += param_norm.item() ** 2
                  ^^^^^^^^^^^^^^^^^
signal tensor([[ 1.1110e+01,  1.1109e+01,  1.1110e+01,  1.1109e+01,  1.1110e+01,
          1.1110e+01,  1.1110e+01,  1.1110e+01,  1.1110e+01,  1.1110e+01],
        [-5.6172e+01, -5.3879e+01, -4.9779e+01, -4.7914e+01, -4.1821e+01,
         -3.8885e+01, -3.5916e+01, -3.2221e+01, -3.0677e+01, -2.6961e+01],
        [-7.2378e+01, -6.8678e+01, -6.4899e+01, -6.1502e+01, -5.7566e+01,
         -5.3829e+01, -5.0247e+01, -4.6642e+01, -4.3449e+01, -4.0151e+01],
        [ 1.6206e+01,  1.4800e+01,  1.5120e+01,  1.3587e+01,  1.5744e+01,
          1.4945e+01,  1.4330e+01,  1.4421e+01,  1.2772e+01,  1.3190e+01],
        [ 6.4930e+01,  5.9650e+01,  5.5413e+01,  5.0227e+01,  4.8428e+01,
          5.8134e+01,  5.6380e+01,  6.0066e+01,  4.9494e+01,  5.2075e+01],
        [ 1.5403e+00,  8.6380e-01,  7.5460e-01,  6.2090e-01,  5.7450e-01,
          8.2470e-01,  7.7950e-01,  8.6630e-01,  5.3080e-01,  5.7970e-01],
        [ 1.6804e+01, -7.2609e+01, -4.3186e+01, -4.5581e+01,  1.0233e+01,
          2.3137e+01,  4.0092e+01,  1.6337e+01,  1.1696e+01, -1.2687e+01],
        [-2.2000e-03, -1.0000e-03, -3.0000e-04,  3.0000e-04,  6.0000e-04,
          8.0000e-04,  9.0000e-04,  9.0000e-04,  9.0000e-04,  7.0000e-04]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[11.1093, 11.1096, 11.1093, 11.1101, 11.1096, 11.1097, 11.1098, 11.1095,
         11.1099, 11.1098]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0840e+01,  1.0839e+01,  1.0840e+01,  1.0838e+01,  1.0838e+01,
          1.0838e+01,  1.0837e+01,  1.0839e+01,  1.0838e+01,  1.0838e+01],
        [ 1.1081e+01,  5.2236e+00,  1.9470e+00, -6.2391e+00, -1.2042e+01,
         -1.6424e+01, -2.3367e+01, -2.3822e+01, -2.4969e+01, -2.6154e+01],
        [ 1.6345e+01,  1.4120e+01,  1.1686e+01,  8.1008e+00,  4.0723e+00,
         -2.7000e-02, -4.6950e+00, -8.5204e+00, -1.1810e+01, -1.4679e+01],
        [-5.2636e+00, -8.8968e+00, -9.7387e+00, -1.4340e+01, -1.6114e+01,
         -1.6397e+01, -1.8672e+01, -1.5302e+01, -1.3159e+01, -1.1475e+01],
        [ 3.6244e+01,  3.5591e+01,  3.8246e+01,  3.1665e+01,  3.6848e+01,
          3.8878e+01,  3.7559e+01,  4.3017e+01,  3.9417e+01,  2.8254e+01],
        [-2.6320e-01, -1.7300e-02,  7.1500e-02, -1.0570e-01,  1.5020e-01,
          2.3810e-01,  2.1650e-01,  4.1700e-01,  2.8480e-01, -1.2530e-01],
        [-9.6480e-01, -2.6574e+01, -5.5450e+01, -3.5783e+01, -1.2437e+01,
          6.0973e+01,  4.8640e+01,  3.1675e+01, -5.2176e+00,  3.2301e+01],
        [-2.0000e-04, -9.0000e-04, -1.6000e-03, -1.9000e-03, -2.6000e-03,
         -3.0000e-03, -3.3000e-03, -4.0000e-03, -4.1000e-03, -4.2000e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.8392, 10.8395, 10.8381, 10.8383, 10.8383, 10.8374, 10.8385, 10.8383,
         10.8381, 10.8386]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0932e+01,  1.0931e+01,  1.0931e+01,  1.0930e+01,  1.0931e+01,
          1.0931e+01,  1.0930e+01,  1.0929e+01,  1.0930e+01,  1.0929e+01],
        [-5.9805e+01, -7.3215e+01, -8.3281e+01, -9.3508e+01, -9.5760e+01,
         -9.6817e+01, -1.0125e+02, -1.0949e+02, -1.1009e+02, -1.1092e+02],
        [-1.7982e+01, -2.9028e+01, -3.9879e+01, -5.0605e+01, -5.9636e+01,
         -6.7072e+01, -7.3908e+01, -8.1024e+01, -8.6839e+01, -9.1654e+01],
        [-4.1823e+01, -4.4186e+01, -4.3402e+01, -4.2903e+01, -3.6124e+01,
         -2.9744e+01, -2.7344e+01, -2.8466e+01, -2.3256e+01, -1.9263e+01],
        [ 2.3092e+01,  2.0624e+01,  2.0283e+01,  2.1611e+01,  2.5503e+01,
          2.5805e+01,  2.2148e+01,  2.2465e+01,  2.8576e+01,  1.8925e+01],
        [-1.5210e-01, -6.2500e-02, -8.1000e-03,  3.5000e-02,  1.3750e-01,
          1.4540e-01,  4.9100e-02,  5.7400e-02,  2.4450e-01, -4.0000e-02],
        [ 7.6479e+01,  7.0055e+01,  1.0313e+02,  3.4095e+01,  2.2813e+01,
          1.3462e+02, -2.8128e+01, -5.7685e+01, -1.3121e+02, -8.7389e+01],
        [-6.4000e-03, -8.0000e-03, -9.9000e-03, -1.1500e-02, -1.2900e-02,
         -1.3300e-02, -1.3400e-02, -1.4100e-02, -1.4100e-02, -1.3500e-02]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.9308, 10.9307, 10.9299, 10.9310, 10.9309, 10.9298, 10.9285, 10.9295,
         10.9292, 10.9298]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0609e+01,  1.0611e+01,  1.0609e+01,  1.0610e+01,  1.0611e+01,
          1.0611e+01,  1.0612e+01,  1.0611e+01,  1.0613e+01,  1.0613e+01],
        [-8.9893e+01, -8.2335e+01, -8.2548e+01, -7.7149e+01, -6.9580e+01,
         -6.1865e+01, -5.1262e+01, -4.4996e+01, -3.5851e+01, -2.7769e+01],
        [-7.2955e+01, -7.4831e+01, -7.6374e+01, -7.6529e+01, -7.5139e+01,
         -7.2485e+01, -6.8240e+01, -6.3591e+01, -5.8043e+01, -5.1988e+01],
        [-1.6938e+01, -7.5040e+00, -6.1735e+00, -6.2010e-01,  5.5590e+00,
          1.0620e+01,  1.6978e+01,  1.8595e+01,  2.2192e+01,  2.4219e+01],
        [ 3.4757e+01,  4.5400e+01,  3.5617e+01,  3.3786e+01,  4.2348e+01,
          4.7655e+01,  5.1583e+01,  5.1513e+01,  5.6987e+01,  5.4693e+01],
        [ 6.6060e-01,  1.1950e+00,  5.7980e-01,  5.0120e-01,  8.6890e-01,
          1.0968e+00,  1.1538e+00,  9.9760e-01,  1.1834e+00,  9.3380e-01],
        [-1.7172e+01, -5.0640e+01, -2.9839e+01, -4.0635e+01, -4.3971e+01,
          8.6300e+00, -5.5613e+01, -8.3221e+01, -9.7268e+01, -1.1969e+02],
        [-1.2700e-02, -1.2300e-02, -1.0600e-02, -9.8000e-03, -9.0000e-03,
         -7.5000e-03, -5.9000e-03, -4.2000e-03, -2.6000e-03, -6.0000e-04]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.6107, 10.6085, 10.6100, 10.6107, 10.6110, 10.6122, 10.6114, 10.6126,
         10.6127, 10.6121]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0794e+01,  1.0793e+01,  1.0794e+01,  1.0795e+01,  1.0795e+01,
          1.0795e+01,  1.0795e+01,  1.0795e+01,  1.0795e+01,  1.0796e+01],
        [-3.7195e+01, -3.8617e+01, -3.5940e+01, -2.8958e+01, -2.4518e+01,
         -1.9399e+01, -1.6311e+01, -1.2636e+01, -1.0336e+01, -7.2940e+00],
        [-2.3476e+01, -2.6505e+01, -2.8392e+01, -2.8505e+01, -2.7708e+01,
         -2.6046e+01, -2.4099e+01, -2.1806e+01, -1.9512e+01, -1.7069e+01],
        [-1.3719e+01, -1.2113e+01, -7.5483e+00, -4.5280e-01,  3.1894e+00,
          6.6470e+00,  7.7881e+00,  9.1705e+00,  9.1762e+00,  9.7746e+00],
        [ 2.3779e+01,  1.9260e+01,  3.0930e+01,  4.2365e+01,  4.1653e+01,
          4.8104e+01,  5.5707e+01,  5.6215e+01,  5.3207e+01,  5.7100e+01],
        [-4.1800e-02, -1.3270e-01,  3.3920e-01,  6.7150e-01,  6.5080e-01,
          9.2290e-01,  1.2636e+00,  1.0139e+00,  9.1860e-01,  1.0240e+00],
        [ 2.8939e+01,  7.4330e-01, -5.7491e+01, -4.0504e+01, -2.7094e+01,
         -3.6034e+01, -8.6202e+01, -8.9700e+01, -9.7676e+01, -3.8472e+01],
        [-6.4000e-03, -6.7000e-03, -7.1000e-03, -6.7000e-03, -5.5000e-03,
         -4.6000e-03, -3.5000e-03, -2.4000e-03, -1.1000e-03, -1.0000e-04]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.7934, 10.7943, 10.7954, 10.7951, 10.7954, 10.7951, 10.7954, 10.7952,
         10.7955, 10.7951]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0433e+01,  1.0433e+01,  1.0433e+01,  1.0432e+01,  1.0433e+01,
          1.0433e+01,  1.0431e+01,  1.0432e+01,  1.0433e+01,  1.0433e+01],
        [ 1.0760e+01,  1.5029e+01,  1.7413e+01,  1.7187e+01,  1.9086e+01,
          1.9577e+01,  1.5347e+01,  1.4668e+01,  1.6524e+01,  1.6395e+01],
        [-4.7950e-01,  2.6223e+00,  5.5804e+00,  7.9017e+00,  1.0139e+01,
          1.2026e+01,  1.2690e+01,  1.3086e+01,  1.3774e+01,  1.4298e+01],
        [ 1.1239e+01,  1.2407e+01,  1.1833e+01,  9.2852e+00,  8.9472e+00,
          7.5505e+00,  2.6564e+00,  1.5822e+00,  2.7508e+00,  2.0973e+00],
        [ 6.1938e+01,  6.1537e+01,  5.6555e+01,  5.2029e+01,  6.0337e+01,
          6.2776e+01,  4.8633e+01,  6.4302e+01,  6.8814e+01,  6.0868e+01],
        [ 9.6330e-01,  9.4670e-01,  7.4030e-01,  5.5280e-01,  8.9700e-01,
          9.9800e-01,  4.1210e-01,  1.0613e+00,  1.1761e+00,  6.5080e-01],
        [-1.4436e+01, -4.3581e+01,  2.4580e+01, -6.2737e+01, -7.5554e+01,
         -2.5249e+01,  3.7395e+01,  6.7595e+00,  2.5749e+01,  1.9453e+01],
        [ 1.7000e-03,  2.6000e-03,  3.7000e-03,  4.3000e-03,  4.1000e-03,
          4.8000e-03,  5.4000e-03,  4.5000e-03,  4.3000e-03,  4.5000e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.4334, 10.4331, 10.4324, 10.4333, 10.4330, 10.4314, 10.4324, 10.4333,
         10.4328, 10.4338]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0661e+01,  1.0663e+01,  1.0664e+01,  1.0667e+01,  1.0668e+01,
          1.0670e+01,  1.0671e+01,  1.0671e+01,  1.0671e+01,  1.0672e+01],
        [-6.2378e+00,  7.7680e-01,  9.3901e+00,  2.8160e+01,  4.7062e+01,
          6.5529e+01,  8.3255e+01,  9.7390e+01,  1.0729e+02,  1.1658e+02],
        [ 1.7114e+00,  1.5245e+00,  3.0976e+00,  8.1101e+00,  1.5901e+01,
          2.5826e+01,  3.7312e+01,  4.9327e+01,  6.0920e+01,  7.2052e+01],
        [-7.9493e+00, -7.4770e-01,  6.2924e+00,  2.0050e+01,  3.1162e+01,
          3.9703e+01,  4.5943e+01,  4.8062e+01,  4.6371e+01,  4.4528e+01],
        [ 4.1302e+01,  4.2395e+01,  5.3723e+01,  6.5047e+01,  6.8716e+01,
          7.3242e+01,  7.6369e+01,  8.1355e+01,  8.0865e+01,  8.7674e+01],
        [ 2.6510e-01,  3.0830e-01,  9.6830e-01,  1.5677e+00,  1.1205e+00,
          1.1326e+00,  1.0809e+00,  1.1194e+00,  9.8950e-01,  1.1351e+00],
        [ 2.0266e+01, -1.2481e+01, -3.2546e+01, -8.0443e+01, -7.1825e+01,
         -1.3958e+02, -7.4314e+01, -9.2453e+01, -1.9603e+02, -1.0752e+02],
        [-4.5000e-03, -4.6000e-03, -4.1000e-03, -2.8000e-03, -1.0000e-04,
          3.0000e-03,  6.4000e-03,  1.0000e-02,  1.3100e-02,  1.5700e-02]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.6626, 10.6636, 10.6671, 10.6684, 10.6696, 10.6708, 10.6712, 10.6711,
         10.6719, 10.6723]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0362e+01,  1.0360e+01,  1.0361e+01,  1.0359e+01,  1.0359e+01,
          1.0362e+01,  1.0358e+01,  1.0358e+01,  1.0359e+01,  1.0361e+01],
        [ 1.0946e+02,  1.1036e+02,  1.1103e+02,  1.0484e+02,  1.0062e+02,
          1.0267e+02,  9.2578e+01,  8.4597e+01,  7.9199e+01,  7.8921e+01],
        [ 7.8695e+01,  8.5029e+01,  9.0228e+01,  9.3151e+01,  9.4645e+01,
          9.6250e+01,  9.5515e+01,  9.3332e+01,  9.0505e+01,  8.8188e+01],
        [ 3.0768e+01,  2.5334e+01,  2.0798e+01,  1.1693e+01,  5.9739e+00,
          6.4202e+00, -2.9374e+00, -8.7344e+00, -1.1307e+01, -9.2677e+00],
        [ 7.0206e+01,  6.3789e+01,  6.7663e+01,  7.1142e+01,  7.1145e+01,
          7.1269e+01,  6.3350e+01,  6.2516e+01,  6.4688e+01,  6.4695e+01],
        [ 8.0060e-01,  5.8730e-01,  7.1600e-01,  8.3170e-01,  8.3030e-01,
          8.1020e-01,  5.0580e-01,  4.7380e-01,  5.5720e-01,  3.8640e-01],
        [-9.3144e+01, -3.2062e+01, -8.7561e+01, -7.2869e+01, -1.0111e+02,
         -5.5757e+01,  7.7746e+01,  7.7917e+01,  1.4239e+02,  1.9861e+02],
        [ 1.3500e-02,  1.6000e-02,  1.7000e-02,  1.7700e-02,  1.8200e-02,
          1.8400e-02,  1.8900e-02,  1.7600e-02,  1.5400e-02,  1.3700e-02]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.3603, 10.3608, 10.3587, 10.3594, 10.3620, 10.3578, 10.3582, 10.3589,
         10.3608, 10.3563]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0783e+01,  1.0784e+01,  1.0784e+01,  1.0784e+01,  1.0785e+01,
          1.0785e+01,  1.0784e+01,  1.0784e+01,  1.0785e+01,  1.0785e+01],
        [-3.2402e+01, -2.9268e+01, -2.7292e+01, -2.3406e+01, -1.9202e+01,
         -1.4710e+01, -1.3250e+01, -1.2039e+01, -8.2265e+00, -6.4473e+00],
        [-2.2996e+01, -2.4250e+01, -2.4858e+01, -2.4568e+01, -2.3495e+01,
         -2.1738e+01, -2.0040e+01, -1.8440e+01, -1.6397e+01, -1.4407e+01],
        [-9.4068e+00, -5.0182e+00, -2.4337e+00,  1.1621e+00,  4.2924e+00,
          7.0279e+00,  6.7904e+00,  6.4007e+00,  8.1709e+00,  7.9601e+00],
        [ 3.9086e+01,  4.4733e+01,  3.1477e+01,  3.8364e+01,  4.4132e+01,
          4.2773e+01,  4.3388e+01,  4.5862e+01,  6.3312e+01,  6.4788e+01],
        [ 6.4900e-01,  9.8910e-01, -4.1500e-02,  5.1410e-01,  9.5460e-01,
          8.5210e-01,  8.9850e-01,  1.0852e+00,  2.2130e+00,  1.0464e+00],
        [ 3.1595e+01,  5.7708e+01,  2.9824e+01,  1.5456e+01, -3.4824e+01,
         -5.4728e+01, -5.3923e+01, -6.7442e+01, -6.3069e+01, -4.1040e+01],
        [-3.3000e-03, -3.5000e-03, -3.3000e-03, -3.4000e-03, -3.2000e-03,
         -2.7000e-03, -2.1000e-03, -1.6000e-03, -1.0000e-03, -1.0000e-04]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.7840, 10.7837, 10.7843, 10.7845, 10.7848, 10.7842, 10.7842, 10.7849,
         10.7845, 10.7839]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0918e+01,  1.0918e+01,  1.0917e+01,  1.0918e+01,  1.0918e+01,
          1.0918e+01,  1.0918e+01,  1.0919e+01,  1.0918e+01,  1.0919e+01],
        [ 2.9573e+01,  2.7396e+01,  2.1681e+01,  2.1180e+01,  2.0340e+01,
          2.1125e+01,  2.2292e+01,  2.4628e+01,  2.1445e+01,  2.3256e+01],
        [ 4.0169e+01,  3.7614e+01,  3.4428e+01,  3.1778e+01,  2.9490e+01,
          2.7817e+01,  2.6712e+01,  2.6295e+01,  2.5326e+01,  2.4912e+01],
        [-1.0596e+01, -1.0218e+01, -1.2747e+01, -1.0598e+01, -9.1508e+00,
         -6.6924e+00, -4.4200e+00, -1.6673e+00, -3.8800e+00, -1.6555e+00],
        [ 4.2179e+01,  3.4663e+01,  2.9715e+01,  4.1757e+01,  3.8372e+01,
          4.6280e+01,  5.9680e+01,  6.3669e+01,  5.2844e+01,  5.6697e+01],
        [ 4.4000e-02, -1.6780e-01, -1.1940e-01,  2.5960e-01,  1.8660e-01,
          4.1610e-01,  1.0424e+00,  1.1331e+00,  6.8120e-01,  7.9470e-01],
        [ 7.5332e+01,  4.0971e+01, -2.3330e+01, -2.7091e+01, -3.3123e+01,
         -1.0186e+01, -3.0351e+01, -4.6963e+01, -2.7319e+01, -3.7371e+00],
        [-1.0000e-04, -6.0000e-04, -1.1000e-03, -1.8000e-03, -1.7000e-03,
         -1.7000e-03, -1.4000e-03, -9.0000e-04, -2.0000e-04,  2.0000e-04]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.9177, 10.9169, 10.9179, 10.9178, 10.9182, 10.9184, 10.9188, 10.9177,
         10.9187, 10.9160]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0447e+01,  1.0446e+01,  1.0447e+01,  1.0448e+01,  1.0448e+01,
          1.0449e+01,  1.0449e+01,  1.0449e+01,  1.0449e+01,  1.0449e+01],
        [-6.6217e+00, -7.3790e+00, -3.9970e+00, -3.0060e-01,  3.2179e+00,
          9.3282e+00,  1.4458e+01,  1.8501e+01,  2.0270e+01,  2.2389e+01],
        [-1.1293e+01, -1.0510e+01, -9.2076e+00, -7.4262e+00, -5.2974e+00,
         -2.3723e+00,  9.9370e-01,  4.4952e+00,  7.6502e+00,  1.0598e+01],
        [ 4.6714e+00,  3.1313e+00,  5.2106e+00,  7.1256e+00,  8.5153e+00,
          1.1700e+01,  1.3464e+01,  1.4006e+01,  1.2620e+01,  1.1791e+01],
        [ 7.8538e+01,  5.6504e+01,  6.2111e+01,  6.3556e+01,  5.6609e+01,
          6.1486e+01,  6.5042e+01,  6.7988e+01,  6.8500e+01,  7.1532e+01],
        [ 1.8773e+00,  4.8880e-01,  6.1390e-01,  6.3480e-01,  4.6550e-01,
          5.8430e-01,  6.7100e-01,  7.4280e-01,  7.5530e-01,  8.2920e-01],
        [ 1.5475e+01,  2.3867e+01,  1.2601e+01,  2.7638e+00, -1.3775e+01,
         -1.9891e+01, -3.9950e+01, -3.5727e+01, -5.7324e+00, -3.9052e+00],
        [-1.6000e-03,  2.0000e-04,  4.0000e-04,  1.1000e-03,  1.8000e-03,
          2.2000e-03,  3.1000e-03,  3.8000e-03,  4.6000e-03,  5.2000e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.4457, 10.4471, 10.4475, 10.4477, 10.4490, 10.4491, 10.4492, 10.4488,
         10.4491, 10.4493]])
signal tensor([[ 1.1110e+01,  1.1109e+01,  1.1110e+01,  1.1109e+01,  1.1110e+01,
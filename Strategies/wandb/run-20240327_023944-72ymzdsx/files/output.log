  0%|          | 0/350 [00:00<?, ?it/s]C:\Users\dadou\anaconda3\envs\Advanced-Programming\Lib\site-packages\torch\nn\functional.py:5476: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\aten\src\ATen\native\transformers\cuda\sdp_utils.cpp:263.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([64, 1, 10])
[33mx permuted and embedding:[39m --> (None, None, None):  torch.Size([64, 10, 128])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 128])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 128])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([64, 10, 128])
[33mx permuted and fc_decoded[39m --> (None, None, None):  torch.Size([64, 10, 1])
signal torch.Size([64, 1, 10]) tensor([[7.7235, 7.7229, 7.7232, 7.7240, 7.7236, 7.7228, 7.7238, 7.7230, 7.7228,
         7.7217]])
preds torch.Size([64, 1, 10]) tensor([[0.2695, 0.2979, 0.2079, 0.6249, 0.2306, 0.2774, 0.5662, 0.4068, 0.9033,
         0.2299]], grad_fn=<ToCopyBackward0>)
targets torch.Size([64, 1, 10]) tensor([[7.7229, 7.7232, 7.7240, 7.7236, 7.7228, 7.7238, 7.7230, 7.7228, 7.7217,
         7.7206]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([64, 1, 10])
[33mx permuted and embedding:[39m --> (None, None, None):  torch.Size([64, 10, 128])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 128])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 128])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([64, 10, 128])
[33mx permuted and fc_decoded[39m --> (None, None, None):  torch.Size([64, 10, 1])
signal torch.Size([64, 1, 10]) tensor([[7.7252, 7.7255, 7.7256, 7.7252, 7.7254, 7.7250, 7.7256, 7.7256, 7.7256,
         7.7263]])
preds torch.Size([64, 1, 10]) tensor([[5.5491, 5.6408, 5.6570, 5.6039, 5.7167, 5.3572, 5.4583, 5.5446, 5.6358,
         5.4991]], grad_fn=<ToCopyBackward0>)
targets torch.Size([64, 1, 10]) tensor([[7.7255, 7.7256, 7.7252, 7.7254, 7.7250, 7.7256, 7.7256, 7.7256, 7.7263,
         7.7253]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([64, 1, 10])
[33mx permuted and embedding:[39m --> (None, None, None):  torch.Size([64, 10, 128])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 128])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 128])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([64, 10, 128])
[33mx permuted and fc_decoded[39m --> (None, None, None):  torch.Size([64, 10, 1])
signal torch.Size([64, 1, 10]) tensor([[7.7150, 7.7153, 7.7151, 7.7155, 7.7158, 7.7161, 7.7183, 7.7183, 7.7197,
         7.7213]])
preds torch.Size([64, 1, 10]) tensor([[7.0119, 6.9027, 6.8578, 6.6952, 7.0688, 6.8296, 7.0425, 6.9917, 6.8349,
         6.7679]], grad_fn=<ToCopyBackward0>)
targets torch.Size([64, 1, 10]) tensor([[7.7153, 7.7151, 7.7155, 7.7158, 7.7161, 7.7183, 7.7183, 7.7197, 7.7213,
         7.7218]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([64, 1, 10])
[33mx permuted and embedding:[39m --> (None, None, None):  torch.Size([64, 10, 128])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 128])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 128])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([64, 10, 128])
[33mx permuted and fc_decoded[39m --> (None, None, None):  torch.Size([64, 10, 1])
signal torch.Size([64, 1, 10]) tensor([[7.7175, 7.7183, 7.7179, 7.7183, 7.7185, 7.7185, 7.7180, 7.7178, 7.7169,
         7.7168]])
preds torch.Size([64, 1, 10]) tensor([[7.3852, 7.2218, 7.3293, 7.3628, 7.3012, 7.2429, 7.3595, 7.2634, 7.2861,
         7.3159]], grad_fn=<ToCopyBackward0>)
targets torch.Size([64, 1, 10]) tensor([[7.7183, 7.7179, 7.7183, 7.7185, 7.7185, 7.7180, 7.7178, 7.7169, 7.7168,
         7.7168]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([64, 1, 10])
[33mx permuted and embedding:[39m --> (None, None, None):  torch.Size([64, 10, 128])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 128])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 128])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([64, 10, 128])
[33mx permuted and fc_decoded[39m --> (None, None, None):  torch.Size([64, 10, 1])
signal torch.Size([64, 1, 10]) tensor([[7.7137, 7.7141, 7.7146, 7.7147, 7.7147, 7.7145, 7.7141, 7.7137, 7.7142,
         7.7145]])
preds torch.Size([64, 1, 10]) tensor([[7.3048, 7.3758, 7.3849, 7.4253, 7.4222, 7.2779, 7.3185, 7.2549, 7.2848,
         7.2285]], grad_fn=<ToCopyBackward0>)
targets torch.Size([64, 1, 10]) tensor([[7.7141, 7.7146, 7.7147, 7.7147, 7.7145, 7.7141, 7.7137, 7.7142, 7.7145,
         7.7146]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([64, 1, 10])
[33mx permuted and embedding:[39m --> (None, None, None):  torch.Size([64, 10, 128])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 128])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 128])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([64, 10, 128])
[33mx permuted and fc_decoded[39m --> (None, None, None):  torch.Size([64, 10, 1])
signal torch.Size([64, 1, 10]) tensor([[7.7222, 7.7219, 7.7217, 7.7214, 7.7221, 7.7223, 7.7228, 7.7229, 7.7228,
         7.7220]])
preds torch.Size([64, 1, 10]) tensor([[7.3848, 7.4418, 7.3151, 7.3092, 7.5090, 7.4550, 7.3700, 7.4872, 7.5510,
         7.4768]], grad_fn=<ToCopyBackward0>)
targets torch.Size([64, 1, 10]) tensor([[7.7219, 7.7217, 7.7214, 7.7221, 7.7223, 7.7228, 7.7229, 7.7228, 7.7220,
         7.7223]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([64, 1, 10])
[33mx permuted and embedding:[39m --> (None, None, None):  torch.Size([64, 10, 128])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 128])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 128])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([64, 10, 128])
[33mx permuted and fc_decoded[39m --> (None, None, None):  torch.Size([64, 10, 1])
signal torch.Size([64, 1, 10]) tensor([[7.8310, 7.8305, 7.8302, 7.8299, 7.8291, 7.8299, 7.8293, 7.8289, 7.8304,
         7.8301]])
preds torch.Size([64, 1, 10]) tensor([[7.5948, 7.6607, 7.5775, 7.4491, 7.5559, 7.6553, 7.4873, 7.7918, 7.5335,
         7.5814]], grad_fn=<ToCopyBackward0>)
targets torch.Size([64, 1, 10]) tensor([[7.8305, 7.8302, 7.8299, 7.8291, 7.8299, 7.8293, 7.8289, 7.8304, 7.8301,
         7.8299]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([64, 1, 10])
[33mx permuted and embedding:[39m --> (None, None, None):  torch.Size([64, 10, 128])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 128])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 128])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([64, 10, 128])
[33mx permuted and fc_decoded[39m --> (None, None, None):  torch.Size([64, 10, 1])
signal torch.Size([64, 1, 10]) tensor([[7.8124, 7.8127, 7.8121, 7.8121, 7.8127, 7.8128, 7.8133, 7.8129, 7.8127,
         7.8126]])
preds torch.Size([64, 1, 10]) tensor([[7.6267, 7.4304, 7.6359, 7.6362, 7.6202, 7.6599, 7.7013, 7.8686, 7.6552,
         7.7170]], grad_fn=<ToCopyBackward0>)
targets torch.Size([64, 1, 10]) tensor([[7.8127, 7.8121, 7.8121, 7.8127, 7.8128, 7.8133, 7.8129, 7.8127, 7.8126,
         7.8126]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([64, 1, 10])
[33mx permuted and embedding:[39m --> (None, None, None):  torch.Size([64, 10, 128])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 128])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 128])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([64, 10, 128])
[33mx permuted and fc_decoded[39m --> (None, None, None):  torch.Size([64, 10, 1])
signal torch.Size([64, 1, 10]) tensor([[7.7296, 7.7296, 7.7291, 7.7292, 7.7285, 7.7281, 7.7283, 7.7282, 7.7278,
         7.7276]])
preds torch.Size([64, 1, 10]) tensor([[7.9132, 7.7625, 7.8400, 7.9304, 7.7538, 7.8888, 7.9848, 7.8238, 7.8285,
         7.7986]], grad_fn=<ToCopyBackward0>)
targets torch.Size([64, 1, 10]) tensor([[7.7296, 7.7291, 7.7292, 7.7285, 7.7281, 7.7283, 7.7282, 7.7278, 7.7276,
         7.7276]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([64, 1, 10])
[33mx permuted and embedding:[39m --> (None, None, None):  torch.Size([64, 10, 128])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 128])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 128])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([64, 10, 128])
[33mx permuted and fc_decoded[39m --> (None, None, None):  torch.Size([64, 10, 1])
signal torch.Size([64, 1, 10]) tensor([[7.8133, 7.8133, 7.8129, 7.8129, 7.8133, 7.8123, 7.8130, 7.8125, 7.8119,
         7.8117]])
preds torch.Size([64, 1, 10]) tensor([[7.9365, 7.9913, 7.7134, 7.9963, 7.8625, 7.7277, 7.7271, 7.9524, 7.8659,
         7.7730]], grad_fn=<ToCopyBackward0>)
targets torch.Size([64, 1, 10]) tensor([[7.8133, 7.8129, 7.8129, 7.8133, 7.8123, 7.8130, 7.8125, 7.8119, 7.8117,
         7.8120]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([64, 1, 10])
[33mx permuted and embedding:[39m --> (None, None, None):  torch.Size([64, 10, 128])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 128])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 128])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([64, 10, 128])
[33mx permuted and fc_decoded[39m --> (None, None, None):  torch.Size([64, 10, 1])
signal torch.Size([64, 1, 10]) tensor([[7.8113, 7.8113, 7.8113, 7.8115, 7.8113, 7.8113, 7.8118, 7.8112, 7.8112,
         7.8111]])
preds torch.Size([64, 1, 10]) tensor([[7.9594, 7.8093, 7.7709, 7.9121, 7.8850, 7.8240, 8.0273, 7.9958, 7.9959,
         7.7436]], grad_fn=<ToCopyBackward0>)
targets torch.Size([64, 1, 10]) tensor([[7.8113, 7.8113, 7.8115, 7.8113, 7.8113, 7.8118, 7.8112, 7.8112, 7.8111,
         7.8106]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([64, 1, 10])
[33mx permuted and embedding:[39m --> (None, None, None):  torch.Size([64, 10, 128])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 128])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 128])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([64, 10, 128])
[33mx permuted and fc_decoded[39m --> (None, None, None):  torch.Size([64, 10, 1])
signal torch.Size([64, 1, 10]) tensor([[7.7358, 7.7352, 7.7346, 7.7347, 7.7351, 7.7349, 7.7351, 7.7343, 7.7345,
         7.7337]])
preds torch.Size([64, 1, 10]) tensor([[7.8317, 7.8329, 7.7755, 7.7564, 7.6864, 7.8166, 8.0721, 7.8468, 7.8259,
         7.8260]], grad_fn=<ToCopyBackward0>)
targets torch.Size([64, 1, 10]) tensor([[7.7352, 7.7346, 7.7347, 7.7351, 7.7349, 7.7351, 7.7343, 7.7345, 7.7337,
         7.7335]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([64, 1, 10])
[33mx permuted and embedding:[39m --> (None, None, None):  torch.Size([64, 10, 128])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 128])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 128])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([64, 10, 128])
[33mx permuted and fc_decoded[39m --> (None, None, None):  torch.Size([64, 10, 1])
signal torch.Size([64, 1, 10]) tensor([[7.7254, 7.7257, 7.7250, 7.7249, 7.7251, 7.7248, 7.7248, 7.7257, 7.7255,
         7.7252]])
preds torch.Size([64, 1, 10]) tensor([[7.7152, 7.6060, 7.7132, 7.3574, 7.7190, 7.7733, 7.7114, 7.5910, 7.6064,
         7.8854]], grad_fn=<ToCopyBackward0>)
targets torch.Size([64, 1, 10]) tensor([[7.7257, 7.7250, 7.7249, 7.7251, 7.7248, 7.7248, 7.7257, 7.7255, 7.7252,
         7.7254]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([64, 1, 10])
[33mx permuted and embedding:[39m --> (None, None, None):  torch.Size([64, 10, 128])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 128])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 128])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([64, 10, 128])
[33mx permuted and fc_decoded[39m --> (None, None, None):  torch.Size([64, 10, 1])
signal torch.Size([64, 1, 10]) tensor([[7.8505, 7.8507, 7.8501, 7.8511, 7.8511, 7.8510, 7.8510, 7.8515, 7.8514,
         7.8516]])
preds torch.Size([64, 1, 10]) tensor([[7.6428, 7.5887, 7.6120, 7.5836, 7.6979, 7.6417, 7.8373, 7.6477, 7.6607,
         7.6801]], grad_fn=<ToCopyBackward0>)
targets torch.Size([64, 1, 10]) tensor([[7.8507, 7.8501, 7.8511, 7.8511, 7.8510, 7.8510, 7.8515, 7.8514, 7.8516,
         7.8513]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([64, 1, 10])
[33mx permuted and embedding:[39m --> (None, None, None):  torch.Size([64, 10, 128])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 128])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 128])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([64, 10, 128])
[33mx permuted and fc_decoded[39m --> (None, None, None):  torch.Size([64, 10, 1])
signal torch.Size([64, 1, 10]) tensor([[7.8122, 7.8122, 7.8121, 7.8121, 7.8124, 7.8127, 7.8123, 7.8123, 7.8125,
         7.8125]])
preds torch.Size([64, 1, 10]) tensor([[7.7904, 7.8218, 7.7845, 7.7273, 7.7152, 7.8745, 7.6055, 7.6163, 7.6736,
         7.4794]], grad_fn=<ToCopyBackward0>)
targets torch.Size([64, 1, 10]) tensor([[7.8122, 7.8121, 7.8121, 7.8124, 7.8127, 7.8123, 7.8123, 7.8125, 7.8125,
         7.8120]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([64, 1, 10])
[33mx permuted and embedding:[39m --> (None, None, None):  torch.Size([64, 10, 128])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 128])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 128])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([64, 10, 128])
[33mx permuted and fc_decoded[39m --> (None, None, None):  torch.Size([64, 10, 1])
signal torch.Size([64, 1, 10]) tensor([[7.8322, 7.8326, 7.8322, 7.8327, 7.8325, 7.8325, 7.8332, 7.8328, 7.8332,
         7.8329]])
preds torch.Size([64, 1, 10]) tensor([[7.7204, 7.9644, 7.7950, 7.6887, 7.8372, 7.7344, 7.7481, 7.7907, 7.8487,
         8.0246]], grad_fn=<ToCopyBackward0>)
targets torch.Size([64, 1, 10]) tensor([[7.8326, 7.8322, 7.8327, 7.8325, 7.8325, 7.8332, 7.8328, 7.8332, 7.8329,
         7.8333]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([64, 1, 10])
[33mx permuted and embedding:[39m --> (None, None, None):  torch.Size([64, 10, 128])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 128])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 128])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([64, 10, 128])
[33mx permuted and fc_decoded[39m --> (None, None, None):  torch.Size([64, 10, 1])
signal torch.Size([64, 1, 10]) tensor([[7.7324, 7.7325, 7.7331, 7.7332, 7.7329, 7.7330, 7.7329, 7.7325, 7.7322,
         7.7318]])
preds torch.Size([64, 1, 10]) tensor([[7.9259, 7.8325, 7.8703, 7.9815, 7.9355, 7.9076, 8.0808, 7.7603, 8.0767,
         8.0607]], grad_fn=<ToCopyBackward0>)
targets torch.Size([64, 1, 10]) tensor([[7.7325, 7.7331, 7.7332, 7.7329, 7.7330, 7.7329, 7.7325, 7.7322, 7.7318,
         7.7325]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([64, 1, 10])
[33mx permuted and embedding:[39m --> (None, None, None):  torch.Size([64, 10, 128])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 128])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 128])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([64, 10, 128])
[33mx permuted and fc_decoded[39m --> (None, None, None):  torch.Size([64, 10, 1])
signal torch.Size([64, 1, 10]) tensor([[7.7259, 7.7257, 7.7242, 7.7254, 7.7246, 7.7242, 7.7247, 7.7245, 7.7248,
         7.7251]])
preds torch.Size([64, 1, 10]) tensor([[8.1816, 7.8247, 7.9003, 7.9356, 8.0171, 7.9270, 7.9220, 7.9600, 8.0021,
         7.9150]], grad_fn=<ToCopyBackward0>)
targets torch.Size([64, 1, 10]) tensor([[7.7257, 7.7242, 7.7254, 7.7246, 7.7242, 7.7247, 7.7245, 7.7248, 7.7251,
         7.7261]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([64, 1, 10])
[33mx permuted and embedding:[39m --> (None, None, None):  torch.Size([64, 10, 128])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 128])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 128])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([64, 10, 128])
[33mx permuted and fc_decoded[39m --> (None, None, None):  torch.Size([64, 10, 1])
signal torch.Size([64, 1, 10]) tensor([[7.7034, 7.7034, 7.7029, 7.7031, 7.7029, 7.7026, 7.7032, 7.7030, 7.7043,
         7.7042]])
preds torch.Size([64, 1, 10]) tensor([[7.8327, 7.8663, 7.9094, 7.9872, 7.8278, 7.6442, 7.7972, 7.8127, 7.9284,
         7.6206]], grad_fn=<ToCopyBackward0>)
targets torch.Size([64, 1, 10]) tensor([[7.7034, 7.7029, 7.7031, 7.7029, 7.7026, 7.7032, 7.7030, 7.7043, 7.7042,
         7.7039]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([64, 1, 10])
[33mx permuted and embedding:[39m --> (None, None, None):  torch.Size([64, 10, 128])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 128])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 128])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([64, 10, 128])
[33mx permuted and fc_decoded[39m --> (None, None, None):  torch.Size([64, 10, 1])
signal torch.Size([64, 1, 10]) tensor([[7.7154, 7.7154, 7.7153, 7.7153, 7.7156, 7.7155, 7.7155, 7.7156, 7.7163,
         7.7170]])
preds torch.Size([64, 1, 10]) tensor([[7.7643, 7.7810, 7.5721, 7.9026, 7.8070, 7.9878, 7.7071, 7.8784, 7.6727,
         7.7514]], grad_fn=<ToCopyBackward0>)
targets torch.Size([64, 1, 10]) tensor([[7.7154, 7.7153, 7.7153, 7.7156, 7.7155, 7.7155, 7.7156, 7.7163, 7.7170,
         7.7159]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([64, 1, 10])
[33mx permuted and embedding:[39m --> (None, None, None):  torch.Size([64, 10, 128])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 128])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 128])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([64, 10, 128])
[33mx permuted and fc_decoded[39m --> (None, None, None):  torch.Size([64, 10, 1])
signal torch.Size([64, 1, 10]) tensor([[7.8526, 7.8526, 7.8531, 7.8537, 7.8536, 7.8548, 7.8546, 7.8554, 7.8541,
         7.8552]])
preds torch.Size([64, 1, 10]) tensor([[7.5638, 7.7866, 7.8683, 7.6375, 7.6782, 7.4313, 7.6051, 7.6801, 7.5178,
         7.6773]], grad_fn=<ToCopyBackward0>)
targets torch.Size([64, 1, 10]) tensor([[7.8526, 7.8531, 7.8537, 7.8536, 7.8548, 7.8546, 7.8554, 7.8541, 7.8552,
         7.8553]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([64, 1, 10])
[33mx permuted and embedding:[39m --> (None, None, None):  torch.Size([64, 10, 128])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 128])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 128])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([64, 10, 128])
[33mx permuted and fc_decoded[39m --> (None, None, None):  torch.Size([64, 10, 1])
signal torch.Size([64, 1, 10]) tensor([[7.8347, 7.8344, 7.8340, 7.8335, 7.8343, 7.8336, 7.8334, 7.8342, 7.8346,
         7.8343]])
preds torch.Size([64, 1, 10]) tensor([[7.7002, 7.7320, 7.6320, 7.6119, 7.6525, 7.6076, 7.7739, 7.8445, 7.7906,
         7.6566]], grad_fn=<ToCopyBackward0>)
targets torch.Size([64, 1, 10]) tensor([[7.8344, 7.8340, 7.8335, 7.8343, 7.8336, 7.8334, 7.8342, 7.8346, 7.8343,
         7.8346]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([64, 1, 10])
[33mx permuted and embedding:[39m --> (None, None, None):  torch.Size([64, 10, 128])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 128])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 128])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([64, 10, 128])
[33mx permuted and fc_decoded[39m --> (None, None, None):  torch.Size([64, 10, 1])
signal torch.Size([64, 1, 10]) tensor([[7.7219, 7.7223, 7.7230, 7.7230, 7.7225, 7.7224, 7.7226, 7.7225, 7.7226,
         7.7217]])
preds torch.Size([64, 1, 10]) tensor([[7.7189, 7.9281, 7.7128, 7.7414, 7.8087, 7.6662, 7.5414, 7.7140, 7.7560,
         7.8692]], grad_fn=<ToCopyBackward0>)
targets torch.Size([64, 1, 10]) tensor([[7.7223, 7.7230, 7.7230, 7.7225, 7.7224, 7.7226, 7.7225, 7.7226, 7.7217,
         7.7213]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([64, 1, 10])
[33mx permuted and embedding:[39m --> (None, None, None):  torch.Size([64, 10, 128])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 128])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 128])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([64, 10, 128])
[33mx permuted and fc_decoded[39m --> (None, None, None):  torch.Size([64, 10, 1])
signal torch.Size([64, 1, 10]) tensor([[7.8379, 7.8390, 7.8384, 7.8389, 7.8379, 7.8378, 7.8376, 7.8386, 7.8386,
         7.8390]])
preds torch.Size([64, 1, 10]) tensor([[7.7686, 7.9734, 7.6465, 7.7617, 7.8591, 7.7388, 7.7469, 7.7990, 7.7431,
         7.9044]], grad_fn=<ToCopyBackward0>)
targets torch.Size([64, 1, 10]) tensor([[7.8390, 7.8384, 7.8389, 7.8379, 7.8378, 7.8376, 7.8386, 7.8386, 7.8390,
         7.8382]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([64, 1, 10])
[33mx permuted and embedding:[39m --> (None, None, None):  torch.Size([64, 10, 128])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 128])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 128])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([64, 10, 128])
[33mx permuted and fc_decoded[39m --> (None, None, None):  torch.Size([64, 10, 1])
signal torch.Size([64, 1, 10]) tensor([[7.7130, 7.7131, 7.7129, 7.7124, 7.7125, 7.7122, 7.7114, 7.7113, 7.7125,
         7.7122]])
preds torch.Size([64, 1, 10]) tensor([[7.9026, 7.7498, 7.8763, 7.8729, 8.0603, 8.0296, 8.0191, 7.9959, 7.9032,
         7.8869]], grad_fn=<ToCopyBackward0>)
targets torch.Size([64, 1, 10]) tensor([[7.7131, 7.7129, 7.7124, 7.7125, 7.7122, 7.7114, 7.7113, 7.7125, 7.7122,
         7.7117]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([64, 1, 10])
[33mx permuted and embedding:[39m --> (None, None, None):  torch.Size([64, 10, 128])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 128])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 128])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([64, 10, 128])
[33mx permuted and fc_decoded[39m --> (None, None, None):  torch.Size([64, 10, 1])
signal torch.Size([64, 1, 10]) tensor([[7.8098, 7.8086, 7.8083, 7.8088, 7.8097, 7.8089, 7.8091, 7.8089, 7.8090,
         7.8071]])
preds torch.Size([64, 1, 10]) tensor([[7.9297, 7.9703, 7.7698, 7.9970, 7.7176, 8.0853, 7.7605, 7.6574, 7.8366,
         7.9429]], grad_fn=<ToCopyBackward0>)
targets torch.Size([64, 1, 10]) tensor([[7.8086, 7.8083, 7.8088, 7.8097, 7.8089, 7.8091, 7.8089, 7.8090, 7.8071,
         7.8076]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([64, 1, 10])
[33mx permuted and embedding:[39m --> (None, None, None):  torch.Size([64, 10, 128])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 128])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 128])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([64, 10, 128])
[33mx permuted and fc_decoded[39m --> (None, None, None):  torch.Size([64, 10, 1])
signal torch.Size([64, 1, 10]) tensor([[7.7171, 7.7172, 7.7175, 7.7182, 7.7181, 7.7180, 7.7182, 7.7176, 7.7176,
         7.7178]])
preds torch.Size([64, 1, 10]) tensor([[7.7593, 7.6806, 7.7290, 7.7833, 7.8099, 7.8801, 7.7449, 7.7000, 7.7929,
         7.7912]], grad_fn=<ToCopyBackward0>)
targets torch.Size([64, 1, 10]) tensor([[7.7172, 7.7175, 7.7182, 7.7181, 7.7180, 7.7182, 7.7176, 7.7176, 7.7178,
         7.7178]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([64, 1, 10])
[33mx permuted and embedding:[39m --> (None, None, None):  torch.Size([64, 10, 128])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 128])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 128])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([64, 10, 128])
[33mx permuted and fc_decoded[39m --> (None, None, None):  torch.Size([64, 10, 1])
signal torch.Size([64, 1, 10]) tensor([[7.7127, 7.7135, 7.7124, 7.7129, 7.7128, 7.7130, 7.7128, 7.7125, 7.7122,
         7.7130]])
preds torch.Size([64, 1, 10]) tensor([[7.8803, 7.7491, 7.8980, 7.7731, 7.7280, 7.8697, 7.5552, 7.8110, 7.6746,
         7.7889]], grad_fn=<ToCopyBackward0>)
targets torch.Size([64, 1, 10]) tensor([[7.7135, 7.7124, 7.7129, 7.7128, 7.7130, 7.7128, 7.7125, 7.7122, 7.7130,
         7.7122]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([64, 1, 10])
[33mx permuted and embedding:[39m --> (None, None, None):  torch.Size([64, 10, 128])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 128])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 128])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([64, 10, 128])
[33mx permuted and fc_decoded[39m --> (None, None, None):  torch.Size([64, 10, 1])
signal torch.Size([64, 1, 10]) tensor([[7.8235, 7.8226, 7.8218, 7.8226, 7.8229, 7.8229, 7.8234, 7.8226, 7.8226,
         7.8227]])
preds torch.Size([64, 1, 10]) tensor([[7.7776, 7.7354, 7.7316, 7.7125, 7.7193, 7.6756, 7.6046, 7.5511, 7.7444,
         7.7186]], grad_fn=<ToCopyBackward0>)
targets torch.Size([64, 1, 10]) tensor([[7.8226, 7.8218, 7.8226, 7.8229, 7.8229, 7.8234, 7.8226, 7.8226, 7.8227,
         7.8226]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([64, 1, 10])
[33mx permuted and embedding:[39m --> (None, None, None):  torch.Size([64, 10, 128])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 128])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 128])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([64, 10, 128])
[33mx permuted and fc_decoded[39m --> (None, None, None):  torch.Size([64, 10, 1])
signal torch.Size([64, 1, 10]) tensor([[7.7757, 7.7758, 7.7756, 7.7752, 7.7755, 7.7751, 7.7759, 7.7764, 7.7763,
         7.7753]])
preds torch.Size([64, 1, 10]) tensor([[7.6973, 7.8485, 7.7454, 7.7582, 7.5363, 7.8668, 7.6964, 7.7741, 7.8249,
         7.6904]], grad_fn=<ToCopyBackward0>)
targets torch.Size([64, 1, 10]) tensor([[7.7758, 7.7756, 7.7752, 7.7755, 7.7751, 7.7759, 7.7764, 7.7763, 7.7753,
         7.7757]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([64, 1, 10])
[33mx permuted and embedding:[39m --> (None, None, None):  torch.Size([64, 10, 128])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 128])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 128])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([64, 10, 128])
[33mx permuted and fc_decoded[39m --> (None, None, None):  torch.Size([64, 10, 1])
signal torch.Size([64, 1, 10]) tensor([[7.7168, 7.7171, 7.7176, 7.7172, 7.7171, 7.7171, 7.7167, 7.7170, 7.7158,
         7.7165]])
preds torch.Size([64, 1, 10]) tensor([[7.6950, 7.7582, 7.9031, 7.8173, 7.8021, 7.8037, 7.8186, 7.7425, 7.7608,
         7.7560]], grad_fn=<ToCopyBackward0>)
targets torch.Size([64, 1, 10]) tensor([[7.7171, 7.7176, 7.7172, 7.7171, 7.7171, 7.7167, 7.7170, 7.7158, 7.7165,
         7.7170]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([64, 1, 10])
[33mx permuted and embedding:[39m --> (None, None, None):  torch.Size([64, 10, 128])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 128])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 128])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([64, 10, 128])
[33mx permuted and fc_decoded[39m --> (None, None, None):  torch.Size([64, 10, 1])
signal torch.Size([64, 1, 10]) tensor([[7.8005, 7.8004, 7.8004, 7.8013, 7.8015, 7.8014, 7.8014, 7.8004, 7.8005,
         7.7996]])
preds torch.Size([64, 1, 10]) tensor([[7.8695, 7.6722, 7.9099, 7.8323, 7.7322, 7.8958, 7.8223, 7.8484, 7.8905,
         7.8346]], grad_fn=<ToCopyBackward0>)
targets torch.Size([64, 1, 10]) tensor([[7.8004, 7.8004, 7.8013, 7.8015, 7.8014, 7.8014, 7.8004, 7.8005, 7.7996,
         7.8012]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([64, 1, 10])
[33mx permuted and embedding:[39m --> (None, None, None):  torch.Size([64, 10, 128])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 128])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 128])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([64, 10, 128])
[33mx permuted and fc_decoded[39m --> (None, None, None):  torch.Size([64, 10, 1])
signal torch.Size([64, 1, 10]) tensor([[7.7378, 7.7382, 7.7386, 7.7378, 7.7378, 7.7386, 7.7382, 7.7383, 7.7386,
         7.7382]])
preds torch.Size([64, 1, 10]) tensor([[7.8285, 7.9209, 7.8469, 7.7885, 7.8206, 7.8147, 7.9357, 7.8484, 7.8079,
         7.7938]], grad_fn=<ToCopyBackward0>)
targets torch.Size([64, 1, 10]) tensor([[7.7382, 7.7386, 7.7378, 7.7378, 7.7386, 7.7382, 7.7383, 7.7386, 7.7382,
         7.7376]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([64, 1, 10])
[33mx permuted and embedding:[39m --> (None, None, None):  torch.Size([64, 10, 128])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 128])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 128])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([64, 10, 128])
[33mx permuted and fc_decoded[39m --> (None, None, None):  torch.Size([64, 10, 1])
signal torch.Size([64, 1, 10]) tensor([[7.7107, 7.7104, 7.7105, 7.7112, 7.7105, 7.7105, 7.7092, 7.7093, 7.7088,
         7.7083]])
preds torch.Size([64, 1, 10]) tensor([[7.7228, 7.7403, 7.6437, 7.7168, 7.5758, 7.8372, 7.7166, 7.6863, 7.6798,
         7.7481]], grad_fn=<ToCopyBackward0>)
targets torch.Size([64, 1, 10]) tensor([[7.7104, 7.7105, 7.7112, 7.7105, 7.7105, 7.7092, 7.7093, 7.7088, 7.7083,
         7.7088]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([64, 1, 10])
[33mx permuted and embedding:[39m --> (None, None, None):  torch.Size([64, 10, 128])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 128])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 128])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([64, 10, 128])
[33mx permuted and fc_decoded[39m --> (None, None, None):  torch.Size([64, 10, 1])
signal torch.Size([64, 1, 10]) tensor([[7.7052, 7.7037, 7.7030, 7.7022, 7.7025, 7.7031, 7.7026, 7.7032, 7.7037,
         7.7046]])
preds torch.Size([64, 1, 10]) tensor([[7.6338, 7.6506, 7.8244, 7.8048, 7.6380, 7.6848, 7.8375, 7.7616, 7.6926,
         7.8265]], grad_fn=<ToCopyBackward0>)
targets torch.Size([64, 1, 10]) tensor([[7.7037, 7.7030, 7.7022, 7.7025, 7.7031, 7.7026, 7.7032, 7.7037, 7.7046,
         7.7048]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([64, 1, 10])
[33mx permuted and embedding:[39m --> (None, None, None):  torch.Size([64, 10, 128])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 128])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 128])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([64, 10, 128])
[33mx permuted and fc_decoded[39m --> (None, None, None):  torch.Size([64, 10, 1])
signal torch.Size([64, 1, 10]) tensor([[7.7094, 7.7101, 7.7113, 7.7122, 7.7113, 7.7110, 7.7111, 7.7112, 7.7104,
         7.7098]])
preds torch.Size([64, 1, 10]) tensor([[7.7087, 7.8031, 7.8691, 7.6860, 7.7603, 7.8646, 7.7434, 7.6552, 7.7794,
         7.5977]], grad_fn=<ToCopyBackward0>)
targets torch.Size([64, 1, 10]) tensor([[7.7101, 7.7113, 7.7122, 7.7113, 7.7110, 7.7111, 7.7112, 7.7104, 7.7098,
         7.7090]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([64, 1, 10])
[33mx permuted and embedding:[39m --> (None, None, None):  torch.Size([64, 10, 128])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 128])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 128])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([64, 10, 128])
[33mx permuted and fc_decoded[39m --> (None, None, None):  torch.Size([64, 10, 1])
signal torch.Size([64, 1, 10]) tensor([[7.7096, 7.7098, 7.7111, 7.7111, 7.7107, 7.7100, 7.7094, 7.7107, 7.7102,
         7.7111]])
preds torch.Size([64, 1, 10]) tensor([[7.7738, 7.9058, 7.7966, 7.9037, 7.8647, 7.7956, 7.9395, 7.8846, 7.8537,
         7.9529]], grad_fn=<ToCopyBackward0>)
targets torch.Size([64, 1, 10]) tensor([[7.7098, 7.7111, 7.7111, 7.7107, 7.7100, 7.7094, 7.7107, 7.7102, 7.7111,
         7.7107]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([64, 1, 10])
[33mx permuted and embedding:[39m --> (None, None, None):  torch.Size([64, 10, 128])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 128])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 128])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([64, 10, 128])
[33mx permuted and fc_decoded[39m --> (None, None, None):  torch.Size([64, 10, 1])
signal torch.Size([64, 1, 10]) tensor([[7.7728, 7.7727, 7.7721, 7.7713, 7.7702, 7.7689, 7.7697, 7.7688, 7.7692,
         7.7702]])
preds torch.Size([64, 1, 10]) tensor([[7.8457, 7.8822, 7.8986, 7.8890, 7.8915, 7.7998, 7.8066, 7.9201, 7.9211,
         7.9292]], grad_fn=<ToCopyBackward0>)
targets torch.Size([64, 1, 10]) tensor([[7.7727, 7.7721, 7.7713, 7.7702, 7.7689, 7.7697, 7.7688, 7.7692, 7.7702,
         7.7698]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([64, 1, 10])
[33mx permuted and embedding:[39m --> (None, None, None):  torch.Size([64, 10, 128])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 128])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 128])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([64, 10, 128])
[33mx permuted and fc_decoded[39m --> (None, None, None):  torch.Size([64, 10, 1])
signal torch.Size([64, 1, 10]) tensor([[7.7493, 7.7484, 7.7498, 7.7509, 7.7529, 7.7519, 7.7521, 7.7514, 7.7541,
         7.7529]])
preds torch.Size([64, 1, 10]) tensor([[7.7065, 7.8527, 7.7963, 7.8022, 7.8800, 7.8804, 7.8431, 7.7474, 7.8477,
         7.8685]], grad_fn=<ToCopyBackward0>)
targets torch.Size([64, 1, 10]) tensor([[7.7484, 7.7498, 7.7509, 7.7529, 7.7519, 7.7521, 7.7514, 7.7541, 7.7529,
         7.7522]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([64, 1, 10])
[33mx permuted and embedding:[39m --> (None, None, None):  torch.Size([64, 10, 128])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 128])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 128])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([64, 10, 128])
[33mx permuted and fc_decoded[39m --> (None, None, None):  torch.Size([64, 10, 1])
signal torch.Size([64, 1, 10]) tensor([[7.7133, 7.7135, 7.7132, 7.7127, 7.7129, 7.7126, 7.7131, 7.7134, 7.7134,
         7.7137]])
preds torch.Size([64, 1, 10]) tensor([[7.7907, 7.6417, 7.7703, 7.8243, 7.6158, 7.7473, 7.8290, 7.7161, 7.6714,
         7.7911]], grad_fn=<ToCopyBackward0>)
targets torch.Size([64, 1, 10]) tensor([[7.7135, 7.7132, 7.7127, 7.7129, 7.7126, 7.7131, 7.7134, 7.7134, 7.7137,
         7.7132]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([64, 1, 10])
[33mx permuted and embedding:[39m --> (None, None, None):  torch.Size([64, 10, 128])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 128])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 128])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([64, 10, 128])
[33mx permuted and fc_decoded[39m --> (None, None, None):  torch.Size([64, 10, 1])
signal torch.Size([64, 1, 10]) tensor([[7.8431, 7.8430, 7.8423, 7.8424, 7.8431, 7.8431, 7.8435, 7.8438, 7.8437,
         7.8434]])
preds torch.Size([64, 1, 10]) tensor([[7.7955, 7.7054, 7.7609, 7.7796, 7.7560, 7.6939, 7.6802, 7.6685, 7.8144,
         7.8214]], grad_fn=<ToCopyBackward0>)
targets torch.Size([64, 1, 10]) tensor([[7.8430, 7.8423, 7.8424, 7.8431, 7.8431, 7.8435, 7.8438, 7.8437, 7.8434,
         7.8433]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([64, 1, 10])
[33mx permuted and embedding:[39m --> (None, None, None):  torch.Size([64, 10, 128])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 128])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 128])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([64, 10, 128])
[33mx permuted and fc_decoded[39m --> (None, None, None):  torch.Size([64, 10, 1])
signal torch.Size([64, 1, 10]) tensor([[7.7744, 7.7742, 7.7744, 7.7762, 7.7780, 7.7770, 7.7762, 7.7757, 7.7751,
         7.7753]])
preds torch.Size([64, 1, 10]) tensor([[7.7039, 7.7879, 7.6424, 7.7775, 7.7404, 7.7671, 7.8325, 7.8126, 7.7372,
         7.8184]], grad_fn=<ToCopyBackward0>)
targets torch.Size([64, 1, 10]) tensor([[7.7742, 7.7744, 7.7762, 7.7780, 7.7770, 7.7762, 7.7757, 7.7751, 7.7753,
         7.7736]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([64, 1, 10])
[33mx permuted and embedding:[39m --> (None, None, None):  torch.Size([64, 10, 128])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 128])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 128])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([64, 10, 128])
[33mx permuted and fc_decoded[39m --> (None, None, None):  torch.Size([64, 10, 1])
signal torch.Size([64, 1, 10]) tensor([[7.8638, 7.8633, 7.8635, 7.8625, 7.8619, 7.8629, 7.8627, 7.8621, 7.8615,
         7.8623]])
preds torch.Size([64, 1, 10]) tensor([[7.8224, 7.8784, 7.9006, 7.7484, 7.9246, 7.9285, 7.7806, 7.6904, 7.7762,
         7.8743]], grad_fn=<ToCopyBackward0>)
targets torch.Size([64, 1, 10]) tensor([[7.8633, 7.8635, 7.8625, 7.8619, 7.8629, 7.8627, 7.8621, 7.8615, 7.8623,
         7.8631]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([64, 1, 10])
[33mx permuted and embedding:[39m --> (None, None, None):  torch.Size([64, 10, 128])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 128])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 128])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([64, 10, 128])
[33mx permuted and fc_decoded[39m --> (None, None, None):  torch.Size([64, 10, 1])
signal torch.Size([64, 1, 10]) tensor([[7.7067, 7.7067, 7.7049, 7.7054, 7.7046, 7.7013, 7.7015, 7.6996, 7.6983,
         7.7012]])
preds torch.Size([64, 1, 10]) tensor([[7.8765, 7.8256, 7.8674, 7.7592, 7.8614, 7.7271, 7.7655, 7.7983, 7.8659,
         7.7754]], grad_fn=<ToCopyBackward0>)
targets torch.Size([64, 1, 10]) tensor([[7.7067, 7.7049, 7.7054, 7.7046, 7.7013, 7.7015, 7.6996, 7.6983, 7.7012,
         7.7021]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([64, 1, 10])
[33mx permuted and embedding:[39m --> (None, None, None):  torch.Size([64, 10, 128])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 128])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 128])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([64, 10, 128])
[33mx permuted and fc_decoded[39m --> (None, None, None):  torch.Size([64, 10, 1])
signal torch.Size([64, 1, 10]) tensor([[7.8328, 7.8326, 7.8326, 7.8321, 7.8321, 7.8322, 7.8329, 7.8326, 7.8322,
         7.8325]])
preds torch.Size([64, 1, 10]) tensor([[7.7412, 7.7844, 7.7034, 7.7052, 7.6040, 7.7310, 7.7937, 7.7732, 7.7842,
         7.6775]], grad_fn=<ToCopyBackward0>)
targets torch.Size([64, 1, 10]) tensor([[7.8326, 7.8326, 7.8321, 7.8321, 7.8322, 7.8329, 7.8326, 7.8322, 7.8325,
         7.8323]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([64, 1, 10])
[33mx permuted and embedding:[39m --> (None, None, None):  torch.Size([64, 10, 128])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 128])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 128])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([64, 10, 128])
[33mx permuted and fc_decoded[39m --> (None, None, None):  torch.Size([64, 10, 1])
signal torch.Size([64, 1, 10]) tensor([[7.8371, 7.8379, 7.8373, 7.8374, 7.8378, 7.8379, 7.8377, 7.8382, 7.8380,
         7.8396]])
preds torch.Size([64, 1, 10]) tensor([[7.6532, 7.8163, 7.7952, 7.6142, 7.7473, 7.7397, 7.6801, 7.8282, 7.6814,
         7.6841]], grad_fn=<ToCopyBackward0>)
targets torch.Size([64, 1, 10]) tensor([[7.8379, 7.8373, 7.8374, 7.8378, 7.8379, 7.8377, 7.8382, 7.8380, 7.8396,
         7.8398]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([64, 1, 10])
[33mx permuted and embedding:[39m --> (None, None, None):  torch.Size([64, 10, 128])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 128])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 128])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([64, 10, 128])
[33mx permuted and fc_decoded[39m --> (None, None, None):  torch.Size([64, 10, 1])
signal torch.Size([64, 1, 10]) tensor([[7.7150, 7.7134, 7.7133, 7.7134, 7.7152, 7.7133, 7.7133, 7.7132, 7.7142,
         7.7146]])
preds torch.Size([64, 1, 10]) tensor([[7.7455, 7.8174, 7.8871, 7.8068, 7.8097, 7.8044, 7.7408, 7.7791, 7.7917,
         7.8711]], grad_fn=<ToCopyBackward0>)
targets torch.Size([64, 1, 10]) tensor([[7.7134, 7.7133, 7.7134, 7.7152, 7.7133, 7.7133, 7.7132, 7.7142, 7.7146,
         7.7141]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([64, 1, 10])
[33mx permuted and embedding:[39m --> (None, None, None):  torch.Size([64, 10, 128])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 128])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 128])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([64, 10, 128])
[33mx permuted and fc_decoded[39m --> (None, None, None):  torch.Size([64, 10, 1])
signal torch.Size([64, 1, 10]) tensor([[7.7299, 7.7298, 7.7293, 7.7292, 7.7290, 7.7282, 7.7284, 7.7291, 7.7285,
         7.7284]])
preds torch.Size([64, 1, 10]) tensor([[7.8865, 7.9084, 7.6920, 7.8541, 7.8298, 7.7726, 7.9089, 7.7975, 7.8441,
         7.8528]], grad_fn=<ToCopyBackward0>)
targets torch.Size([64, 1, 10]) tensor([[7.7298, 7.7293, 7.7292, 7.7290, 7.7282, 7.7284, 7.7291, 7.7285, 7.7284,
         7.7275]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([64, 1, 10])
[33mx permuted and embedding:[39m --> (None, None, None):  torch.Size([64, 10, 128])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 128])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 128])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([64, 10, 128])
[33mx permuted and fc_decoded[39m --> (None, None, None):  torch.Size([64, 10, 1])
signal torch.Size([64, 1, 10]) tensor([[7.8631, 7.8627, 7.8621, 7.8620, 7.8622, 7.8641, 7.8642, 7.8658, 7.8660,
         7.8679]])
preds torch.Size([64, 1, 10]) tensor([[7.8210, 7.8255, 7.8374, 7.8267, 7.7231, 7.8433, 7.8035, 7.8063, 7.7302,
         7.8224]], grad_fn=<ToCopyBackward0>)
targets torch.Size([64, 1, 10]) tensor([[7.8627, 7.8621, 7.8620, 7.8622, 7.8641, 7.8642, 7.8658, 7.8660, 7.8679,
         7.8674]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([64, 1, 10])
[33mx permuted and embedding:[39m --> (None, None, None):  torch.Size([64, 10, 128])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 128])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 128])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([64, 10, 128])
[33mx permuted and fc_decoded[39m --> (None, None, None):  torch.Size([64, 10, 1])
signal torch.Size([64, 1, 10]) tensor([[7.7181, 7.7184, 7.7180, 7.7179, 7.7183, 7.7182, 7.7175, 7.7179, 7.7174,
         7.7173]])
preds torch.Size([64, 1, 10]) tensor([[7.7409, 7.8254, 7.8111, 7.6985, 7.6654, 7.8470, 7.6739, 7.7957, 7.7942,
         7.7339]], grad_fn=<ToCopyBackward0>)
targets torch.Size([64, 1, 10]) tensor([[7.7184, 7.7180, 7.7179, 7.7183, 7.7182, 7.7175, 7.7179, 7.7174, 7.7173,
         7.7164]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([64, 1, 10])
[33mx permuted and embedding:[39m --> (None, None, None):  torch.Size([64, 10, 128])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 128])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 128])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([64, 10, 128])
[33mx permuted and fc_decoded[39m --> (None, None, None):  torch.Size([64, 10, 1])
signal torch.Size([64, 1, 10]) tensor([[7.7125, 7.7125, 7.7128, 7.7131, 7.7124, 7.7119, 7.7121, 7.7115, 7.7117,
         7.7119]])
preds torch.Size([64, 1, 10]) tensor([[7.7104, 7.7911, 7.8112, 7.7234, 7.7701, 7.7407, 7.7391, 7.6468, 7.7630,
         7.6328]], grad_fn=<ToCopyBackward0>)
targets torch.Size([64, 1, 10]) tensor([[7.7125, 7.7128, 7.7131, 7.7124, 7.7119, 7.7121, 7.7115, 7.7117, 7.7119,
         7.7117]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([64, 1, 10])
[33mx permuted and embedding:[39m --> (None, None, None):  torch.Size([64, 10, 128])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 128])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 128])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([64, 10, 128])
[33mx permuted and fc_decoded[39m --> (None, None, None):  torch.Size([64, 10, 1])
signal torch.Size([64, 1, 10]) tensor([[7.8338, 7.8340, 7.8343, 7.8346, 7.8342, 7.8344, 7.8352, 7.8351, 7.8345,
         7.8350]])
preds torch.Size([64, 1, 10]) tensor([[7.7611, 7.8342, 7.6961, 7.7912, 7.8327, 7.7388, 7.7982, 7.7036, 7.8090,
         7.7156]], grad_fn=<ToCopyBackward0>)
targets torch.Size([64, 1, 10]) tensor([[7.8340, 7.8343, 7.8346, 7.8342, 7.8344, 7.8352, 7.8351, 7.8345, 7.8350,
         7.8343]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([64, 1, 10])
[33mx permuted and embedding:[39m --> (None, None, None):  torch.Size([64, 10, 128])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 128])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 128])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([64, 10, 128])
[33mx permuted and fc_decoded[39m --> (None, None, None):  torch.Size([64, 10, 1])
signal torch.Size([64, 1, 10]) tensor([[7.8139, 7.8140, 7.8140, 7.8141, 7.8140, 7.8140, 7.8140, 7.8143, 7.8145,
         7.8147]])
preds torch.Size([64, 1, 10]) tensor([[7.8416, 7.7538, 7.7609, 7.8408, 7.8064, 7.8035, 7.8214, 7.8240, 7.8716,
         7.8471]], grad_fn=<ToCopyBackward0>)
targets torch.Size([64, 1, 10]) tensor([[7.8140, 7.8140, 7.8141, 7.8140, 7.8140, 7.8140, 7.8143, 7.8145, 7.8147,
         7.8144]])
  0%|          | 0/350 [00:02<?, ?it/s]
Traceback (most recent call last):
  File "C:\Users\dadou\Documents\Github\Advanced-Programming\Strategies\Transformer_strategy.py", line 420, in <module>
    trainer.train()
  File "C:\Users\dadou\Documents\Github\Advanced-Programming\utils\trainer.py", line 75, in train
    preds = self.model(signal.to(self.device))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\dadou\anaconda3\envs\Advanced-Programming\Lib\site-packages\torch\nn\modules\module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\dadou\anaconda3\envs\Advanced-Programming\Lib\site-packages\torch\nn\modules\module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\dadou\Documents\Github\Advanced-Programming\Strategies\Transformer_strategy.py", line 191, in forward
    x = self.transformer_encoder(x)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\dadou\anaconda3\envs\Advanced-Programming\Lib\site-packages\torch\nn\modules\module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\dadou\anaconda3\envs\Advanced-Programming\Lib\site-packages\torch\nn\modules\module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\dadou\anaconda3\envs\Advanced-Programming\Lib\site-packages\torch\nn\modules\transformer.py", line 391, in forward
    output = mod(output, src_mask=mask, is_causal=is_causal, src_key_padding_mask=src_key_padding_mask_for_layers)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\dadou\anaconda3\envs\Advanced-Programming\Lib\site-packages\torch\nn\modules\module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\dadou\anaconda3\envs\Advanced-Programming\Lib\site-packages\torch\nn\modules\module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\dadou\anaconda3\envs\Advanced-Programming\Lib\site-packages\torch\nn\modules\transformer.py", line 714, in forward
    x = self.norm1(x + self._sa_block(x, src_mask, src_key_padding_mask, is_causal=is_causal))
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\dadou\anaconda3\envs\Advanced-Programming\Lib\site-packages\torch\nn\modules\transformer.py", line 722, in _sa_block
    x = self.self_attn(x, x, x,
        ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\dadou\anaconda3\envs\Advanced-Programming\Lib\site-packages\torch\nn\modules\module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\dadou\anaconda3\envs\Advanced-Programming\Lib\site-packages\torch\nn\modules\module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\dadou\anaconda3\envs\Advanced-Programming\Lib\site-packages\torch\nn\modules\activation.py", line 1241, in forward
    attn_output, attn_output_weights = F.multi_head_attention_forward(
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\dadou\anaconda3\envs\Advanced-Programming\Lib\site-packages\torch\nn\functional.py", line 5479, in multi_head_attention_forward
    attn_output = linear(attn_output, out_proj_weight, out_proj_bias)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([64, 1, 10])
[33mx permuted and embedding:[39m --> (None, None, None):  torch.Size([64, 10, 128])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 128])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 128])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([64, 10, 128])
[33mx permuted and fc_decoded[39m --> (None, None, None):  torch.Size([64, 10, 1])
signal torch.Size([64, 1, 10]) tensor([[7.8272, 7.8269, 7.8275, 7.8279, 7.8283, 7.8274, 7.8283, 7.8292, 7.8292,
         7.8289]])
preds torch.Size([64, 1, 10]) tensor([[7.8254, 7.7815, 7.7901, 7.7127, 7.7634, 7.8057, 7.7892, 7.8507, 7.8031,
         7.7637]], grad_fn=<ToCopyBackward0>)
targets torch.Size([64, 1, 10]) tensor([[7.8269, 7.8275, 7.8279, 7.8283, 7.8274, 7.8283, 7.8292, 7.8292, 7.8289,
         7.8287]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([64, 1, 10])
[33mx permuted and embedding:[39m --> (None, None, None):  torch.Size([64, 10, 128])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 128])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 128])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([64, 10, 128])
[33mx permuted and fc_decoded[39m --> (None, None, None):  torch.Size([64, 10, 1])
signal torch.Size([64, 1, 10]) tensor([[7.8425, 7.8421, 7.8426, 7.8430, 7.8428, 7.8428, 7.8424, 7.8420, 7.8422,
         7.8422]])
preds torch.Size([64, 1, 10]) tensor([[7.7827, 7.7848, 7.8452, 7.8160, 7.7764, 7.7224, 7.7736, 7.7660, 7.6908,
         7.8124]], grad_fn=<ToCopyBackward0>)
targets torch.Size([64, 1, 10]) tensor([[7.8421, 7.8426, 7.8430, 7.8428, 7.8428, 7.8424, 7.8420, 7.8422, 7.8422,
         7.8421]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([64, 1, 10])
[33mx permuted and embedding:[39m --> (None, None, None):  torch.Size([64, 10, 128])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 128])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 128])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([64, 10, 128])
[33mx permuted and fc_decoded[39m --> (None, None, None):  torch.Size([64, 10, 1])
signal torch.Size([64, 1, 10]) tensor([[7.7074, 7.7065, 7.7064, 7.7057, 7.7044, 7.7049, 7.7047, 7.7041, 7.7035,
         7.7036]])
preds torch.Size([64, 1, 10]) tensor([[7.7434, 7.6487, 7.7333, 7.7562, 7.6492, 7.7541, 7.6863, 7.7238, 7.6857,
         7.7394]], grad_fn=<ToCopyBackward0>)
targets torch.Size([64, 1, 10]) tensor([[7.7065, 7.7064, 7.7057, 7.7044, 7.7049, 7.7047, 7.7041, 7.7035, 7.7036,
         7.7045]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([64, 1, 10])
[33mx permuted and embedding:[39m --> (None, None, None):  torch.Size([64, 10, 128])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 128])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 128])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([64, 10, 128])
[33mx permuted and fc_decoded[39m --> (None, None, None):  torch.Size([64, 10, 1])
signal torch.Size([64, 1, 10]) tensor([[7.6891, 7.6880, 7.6900, 7.6894, 7.6906, 7.6898, 7.6880, 7.6825, 7.6847,
         7.6857]])
preds torch.Size([64, 1, 10]) tensor([[7.7964, 7.7584, 7.7614, 7.8017, 7.8195, 7.6487, 7.7111, 7.8272, 7.7865,
         7.7029]], grad_fn=<ToCopyBackward0>)
targets torch.Size([64, 1, 10]) tensor([[7.6880, 7.6900, 7.6894, 7.6906, 7.6898, 7.6880, 7.6825, 7.6847, 7.6857,
         7.6852]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([64, 1, 10])
[33mx permuted and embedding:[39m --> (None, None, None):  torch.Size([64, 10, 128])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 128])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 128])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([64, 10, 128])
[33mx permuted and fc_decoded[39m --> (None, None, None):  torch.Size([64, 10, 1])
signal torch.Size([64, 1, 10]) tensor([[7.8378, 7.8379, 7.8377, 7.8382, 7.8380, 7.8396, 7.8398, 7.8385, 7.8383,
         7.8383]])
preds torch.Size([64, 1, 10]) tensor([[7.7998, 7.7502, 7.7851, 7.7612, 7.7888, 7.7818, 7.7896, 7.7189, 7.8622,
         7.7181]], grad_fn=<ToCopyBackward0>)
targets torch.Size([64, 1, 10]) tensor([[7.8379, 7.8377, 7.8382, 7.8380, 7.8396, 7.8398, 7.8385, 7.8383, 7.8383,
         7.8387]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([64, 1, 10])
[33mx permuted and embedding:[39m --> (None, None, None):  torch.Size([64, 10, 128])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 128])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 128])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([64, 10, 128])
[33mx permuted and fc_decoded[39m --> (None, None, None):  torch.Size([64, 10, 1])
signal torch.Size([64, 1, 10]) tensor([[7.7307, 7.7304, 7.7301, 7.7298, 7.7300, 7.7301, 7.7301, 7.7297, 7.7293,
         7.7284]])
preds torch.Size([64, 1, 10]) tensor([[7.7378, 7.7427, 7.8361, 7.7895, 7.7712, 7.8142, 7.7187, 7.8540, 7.7623,
         7.7759]], grad_fn=<ToCopyBackward0>)
targets torch.Size([64, 1, 10]) tensor([[7.7304, 7.7301, 7.7298, 7.7300, 7.7301, 7.7301, 7.7297, 7.7293, 7.7284,
         7.7277]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([64, 1, 10])
[33mx permuted and embedding:[39m --> (None, None, None):  torch.Size([64, 10, 128])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 128])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 128])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([64, 10, 128])
[33mx permuted and fc_decoded[39m --> (None, None, None):  torch.Size([64, 10, 1])
signal torch.Size([64, 1, 10]) tensor([[7.7192, 7.7197, 7.7200, 7.7200, 7.7198, 7.7195, 7.7194, 7.7209, 7.7206,
         7.7213]])
preds torch.Size([64, 1, 10]) tensor([[7.7617, 7.7861, 7.7897, 7.7385, 7.7500, 7.7591, 7.7286, 7.7751, 7.7456,
         7.7730]], grad_fn=<ToCopyBackward0>)
targets torch.Size([64, 1, 10]) tensor([[7.7197, 7.7200, 7.7200, 7.7198, 7.7195, 7.7194, 7.7209, 7.7206, 7.7213,
         7.7209]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([64, 1, 10])
[33mx permuted and embedding:[39m --> (None, None, None):  torch.Size([64, 10, 128])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 128])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 128])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([64, 10, 128])
[33mx permuted and fc_decoded[39m --> (None, None, None):  torch.Size([64, 10, 1])
signal torch.Size([64, 1, 10]) tensor([[7.7064, 7.7068, 7.7074, 7.7071, 7.7087, 7.7076, 7.7077, 7.7078, 7.7064,
         7.7070]])
preds torch.Size([64, 1, 10]) tensor([[7.7672, 7.7800, 7.8314, 7.8037, 7.7725, 7.7785, 7.7804, 7.8072, 7.7352,
         7.7617]], grad_fn=<ToCopyBackward0>)
targets torch.Size([64, 1, 10]) tensor([[7.7068, 7.7074, 7.7071, 7.7087, 7.7076, 7.7077, 7.7078, 7.7064, 7.7070,
         7.7067]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([64, 1, 10])
[33mx permuted and embedding:[39m --> (None, None, None):  torch.Size([64, 10, 128])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 128])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 128])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([64, 10, 128])
[33mx permuted and fc_decoded[39m --> (None, None, None):  torch.Size([64, 10, 1])
signal torch.Size([64, 1, 10]) tensor([[7.7118, 7.7111, 7.7108, 7.7111, 7.7109, 7.7107, 7.7107, 7.7110, 7.7111,
         7.7110]])
preds torch.Size([64, 1, 10]) tensor([[7.7726, 7.8274, 7.8279, 7.8256, 7.7549, 7.7128, 7.8125, 7.8553, 7.8141,
         7.7601]], grad_fn=<ToCopyBackward0>)
targets torch.Size([64, 1, 10]) tensor([[7.7111, 7.7108, 7.7111, 7.7109, 7.7107, 7.7107, 7.7110, 7.7111, 7.7110,
         7.7113]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([64, 1, 10])
[33mx permuted and embedding:[39m --> (None, None, None):  torch.Size([64, 10, 128])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 128])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 128])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([64, 10, 128])
[33mx permuted and fc_decoded[39m --> (None, None, None):  torch.Size([64, 10, 1])
signal torch.Size([64, 1, 10]) tensor([[7.7519, 7.7518, 7.7513, 7.7515, 7.7526, 7.7525, 7.7521, 7.7520, 7.7523,
         7.7525]])
preds torch.Size([64, 1, 10]) tensor([[7.8196, 7.8348, 7.7816, 7.7322, 7.7263, 7.7982, 7.7542, 7.7902, 7.8226,
         7.8567]], grad_fn=<ToCopyBackward0>)
targets torch.Size([64, 1, 10]) tensor([[7.7518, 7.7513, 7.7515, 7.7526, 7.7525, 7.7521, 7.7520, 7.7523, 7.7525,
         7.7529]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([64, 1, 10])
[33mx permuted and embedding:[39m --> (None, None, None):  torch.Size([64, 10, 128])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 128])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 128])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([64, 10, 128])
[33mx permuted and fc_decoded[39m --> (None, None, None):  torch.Size([64, 10, 1])
signal torch.Size([64, 1, 10]) tensor([[7.7148, 7.7147, 7.7150, 7.7149, 7.7155, 7.7157, 7.7157, 7.7159, 7.7160,
         7.7157]])
preds torch.Size([64, 1, 10]) tensor([[7.7793, 7.7599, 7.7056, 7.8279, 7.6853, 7.7857, 7.7617, 7.7782, 7.7850,
         7.7276]], grad_fn=<ToCopyBackward0>)
targets torch.Size([64, 1, 10]) tensor([[7.7147, 7.7150, 7.7149, 7.7155, 7.7157, 7.7157, 7.7159, 7.7160, 7.7157,
         7.7154]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([64, 1, 10])
[33mx permuted and embedding:[39m --> (None, None, None):  torch.Size([64, 10, 128])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 128])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 128])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([64, 10, 128])
[33mx permuted and fc_decoded[39m --> (None, None, None):  torch.Size([64, 10, 1])
signal torch.Size([64, 1, 10]) tensor([[7.7145, 7.7144, 7.7144, 7.7145, 7.7147, 7.7151, 7.7150, 7.7161, 7.7154,
         7.7161]])
preds torch.Size([64, 1, 10]) tensor([[7.7577, 7.7116, 7.7861, 7.7501, 7.7585, 7.7848, 7.7071, 7.7331, 7.7531,
         7.7092]], grad_fn=<ToCopyBackward0>)
targets torch.Size([64, 1, 10]) tensor([[7.7144, 7.7144, 7.7145, 7.7147, 7.7151, 7.7150, 7.7161, 7.7154, 7.7161,
         7.7163]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([64, 1, 10])
[33mx permuted and embedding:[39m --> (None, None, None):  torch.Size([64, 10, 128])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 128])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 128])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([64, 10, 128])
[33mx permuted and fc_decoded[39m --> (None, None, None):  torch.Size([64, 10, 1])
signal torch.Size([64, 1, 10]) tensor([[7.8946, 7.8963, 7.8971, 7.8985, 7.8993, 7.8993, 7.9018, 7.9039, 7.9032,
         7.9043]])
preds torch.Size([64, 1, 10]) tensor([[7.6999, 7.8212, 7.7135, 7.8110, 7.7909, 7.8060, 7.8512, 7.7201, 7.8229,
         7.7851]], grad_fn=<ToCopyBackward0>)
targets torch.Size([64, 1, 10]) tensor([[7.8963, 7.8971, 7.8985, 7.8993, 7.8993, 7.9018, 7.9039, 7.9032, 7.9043,
         7.9013]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([64, 1, 10])
[33mx permuted and embedding:[39m --> (None, None, None):  torch.Size([64, 10, 128])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 128])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 128])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([64, 10, 128])
[33mx permuted and fc_decoded[39m --> (None, None, None):  torch.Size([64, 10, 1])
signal torch.Size([64, 1, 10]) tensor([[7.7738, 7.7732, 7.7735, 7.7740, 7.7732, 7.7734, 7.7734, 7.7741, 7.7741,
         7.7728]])
preds torch.Size([64, 1, 10]) tensor([[7.8128, 7.8120, 7.8088, 7.8008, 7.8391, 7.7327, 7.7848, 7.7687, 7.7757,
         7.7001]], grad_fn=<ToCopyBackward0>)
targets torch.Size([64, 1, 10]) tensor([[7.7732, 7.7735, 7.7740, 7.7732, 7.7734, 7.7734, 7.7741, 7.7741, 7.7728,
         7.7730]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([64, 1, 10])
[33mx permuted and embedding:[39m --> (None, None, None):  torch.Size([64, 10, 128])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 128])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 128])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([64, 10, 128])
[33mx permuted and fc_decoded[39m --> (None, None, None):  torch.Size([64, 10, 1])
signal torch.Size([64, 1, 10]) tensor([[7.7133, 7.7129, 7.7134, 7.7130, 7.7124, 7.7120, 7.7128, 7.7117, 7.7118,
         7.7109]])
preds torch.Size([64, 1, 10]) tensor([[7.6661, 7.7758, 7.7200, 7.7680, 7.7853, 7.7364, 7.7510, 7.7345, 7.7746,
         7.6944]], grad_fn=<ToCopyBackward0>)
targets torch.Size([64, 1, 10]) tensor([[7.7129, 7.7134, 7.7130, 7.7124, 7.7120, 7.7128, 7.7117, 7.7118, 7.7109,
         7.7114]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([64, 1, 10])
[33mx permuted and embedding:[39m --> (None, None, None):  torch.Size([64, 10, 128])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 128])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 128])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([64, 10, 128])
[33mx permuted and fc_decoded[39m --> (None, None, None):  torch.Size([64, 10, 1])
signal torch.Size([64, 1, 10]) tensor([[7.8660, 7.8666, 7.8648, 7.8640, 7.8645, 7.8640, 7.8639, 7.8658, 7.8659,
         7.8663]])
preds torch.Size([64, 1, 10]) tensor([[7.7805, 7.7175, 7.8289, 7.7723, 7.7480, 7.7799, 7.7684, 7.8171, 7.7688,
         7.7857]], grad_fn=<ToCopyBackward0>)
targets torch.Size([64, 1, 10]) tensor([[7.8666, 7.8648, 7.8640, 7.8645, 7.8640, 7.8639, 7.8658, 7.8659, 7.8663,
         7.8658]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([64, 1, 10])
[33mx permuted and embedding:[39m --> (None, None, None):  torch.Size([64, 10, 128])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 128])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 128])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 64, 128])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 64, 128])
  0%|          | 0/350 [00:00<?, ?it/s]C:\Users\dadou\anaconda3\envs\Advanced-Programming\Lib\site-packages\torch\nn\functional.py:5476: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\aten\src\ATen\native\transformers\cuda\sdp_utils.cpp:263.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0769e+01,  1.0768e+01,  1.0769e+01,  1.0767e+01,  1.0766e+01,
          1.0765e+01,  1.0762e+01,  1.0762e+01,  1.0762e+01,  1.0762e+01],
        [-3.9860e-02, -4.2358e-02, -4.1857e-02, -4.4857e-02, -4.9749e-02,
         -5.8002e-02, -7.2516e-02, -8.5138e-02, -9.3209e-02, -9.7807e-02],
        [-4.3168e-02, -4.3727e-02, -4.4066e-02, -4.4987e-02, -4.6787e-02,
         -5.0017e-02, -5.5751e-02, -6.3078e-02, -7.0690e-02, -7.7779e-02],
        [-1.9914e-04, -5.3177e-03, -3.2196e-03, -8.7676e-03, -1.7114e-02,
         -3.0727e-02, -5.4544e-02, -6.9692e-02, -7.2416e-02, -6.7424e-02],
        [ 5.1473e-01,  4.6534e-01,  5.0858e-01,  4.6408e-01,  4.0288e-01,
          3.7362e-01,  2.6563e-01,  2.6306e-01,  2.5904e-01,  3.3959e-01],
        [ 1.8052e-01,  1.3817e-01,  1.6624e-01,  1.3735e-01,  9.7600e-02,
          7.8601e-02,  8.4610e-03,  6.7926e-03,  4.1879e-03,  5.6503e-02],
        [-3.1646e-02, -3.0296e-02,  2.2933e-02,  1.9007e-02,  3.9304e-02,
         -6.2942e-02, -4.5579e-02,  3.6215e-02,  7.7636e-02,  5.6586e-02],
        [-2.3674e-02, -1.7536e-02, -1.5344e-02, -1.1399e-02, -1.1837e-02,
         -1.4029e-02, -1.9290e-02, -2.6743e-02, -3.5072e-02, -4.4717e-02]])
preds tensor([[-0.0062, -0.0062, -0.0061, -0.0076, -0.0042, -0.0040, -0.0049, -0.0062,
         -0.0037, -0.0048]], grad_fn=<ToCopyBackward0>)
targets tensor([[10.7680, 10.7687, 10.7674, 10.7665, 10.7649, 10.7622, 10.7616, 10.7618,
         10.7620, 10.7621]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0905e+01,  1.0904e+01,  1.0904e+01,  1.0904e+01,  1.0904e+01,
          1.0904e+01,  1.0904e+01,  1.0903e+01,  1.0904e+01,  1.0903e+01],
        [ 8.0940e-03,  5.0659e-03,  1.2216e-03,  1.3871e-03, -1.1886e-06,
         -1.6145e-03, -4.3142e-03, -7.1894e-03, -6.4121e-03, -1.0540e-02],
        [ 1.2935e-02,  1.1447e-02,  9.4229e-03,  7.8394e-03,  6.2712e-03,
          4.6666e-03,  2.7970e-03,  6.7731e-04, -8.4968e-04, -2.9671e-03],
        [-9.8737e-03, -1.4150e-02, -1.9256e-02, -1.5063e-02, -1.4917e-02,
         -1.5264e-02, -1.7784e-02, -2.0163e-02, -1.4525e-02, -2.0142e-02],
        [ 4.7302e-01,  4.4696e-01,  2.9057e-01,  4.2777e-01,  4.8124e-01,
          4.5377e-01,  4.1631e-01,  3.9474e-01,  5.4109e-01,  3.6488e-01],
        [ 1.4249e-02, -3.7283e-03, -1.0555e-01,  8.0899e-02,  1.1272e-01,
          9.6476e-02,  7.4328e-02,  6.1576e-02,  2.0518e-01,  5.0494e-02],
        [-1.5190e-02, -1.1624e-02, -9.4819e-03, -5.5558e-03, -3.3676e-02,
         -4.7578e-03,  1.5023e-02,  1.9290e-02,  7.1532e-03,  6.8790e-03],
        [-3.0688e-03, -3.9456e-03, -4.3840e-03, -6.1377e-03, -6.1377e-03,
         -5.6993e-03, -4.8224e-03, -5.6993e-03, -7.0145e-03, -6.1377e-03]])
preds tensor([[0.0040, 0.0029, 0.0036, 0.0007, 0.0046, 0.0026, 0.0034, 0.0028, 0.0033,
         0.0033]], grad_fn=<ToCopyBackward0>)
targets tensor([[10.9040, 10.9036, 10.9045, 10.9041, 10.9039, 10.9035, 10.9033, 10.9041,
         10.9028, 10.9029]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0993e+01,  1.0992e+01,  1.0992e+01,  1.0992e+01,  1.0990e+01,
          1.0992e+01,  1.0996e+01,  1.0995e+01,  1.0996e+01,  1.0996e+01],
        [-1.2842e-01, -1.3334e-01, -1.3666e-01, -1.3778e-01, -1.4248e-01,
         -1.3891e-01, -1.1904e-01, -1.0499e-01, -8.7288e-02, -7.2596e-02],
        [-1.1300e-01, -1.1933e-01, -1.2512e-01, -1.3000e-01, -1.3492e-01,
         -1.3809e-01, -1.3630e-01, -1.3183e-01, -1.2441e-01, -1.1528e-01],
        [-6.2676e-02, -6.0298e-02, -5.5080e-02, -4.6393e-02, -4.6816e-02,
         -3.0084e-02,  1.6961e-02,  4.2569e-02,  7.0603e-02,  8.6812e-02],
        [ 2.1072e-01,  1.5599e-01,  1.7923e-01,  2.0199e-01,  1.8763e-01,
          2.4001e-01,  4.4951e-01,  4.3203e-01,  5.1331e-01,  5.4889e-01],
        [ 1.2070e-01,  6.3092e-02,  1.1830e-01,  1.5492e-01,  1.3180e-01,
          2.2591e-01,  4.7862e-01,  1.6110e-01,  2.0364e-01,  1.8582e-01],
        [-4.7018e-02, -8.4562e-03, -1.9120e-02, -4.6528e-03, -2.6624e-02,
         -4.3106e-02, -3.7469e-02,  1.2592e-02, -4.3325e-02, -8.1259e-02],
        [-6.1377e-02, -6.0938e-02, -6.1815e-02, -6.1815e-02, -5.9623e-02,
         -5.9623e-02, -5.6554e-02, -4.6471e-02, -3.8141e-02, -2.8496e-02]])
preds tensor([[0.0064, 0.0060, 0.0076, 0.0069, 0.0051, 0.0061, 0.0066, 0.0063, 0.0062,
         0.0069]], grad_fn=<ToCopyBackward0>)
targets tensor([[10.9920, 10.9918, 10.9918, 10.9904, 10.9918, 10.9957, 10.9950, 10.9963,
         10.9963, 10.9984]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0437e+01,  1.0438e+01,  1.0437e+01,  1.0437e+01,  1.0437e+01,
          1.0437e+01,  1.0438e+01,  1.0437e+01,  1.0438e+01,  1.0438e+01],
        [ 2.7301e-03,  6.4495e-03,  6.9785e-03,  6.2901e-03,  6.0414e-03,
          5.7567e-03,  6.8897e-03,  6.9443e-03,  8.4488e-03,  8.4415e-03],
        [-2.5512e-03, -6.4129e-04,  1.0014e-03,  2.1662e-03,  3.0441e-03,
          3.6847e-03,  4.4429e-03,  5.0614e-03,  5.8827e-03,  6.5381e-03],
        [ 1.3112e-02,  1.8168e-02,  1.5626e-02,  1.1080e-02,  8.3505e-03,
          6.0926e-03,  7.2130e-03,  5.8832e-03,  7.8122e-03,  6.2346e-03],
        [ 5.0451e-01,  5.6891e-01,  5.0758e-01,  4.9391e-01,  5.5694e-01,
          5.7951e-01,  6.1771e-01,  6.0312e-01,  6.2594e-01,  6.8053e-01],
        [ 1.2300e-01,  1.6027e-01,  1.3633e-01,  1.3914e-01,  1.6527e-01,
          1.7463e-01,  1.8568e-01,  1.6483e-01,  1.7329e-01,  1.9013e-01],
        [-1.7055e-02, -2.4864e-02, -2.9609e-02, -3.0442e-02, -2.9148e-02,
         -5.5439e-02, -3.6773e-02,  8.8892e-04,  2.9809e-02,  3.3719e-02],
        [-1.1399e-02, -8.3297e-03, -2.6304e-03,  8.7681e-04,  3.0688e-03,
          6.5761e-03,  9.2065e-03,  1.3591e-02,  1.5344e-02,  1.6221e-02]])
preds tensor([[0.0070, 0.0085, 0.0087, 0.0069, 0.0089, 0.0085, 0.0065, 0.0085, 0.0084,
         0.0090]], grad_fn=<ToCopyBackward0>)
targets tensor([[10.4383, 10.4373, 10.4369, 10.4370, 10.4370, 10.4376, 10.4373, 10.4380,
         10.4375, 10.4378]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0924e+01,  1.0924e+01,  1.0922e+01,  1.0922e+01,  1.0922e+01,
          1.0921e+01,  1.0921e+01,  1.0922e+01,  1.0921e+01,  1.0923e+01],
        [-1.5975e-02, -2.2058e-02, -3.6098e-02, -4.5303e-02, -5.2347e-02,
         -6.0231e-02, -6.7750e-02, -6.7785e-02, -7.0222e-02, -6.4330e-02],
        [-5.4737e-03, -9.1661e-03, -1.5167e-02, -2.1965e-02, -2.8933e-02,
         -3.6218e-02, -4.3677e-02, -4.9653e-02, -5.4962e-02, -5.7930e-02],
        [-2.8207e-02, -3.5123e-02, -5.7081e-02, -6.4668e-02, -6.6274e-02,
         -6.9296e-02, -7.0959e-02, -5.6838e-02, -5.0503e-02, -2.8238e-02],
        [ 3.8618e-01,  4.8691e-01,  3.6650e-01,  3.4602e-01,  3.4553e-01,
          3.5611e-01,  2.6627e-01,  3.0346e-01,  2.8762e-01,  3.8733e-01],
        [-1.0998e-02,  7.0582e-02, -1.3790e-02, -1.3279e-02, -3.0644e-04,
          9.7378e-03, -7.2880e-02,  2.3953e-02,  1.4573e-02,  9.2816e-02],
        [-1.0745e-02, -4.5669e-02,  9.4531e-03,  3.7920e-02,  4.5432e-02,
          2.7361e-02,  8.2487e-02,  1.1097e-01,  3.0029e-02,  2.6046e-03],
        [-3.9456e-03, -8.7681e-03, -1.0083e-02, -1.4906e-02, -2.0605e-02,
         -2.6304e-02, -3.1127e-02, -3.6826e-02, -4.1210e-02, -4.6032e-02]])
preds tensor([[0.0106, 0.0103, 0.0100, 0.0096, 0.0104, 0.0100, 0.0104, 0.0100, 0.0102,
         0.0102]], grad_fn=<ToCopyBackward0>)
targets tensor([[10.9241, 10.9216, 10.9219, 10.9218, 10.9211, 10.9205, 10.9219, 10.9210,
         10.9229, 10.9215]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0672e+01,  1.0672e+01,  1.0672e+01,  1.0673e+01,  1.0673e+01,
          1.0673e+01,  1.0672e+01,  1.0672e+01,  1.0673e+01,  1.0673e+01],
        [ 1.8539e-03,  1.9995e-03,  2.6008e-03,  4.4720e-03,  5.8037e-03,
          7.9520e-03,  7.7117e-03,  7.0165e-03,  7.7429e-03,  8.2672e-03],
        [-1.7983e-04,  2.9001e-04,  7.9643e-04,  1.6077e-03,  2.5457e-03,
          3.7623e-03,  4.6835e-03,  5.2695e-03,  5.8960e-03,  6.5109e-03],
        [ 5.2115e-03,  4.4699e-03,  4.8171e-03,  7.7165e-03,  8.9225e-03,
          1.1573e-02,  8.7623e-03,  5.5745e-03,  5.9592e-03,  5.8497e-03],
        [ 5.3070e-01,  4.9134e-01,  5.4369e-01,  5.8685e-01,  4.8873e-01,
          5.5761e-01,  4.9829e-01,  5.0862e-01,  5.4331e-01,  6.5042e-01],
        [ 5.0681e-02,  1.3875e-02,  4.2731e-02,  7.7954e-02, -2.1280e-03,
          5.5516e-02,  7.6949e-03,  1.6020e-02,  4.3990e-02,  1.3032e-01],
        [ 3.2940e-02,  2.3992e-02,  2.0179e-02,  1.1017e-02,  1.0004e-02,
         -1.7588e-02, -1.5778e-03,  9.2758e-03, -9.1415e-03, -1.4286e-02],
        [ 1.1399e-02,  9.6449e-03,  6.5761e-03,  4.8224e-03,  4.3840e-03,
          3.5072e-03,  3.5072e-03,  3.5072e-03,  3.0688e-03,  3.0688e-03]])
preds tensor([[0.0117, 0.0120, 0.0119, 0.0118, 0.0110, 0.0112, 0.0121, 0.0122, 0.0113,
         0.0119]], grad_fn=<ToCopyBackward0>)
targets tensor([[10.6720, 10.6721, 10.6726, 10.6726, 10.6730, 10.6724, 10.6722, 10.6727,
         10.6727, 10.6718]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0773e+01,  1.0773e+01,  1.0773e+01,  1.0774e+01,  1.0773e+01,
          1.0773e+01,  1.0773e+01,  1.0773e+01,  1.0773e+01,  1.0773e+01],
        [-3.0835e-03, -6.5093e-04,  2.1476e-03,  5.2271e-03,  7.0325e-03,
          7.3983e-03,  6.8969e-03,  7.2023e-03,  8.2724e-03,  8.3671e-03],
        [-2.5023e-03, -2.1431e-03, -1.2484e-03,  1.3570e-04,  1.6348e-03,
          2.9134e-03,  3.8275e-03,  4.6250e-03,  5.4953e-03,  6.2121e-03],
        [-2.0061e-03,  3.4168e-03,  8.5104e-03,  1.3166e-02,  1.4260e-02,
          1.2163e-02,  8.6951e-03,  7.5865e-03,  8.2784e-03,  6.8182e-03],
        [ 5.9938e-01,  6.1067e-01,  5.9491e-01,  6.6919e-01,  6.7826e-01,
          6.0608e-01,  6.0394e-01,  6.2786e-01,  7.2749e-01,  6.5124e-01],
        [ 2.3269e-01,  1.7574e-01,  1.6280e-01,  1.9789e-01,  1.7394e-01,
          1.4152e-01,  1.4067e-01,  1.5019e-01,  1.8984e-01,  1.4244e-01],
        [-1.7030e-02, -9.9804e-03, -1.4356e-02, -1.2992e-02, -2.4325e-02,
         -1.0589e-02, -1.3730e-02, -1.9384e-02, -9.5236e-03, -1.2223e-03],
        [-1.1837e-02, -8.3297e-03, -4.8224e-03, -1.7536e-03,  1.7536e-03,
          4.3840e-03,  6.5761e-03,  7.4529e-03,  8.3297e-03,  1.0083e-02]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.7731, 10.7733, 10.7736, 10.7735, 10.7732, 10.7729, 10.7732, 10.7735,
         10.7733, 10.7730]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0634e+01,  1.0633e+01,  1.0633e+01,  1.0633e+01,  1.0633e+01,
          1.0633e+01,  1.0632e+01,  1.0633e+01,  1.0633e+01,  1.0633e+01],
        [-2.8965e-02, -2.6066e-02, -2.4940e-02, -2.3957e-02, -2.2633e-02,
         -2.1833e-02, -2.2088e-02, -2.0340e-02, -1.7510e-02, -1.6629e-02],
        [-3.6617e-02, -3.4950e-02, -3.3373e-02, -3.1897e-02, -3.0430e-02,
         -2.9082e-02, -2.8059e-02, -2.6862e-02, -2.5289e-02, -2.3840e-02],
        [ 1.2334e-02,  1.5853e-02,  1.5007e-02,  1.4033e-02,  1.3960e-02,
          1.2819e-02,  9.7302e-03,  1.1392e-02,  1.4956e-02,  1.3782e-02],
        [ 5.5101e-01,  5.8003e-01,  5.0201e-01,  3.9311e-01,  4.2805e-01,
          4.0977e-01,  4.0497e-01,  4.8002e-01,  6.4865e-01,  5.1516e-01],
        [ 2.1246e-01,  1.8134e-01,  1.4115e-01,  9.4246e-02,  1.0846e-01,
          1.0102e-01,  9.9081e-02,  1.2426e-01,  2.0308e-01,  9.5523e-02],
        [ 3.9233e-03,  6.6599e-03, -4.6407e-04,  9.7094e-04, -2.2087e-02,
         -7.0963e-03, -5.7453e-03, -3.1424e-03, -3.0291e-03, -8.5880e-03],
        [-8.3297e-03, -5.6993e-03, -3.5072e-03, -2.6304e-03, -2.6304e-03,
         -2.1920e-03, -1.7536e-03, -2.1920e-03, -2.1920e-03, -4.3840e-04]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.6334, 10.6329, 10.6328, 10.6329, 10.6328, 10.6324, 10.6330, 10.6334,
         10.6329, 10.6329]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.1047e+01,  1.1047e+01,  1.1046e+01,  1.1046e+01,  1.1046e+01,
          1.1046e+01,  1.1046e+01,  1.1046e+01,  1.1047e+01,  1.1047e+01],
        [ 6.0679e-03,  1.7467e-03, -3.2212e-03, -7.0768e-03, -1.1919e-02,
         -1.4105e-02, -1.5657e-02, -1.5274e-02, -1.3028e-02, -1.2256e-02],
        [ 1.1149e-02,  9.2980e-03,  6.7393e-03,  3.8557e-03,  4.9776e-04,
         -2.6629e-03, -5.5282e-03, -7.7373e-03, -9.0171e-03, -9.8735e-03],
        [-1.0854e-02, -1.7604e-02, -2.4339e-02, -2.7430e-02, -3.1941e-02,
         -3.0065e-02, -2.7255e-02, -2.1014e-02, -1.2174e-02, -8.1465e-03],
        [ 4.6171e-01,  3.3650e-01,  2.8909e-01,  2.8898e-01,  2.2656e-01,
          2.8814e-01,  2.9723e-01,  3.9461e-01,  4.4903e-01,  4.2454e-01],
        [ 1.9850e-02, -5.9738e-02, -2.2693e-02, -5.1073e-05, -2.8413e-02,
          2.4021e-02,  2.7596e-02,  8.7947e-02,  1.1643e-01,  1.0363e-01],
        [ 2.1189e-02,  1.7889e-02,  1.3702e-02, -6.4676e-03, -4.2744e-03,
         -1.0359e-03,  8.8910e-03,  5.7185e-03, -8.8013e-03,  2.0934e-02],
        [-8.7681e-04, -1.7536e-03, -3.9456e-03, -6.5761e-03, -8.3297e-03,
         -1.0522e-02, -1.1837e-02, -1.2714e-02, -1.2275e-02, -1.0960e-02]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[11.0465, 11.0462, 11.0462, 11.0457, 11.0461, 11.0461, 11.0464, 11.0468,
         11.0465, 11.0460]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0973e+01,  1.0973e+01,  1.0974e+01,  1.0972e+01,  1.0974e+01,
          1.0975e+01,  1.0976e+01,  1.0977e+01,  1.0974e+01,  1.0974e+01],
        [ 1.5387e-02,  2.5806e-02,  3.7906e-02,  4.0131e-02,  4.7131e-02,
          5.4558e-02,  6.3560e-02,  7.4651e-02,  7.1940e-02,  6.7972e-02],
        [-5.7328e-03,  1.0143e-03,  9.0378e-03,  1.5939e-02,  2.2980e-02,
          3.0224e-02,  3.7973e-02,  4.6579e-02,  5.2876e-02,  5.7052e-02],
        [ 5.3339e-02,  6.4180e-02,  7.6322e-02,  6.5650e-02,  6.6972e-02,
          6.8908e-02,  7.3711e-02,  8.1863e-02,  5.9895e-02,  3.9724e-02],
        [ 5.8593e-01,  5.7658e-01,  6.2556e-01,  5.9698e-01,  6.8236e-01,
          7.1761e-01,  7.1240e-01,  8.2045e-01,  6.9359e-01,  6.6423e-01],
        [ 1.7254e-01,  1.6370e-01,  1.9792e-01,  1.5306e-01,  2.0438e-01,
          1.8788e-01,  1.6788e-01,  2.1689e-01,  1.2508e-01,  1.1462e-01],
        [-7.2094e-02, -9.8502e-02, -5.8975e-02, -1.3068e-01, -1.1189e-01,
         -7.6780e-02, -2.3558e-02, -5.7271e-02,  5.5945e-03,  2.3221e-02],
        [-1.6659e-02, -7.0145e-03,  2.1920e-03,  1.2714e-02,  1.9290e-02,
          2.9373e-02,  3.9018e-02,  4.6032e-02,  5.3924e-02,  5.6116e-02]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.9731, 10.9742, 10.9725, 10.9739, 10.9745, 10.9755, 10.9767, 10.9740,
         10.9738, 10.9760]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0692e+01,  1.0693e+01,  1.0693e+01,  1.0693e+01,  1.0693e+01,
          1.0693e+01,  1.0693e+01,  1.0692e+01,  1.0692e+01,  1.0692e+01],
        [-1.4601e-02, -1.5453e-02, -1.5952e-02, -1.6871e-02, -1.6309e-02,
         -1.5595e-02, -1.5305e-02, -1.7572e-02, -1.8999e-02, -2.0592e-02],
        [-6.7529e-03, -8.7560e-03, -1.0467e-02, -1.2035e-02, -1.3167e-02,
         -1.3918e-02, -1.4456e-02, -1.5378e-02, -1.6426e-02, -1.7609e-02],
        [-2.1618e-02, -1.9054e-02, -1.6272e-02, -1.4917e-02, -1.0772e-02,
         -7.1433e-03, -5.1158e-03, -8.7733e-03, -9.9647e-03, -1.1259e-02],
        [ 1.1227e-01,  1.6716e-01,  1.8334e-01,  1.8844e-01,  2.6840e-01,
          2.8366e-01,  3.6258e-01,  3.2607e-01,  3.4418e-01,  3.1293e-01],
        [ 1.8556e-03,  1.6667e-02,  2.1025e-02,  2.4191e-02,  5.1992e-02,
          5.9431e-02,  1.1343e-01,  1.1074e-01,  1.1983e-01,  1.3737e-01],
        [ 1.1889e-02,  1.0096e-02, -1.4683e-02, -2.6136e-02, -2.5027e-02,
         -2.0387e-02, -1.3843e-02, -1.1250e-02, -7.4533e-03, -7.0712e-05],
        [-1.6659e-02, -1.9290e-02, -2.0605e-02, -2.0605e-02, -1.9728e-02,
         -1.7975e-02, -1.5783e-02, -1.3591e-02, -1.2275e-02, -1.1399e-02]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.6929, 10.6929, 10.6926, 10.6930, 10.6930, 10.6929, 10.6920, 10.6920,
         10.6918, 10.6922]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0653e+01,  1.0652e+01,  1.0653e+01,  1.0652e+01,  1.0652e+01,
          1.0653e+01,  1.0653e+01,  1.0654e+01,  1.0654e+01,  1.0653e+01],
        [-1.6443e-02, -1.5936e-02, -1.3997e-02, -1.3682e-02, -1.3130e-02,
         -1.1376e-02, -8.5399e-03, -5.6124e-03, -2.9378e-03, -1.4070e-03],
        [-2.0755e-02, -2.0062e-02, -1.9087e-02, -1.8239e-02, -1.7441e-02,
         -1.6422e-02, -1.4991e-02, -1.3210e-02, -1.1206e-02, -9.2701e-03],
        [ 6.9251e-03,  6.5864e-03,  9.2726e-03,  8.0694e-03,  7.5940e-03,
          9.6963e-03,  1.3612e-02,  1.6933e-02,  1.9067e-02,  1.8414e-02],
        [ 5.2700e-01,  4.7304e-01,  4.9820e-01,  4.5957e-01,  4.7023e-01,
          5.2297e-01,  5.2329e-01,  7.0643e-01,  6.5313e-01,  6.4467e-01],
        [ 2.2142e-01,  1.4409e-01,  1.5628e-01,  1.3757e-01,  1.4263e-01,
          1.6827e-01,  1.6832e-01,  2.6350e-01,  1.4942e-01,  1.4612e-01],
        [-3.3706e-03, -1.1578e-02,  2.3164e-03, -4.1446e-02, -1.3446e-02,
         -1.5581e-02, -1.6806e-02, -1.8120e-02, -6.4823e-03,  5.1658e-03],
        [-1.4467e-02, -1.0522e-02, -8.7681e-03, -6.1377e-03, -4.8224e-03,
         -2.6304e-03, -4.3840e-04,  1.3152e-03,  4.8224e-03,  7.4529e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.6524, 10.6529, 10.6524, 10.6524, 10.6529, 10.6533, 10.6535, 10.6536,
         10.6534, 10.6532]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0800e+01,  1.0800e+01,  1.0800e+01,  1.0800e+01,  1.0799e+01,
          1.0799e+01,  1.0799e+01,  1.0799e+01,  1.0798e+01,  1.0797e+01],
        [-1.0911e-02, -7.3502e-03, -5.9921e-03, -4.3072e-03, -3.8841e-03,
         -6.1281e-03, -5.1859e-03, -6.2991e-03, -9.3642e-03, -1.4347e-02],
        [-3.1140e-02, -2.6507e-02, -2.2506e-02, -1.8940e-02, -1.5995e-02,
         -1.4126e-02, -1.2426e-02, -1.1308e-02, -1.1078e-02, -1.1976e-02],
        [ 4.5896e-02,  4.4068e-02,  3.8058e-02,  3.3925e-02,  2.8013e-02,
          1.7778e-02,  1.6168e-02,  1.0636e-02,  2.1812e-03, -8.5415e-03],
        [ 6.2236e-01,  6.3857e-01,  5.9958e-01,  6.4335e-01,  7.3484e-01,
          4.8889e-01,  5.1302e-01,  4.7416e-01,  5.1771e-01,  3.9805e-01],
        [ 1.6478e-01,  1.7167e-01,  1.5381e-01,  1.7225e-01,  2.0836e-01,
          1.9663e-02,  3.3180e-02,  9.1590e-03,  3.6074e-02, -4.9694e-02],
        [-8.0927e-02,  4.0940e-03,  1.7159e-02,  1.3283e-02, -2.1860e-02,
         -4.0692e-03,  1.6244e-02,  1.6481e-02,  2.6564e-02,  3.2157e-02],
        [ 5.6993e-03,  1.0083e-02,  1.4467e-02,  1.4906e-02,  1.5783e-02,
          1.6659e-02,  1.4467e-02,  1.2714e-02,  9.6449e-03,  6.1377e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.8001, 10.7996, 10.7998, 10.7995, 10.7987, 10.7995, 10.7989, 10.7982,
         10.7974, 10.7971]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0764e+01,  1.0763e+01,  1.0763e+01,  1.0763e+01,  1.0763e+01,
          1.0763e+01,  1.0763e+01,  1.0764e+01,  1.0764e+01,  1.0764e+01],
        [-1.7065e-02, -2.0012e-02, -2.0904e-02, -2.0415e-02, -2.0076e-02,
         -1.9452e-02, -1.8986e-02, -1.7853e-02, -1.6670e-02, -1.2932e-02],
        [-1.5029e-02, -1.6367e-02, -1.7630e-02, -1.8535e-02, -1.9185e-02,
         -1.9569e-02, -1.9776e-02, -1.9695e-02, -1.9374e-02, -1.8305e-02],
        [-8.2946e-03, -1.2720e-02, -1.2016e-02, -8.6050e-03, -6.1831e-03,
         -3.6582e-03, -1.9643e-03,  7.6722e-04,  3.0562e-03,  1.0160e-02],
        [ 4.4263e-01,  4.3492e-01,  4.3731e-01,  4.3078e-01,  4.7373e-01,
          4.7877e-01,  4.6348e-01,  5.1803e-01,  4.8505e-01,  4.2635e-01],
        [ 8.7436e-02,  8.2108e-02,  8.3759e-02,  7.9231e-02,  1.1561e-01,
          1.1931e-01,  1.0807e-01,  1.4814e-01,  1.1410e-01,  6.1815e-02],
        [-2.3128e-02, -2.1859e-02, -1.3020e-02, -3.2213e-02, -1.3703e-02,
          3.5371e-02,  6.5286e-02, -5.0188e-03, -1.7610e-02, -1.7080e-02],
        [-1.1837e-02, -1.1837e-02, -1.1399e-02, -1.0960e-02, -1.0083e-02,
         -8.7681e-03, -7.8913e-03, -8.3297e-03, -8.7681e-03, -7.0145e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.7628, 10.7632, 10.7635, 10.7634, 10.7634, 10.7634, 10.7635, 10.7636,
         10.7644, 10.7649]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.1017e+01,  1.1016e+01,  1.1015e+01,  1.1016e+01,  1.1017e+01,
          1.1017e+01,  1.1017e+01,  1.1017e+01,  1.1015e+01,  1.1017e+01],
        [ 2.1099e-02,  1.4274e-02,  5.9283e-03,  3.7681e-03,  4.1404e-03,
          5.5416e-03,  3.8896e-03,  4.0891e-03, -2.3410e-03, -7.9348e-04],
        [ 3.5474e-02,  3.1477e-02,  2.6468e-02,  2.1992e-02,  1.8493e-02,
          1.5997e-02,  1.3642e-02,  1.1801e-02,  8.9324e-03,  6.9737e-03],
        [-2.9915e-02, -3.8021e-02, -4.7646e-02, -4.2576e-02, -3.3292e-02,
         -2.3741e-02, -2.2403e-02, -1.7511e-02, -2.7283e-02, -1.8631e-02],
        [ 4.6268e-01,  3.4937e-01,  3.1536e-01,  4.0314e-01,  3.9866e-01,
          4.5326e-01,  4.3611e-01,  5.5824e-01,  4.6916e-01,  4.7325e-01],
        [ 8.1035e-03, -4.9183e-02, -1.3432e-02,  3.6789e-02,  3.4917e-02,
          7.2506e-02,  7.1127e-02,  1.4484e-01,  9.1726e-02,  9.4161e-02],
        [ 6.1704e-02,  2.4894e-02,  1.8102e-02, -5.5968e-02, -4.8879e-02,
          2.4153e-03,  7.6159e-03,  1.9956e-02, -2.8037e-02,  9.4076e-03],
        [-8.7681e-04, -3.5072e-03, -8.7681e-03, -1.3591e-02, -1.4906e-02,
         -1.4467e-02, -1.2275e-02, -1.2275e-02, -1.0083e-02, -1.0083e-02]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[11.0160, 11.0153, 11.0164, 11.0169, 11.0172, 11.0165, 11.0169, 11.0153,
         11.0169, 11.0176]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0517e+01,  1.0516e+01,  1.0516e+01,  1.0517e+01,  1.0517e+01,
          1.0517e+01,  1.0516e+01,  1.0517e+01,  1.0517e+01,  1.0518e+01],
        [ 2.5183e-02,  2.4984e-02,  2.4196e-02,  2.6066e-02,  2.7102e-02,
          2.7937e-02,  2.4288e-02,  2.3130e-02,  2.2471e-02,  2.3706e-02],
        [ 2.9657e-02,  2.9147e-02,  2.8569e-02,  2.8512e-02,  2.8691e-02,
          2.9016e-02,  2.8484e-02,  2.7807e-02,  2.7122e-02,  2.6843e-02],
        [-5.5410e-03, -4.8441e-03, -5.5026e-03, -5.4201e-04,  1.7064e-03,
          3.0877e-03, -5.0625e-03, -6.4392e-03, -6.5117e-03, -2.6599e-03],
        [ 5.9822e-01,  6.0189e-01,  5.3009e-01,  6.6786e-01,  6.8349e-01,
          6.7615e-01,  4.9751e-01,  5.7205e-01,  5.3495e-01,  5.7609e-01],
        [ 7.0242e-02,  7.2217e-02,  3.3640e-02,  1.5553e-01,  1.8352e-01,
          1.6445e-01,  2.3681e-02,  8.2431e-02,  5.3201e-02,  8.5615e-02],
        [-1.1589e-02, -7.8874e-03,  5.2917e-03, -3.9269e-03,  1.2194e-02,
          1.2905e-02, -9.8523e-03, -1.4182e-02, -8.1623e-03, -5.5017e-03],
        [ 3.9456e-03,  5.2609e-03,  6.5761e-03,  6.5761e-03,  8.7681e-03,
          1.0522e-02,  1.1837e-02,  9.6449e-03,  1.0083e-02,  1.0083e-02]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.5163, 10.5161, 10.5173, 10.5172, 10.5173, 10.5157, 10.5165, 10.5167,
         10.5175, 10.5180]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0799e+01,  1.0798e+01,  1.0798e+01,  1.0798e+01,  1.0799e+01,
          1.0799e+01,  1.0799e+01,  1.0798e+01,  1.0798e+01,  1.0797e+01],
        [ 2.4838e-02,  2.3656e-02,  2.2392e-02,  2.0684e-02,  2.2884e-02,
          2.4750e-02,  2.4751e-02,  2.1572e-02,  1.7025e-02,  9.9905e-03],
        [ 2.4257e-02,  2.4539e-02,  2.4491e-02,  2.4082e-02,  2.4232e-02,
          2.4757e-02,  2.5177e-02,  2.4823e-02,  2.3553e-02,  2.1011e-02],
        [ 6.4099e-03,  2.6864e-03, -4.5854e-04, -3.8931e-03,  1.4264e-03,
          4.9924e-03,  3.9978e-03, -3.3651e-03, -1.2079e-02, -2.4185e-02],
        [ 6.5152e-01,  5.1770e-01,  5.7283e-01,  5.4101e-01,  6.3166e-01,
          6.2240e-01,  6.1402e-01,  5.8772e-01,  5.0401e-01,  4.0557e-01],
        [ 1.2426e-01,  1.5560e-02,  6.4624e-02,  3.6942e-02,  1.1580e-01,
          1.2470e-01,  1.2562e-01,  9.7004e-02, -1.6973e-02, -1.1095e-01],
        [ 1.5209e-03,  6.3994e-03, -3.4029e-03, -2.2219e-02, -1.0221e-02,
         -2.5101e-03,  3.9136e-03, -7.5336e-03, -5.3442e-03,  2.1221e-02],
        [ 5.6993e-03,  7.0145e-03,  6.5761e-03,  6.1377e-03,  6.1377e-03,
          7.8913e-03,  9.2065e-03,  9.6449e-03,  8.7681e-03,  7.4529e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.7982, 10.7982, 10.7981, 10.7992, 10.7993, 10.7990, 10.7981, 10.7975,
         10.7966, 10.7974]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.1074e+01,  1.1074e+01,  1.1075e+01,  1.1075e+01,  1.1076e+01,
          1.1077e+01,  1.1076e+01,  1.1075e+01,  1.1075e+01,  1.1074e+01],
        [-5.3349e-02, -5.3620e-02, -5.0275e-02, -4.8919e-02, -4.0932e-02,
         -3.1985e-02, -2.7531e-02, -2.6123e-02, -2.4282e-02, -2.7326e-02],
        [-4.2735e-02, -4.5825e-02, -4.7571e-02, -4.8673e-02, -4.7822e-02,
         -4.5199e-02, -4.2134e-02, -3.9376e-02, -3.6771e-02, -3.5347e-02],
        [-3.6036e-02, -2.9389e-02, -1.6607e-02, -1.0486e-02,  8.0998e-03,
          2.4949e-02,  2.9154e-02,  2.6230e-02,  2.4785e-02,  1.3544e-02],
        [ 3.2263e-01,  3.3439e-01,  3.0938e-01,  2.5392e-01,  4.2600e-01,
          4.8421e-01,  4.7526e-01,  4.6240e-01,  4.7067e-01,  4.0811e-01],
        [ 1.9986e-02,  2.9026e-02,  9.8059e-03, -3.2823e-02,  1.3521e-01,
          1.8095e-01,  1.6362e-01,  1.5412e-01,  1.6023e-01,  1.1399e-01],
        [ 3.0709e-02,  2.2768e-02,  6.8373e-03, -2.1123e-03,  1.1262e-03,
          7.2825e-03, -1.8986e-02, -5.5530e-02, -8.3563e-02, -5.0883e-02],
        [-1.7536e-02, -2.0605e-02, -2.1920e-02, -2.2359e-02, -2.3235e-02,
         -2.0167e-02, -1.6221e-02, -1.3152e-02, -1.0522e-02, -7.0145e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[11.0743, 11.0750, 11.0746, 11.0760, 11.0765, 11.0759, 11.0753, 11.0754,
         11.0743, 11.0743]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0542e+01,  1.0541e+01,  1.0539e+01,  1.0539e+01,  1.0540e+01,
          1.0540e+01,  1.0540e+01,  1.0541e+01,  1.0539e+01,  1.0541e+01],
        [ 1.2043e-02,  7.9436e-03,  8.7660e-04, -6.1358e-03, -8.8184e-03,
         -9.5959e-03, -9.3547e-03, -8.9819e-03, -1.3209e-02, -1.1545e-02],
        [ 2.0284e-02,  1.7951e-02,  1.4551e-02,  1.0309e-02,  6.3337e-03,
          2.9845e-03,  3.5745e-04, -1.6632e-03, -4.1973e-03, -5.8633e-03],
        [-1.7161e-02, -2.2191e-02, -3.2342e-02, -4.0350e-02, -3.7817e-02,
         -3.1859e-02, -2.4989e-02, -1.9222e-02, -2.4104e-02, -1.5848e-02],
        [ 4.8220e-01,  3.3336e-01,  2.4326e-01,  2.3135e-01,  2.2948e-01,
          2.7627e-01,  3.7620e-01,  3.8688e-01,  2.9480e-01,  4.1370e-01],
        [-5.5771e-02, -7.3510e-02, -3.1069e-02, -3.5921e-03, -5.9585e-04,
          1.5935e-02,  6.1474e-02,  6.5935e-02,  2.7358e-02,  7.7171e-02],
        [ 6.1487e-02,  5.3639e-02,  1.0516e-02,  7.9955e-03,  1.3657e-02,
          1.5011e-02, -2.1962e-04, -1.2959e-02,  2.3419e-03,  1.8179e-03],
        [ 1.0522e-02,  6.1377e-03, -1.3152e-03, -1.0083e-02, -1.6659e-02,
         -2.1482e-02, -2.4551e-02, -2.4989e-02, -2.3674e-02, -2.4989e-02]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.5407, 10.5392, 10.5387, 10.5397, 10.5402, 10.5405, 10.5405, 10.5387,
         10.5406, 10.5389]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0536e+01,  1.0533e+01,  1.0528e+01,  1.0529e+01,  1.0530e+01,
          1.0529e+01,  1.0526e+01,  1.0521e+01,  1.0523e+01,  1.0526e+01],
        [ 4.0423e-02,  3.4238e-02,  1.7450e-02,  6.0036e-03, -2.6744e-04,
         -6.7963e-03, -1.9513e-02, -4.1368e-02, -5.3582e-02, -5.5441e-02],
        [ 2.1283e-02,  2.4457e-02,  2.3353e-02,  1.9985e-02,  1.5930e-02,
          1.1269e-02,  4.7803e-03, -5.1535e-03, -1.5751e-02, -2.4633e-02],
        [ 5.3697e-02,  3.0189e-02, -1.0506e-02, -3.2034e-02, -3.8572e-02,
         -4.4336e-02, -6.1721e-02, -9.4493e-02, -1.0081e-01, -8.4484e-02],
        [ 6.4125e-01,  5.5582e-01,  4.4150e-01,  5.0572e-01,  4.8121e-01,
          4.4248e-01,  3.8715e-01,  2.6217e-01,  3.1188e-01,  3.9788e-01],
        [ 8.3946e-02, -5.6350e-03, -1.1604e-01,  3.8764e-02,  2.3970e-02,
          5.9585e-04, -3.2806e-02, -6.3245e-02,  2.0378e-02,  5.8580e-02],
        [-1.2261e-02,  4.8310e-03,  5.9014e-03,  6.9654e-02,  5.4503e-02,
          4.9003e-03,  6.5881e-02,  5.1717e-02,  6.8788e-02,  1.2958e-01],
        [ 4.5156e-02,  4.8224e-02,  4.3840e-02,  2.9811e-02,  2.0605e-02,
          1.0083e-02, -4.3840e-04, -1.2714e-02, -3.5511e-02, -5.1293e-02]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.5326, 10.5280, 10.5288, 10.5299, 10.5292, 10.5262, 10.5214, 10.5232,
         10.5260, 10.5302]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0997e+01,  1.0997e+01,  1.0996e+01,  1.0996e+01,  1.0996e+01,
          1.0996e+01,  1.0996e+01,  1.0996e+01,  1.0997e+01,  1.0996e+01],
        [ 1.4566e-02,  1.8236e-02,  1.6969e-02,  1.5878e-02,  1.6131e-02,
          1.3839e-02,  1.0609e-02,  1.0014e-02,  1.1590e-02,  9.7797e-03],
        [ 7.5599e-03,  1.0006e-02,  1.1687e-02,  1.2795e-02,  1.3737e-02,
          1.3993e-02,  1.3497e-02,  1.2971e-02,  1.2892e-02,  1.2436e-02],
        [ 1.9609e-02,  2.3263e-02,  1.5994e-02,  1.0543e-02,  8.9575e-03,
          2.4340e-03, -4.7197e-03, -5.0056e-03, -7.4904e-04, -4.3374e-03],
        [ 7.1520e-01,  7.3003e-01,  5.5562e-01,  6.2854e-01,  6.1840e-01,
          5.9641e-01,  5.3972e-01,  5.1251e-01,  5.3393e-01,  5.0745e-01],
        [ 1.8459e-01,  1.7620e-01,  7.6796e-02,  1.1587e-01,  1.1044e-01,
          9.4620e-02,  5.9499e-02, -2.4345e-02,  1.6769e-02, -3.9666e-03],
        [-5.9720e-04, -1.6570e-02, -1.0079e-02,  1.5355e-02,  2.3746e-02,
          5.4453e-03,  7.7295e-03,  1.4041e-02,  1.2413e-02,  5.8889e-03],
        [ 9.6449e-03,  1.1837e-02,  1.4029e-02,  1.3152e-02,  1.3152e-02,
          1.1837e-02,  1.0083e-02,  8.3297e-03,  6.5761e-03,  5.6993e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.9971, 10.9961, 10.9961, 10.9964, 10.9959, 10.9955, 10.9960, 10.9966,
         10.9959, 10.9957]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0673e+01,  1.0675e+01,  1.0674e+01,  1.0675e+01,  1.0674e+01,
          1.0678e+01,  1.0678e+01,  1.0678e+01,  1.0676e+01,  1.0677e+01],
        [-3.5303e-02, -2.7904e-02, -2.4015e-02, -1.6121e-02, -1.3847e-02,
         -1.7772e-03,  1.0457e-02,  1.7742e-02,  1.9231e-02,  2.2269e-02],
        [-3.2117e-02, -3.1750e-02, -3.0611e-02, -2.7988e-02, -2.5395e-02,
         -2.0702e-02, -1.4292e-02, -7.5833e-03, -1.8932e-03,  3.3182e-03],
        [-1.4721e-02,  3.4981e-03,  1.0825e-02,  2.4957e-02,  2.4660e-02,
          4.4644e-02,  6.0971e-02,  6.3817e-02,  5.4126e-02,  4.9572e-02],
        [ 3.9917e-01,  4.8805e-01,  4.7091e-01,  5.6392e-01,  4.8151e-01,
          5.6031e-01,  5.4719e-01,  5.7316e-01,  5.2875e-01,  5.7595e-01],
        [ 1.1866e-02,  6.6479e-02,  5.5941e-02,  1.1307e-01,  6.2462e-02,
          1.1086e-01,  1.0281e-01,  1.7879e-01,  1.3114e-01,  1.7269e-01],
        [ 1.7225e-02,  2.8525e-02,  6.7253e-02,  2.7889e-02,  3.2370e-02,
          4.6412e-03, -6.9240e-02, -1.0171e-01, -9.7942e-02, -4.4187e-02],
        [-1.4029e-02, -1.5783e-02, -1.4906e-02, -1.4906e-02, -1.1837e-02,
         -1.0522e-02, -4.3840e-03,  3.0688e-03,  1.1399e-02,  1.7098e-02]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.6747, 10.6739, 10.6755, 10.6741, 10.6775, 10.6785, 10.6777, 10.6763,
         10.6771, 10.6783]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0973e+01,  1.0974e+01,  1.0974e+01,  1.0975e+01,  1.0976e+01,
          1.0976e+01,  1.0977e+01,  1.0977e+01,  1.0977e+01,  1.0977e+01],
        [-4.6659e-02, -3.9066e-02, -2.9291e-02, -1.8095e-02, -7.4193e-03,
          2.7300e-03,  1.3297e-02,  2.2593e-02,  3.1377e-02,  3.6540e-02],
        [-5.4248e-02, -5.1877e-02, -4.7858e-02, -4.2214e-02, -3.5381e-02,
         -2.7712e-02, -1.9284e-02, -1.0524e-02, -1.6097e-03,  6.6421e-03],
        [ 8.6046e-03,  2.2558e-02,  3.8227e-02,  5.3693e-02,  6.4993e-02,
          7.2946e-02,  8.0171e-02,  8.3328e-02,  8.4795e-02,  7.8493e-02],
        [ 4.4561e-01,  5.6070e-01,  5.9378e-01,  6.4123e-01,  6.1267e-01,
          6.0794e-01,  6.7666e-01,  6.7914e-01,  8.0427e-01,  9.0958e-01],
        [ 1.1236e-01,  2.1983e-01,  1.9416e-01,  2.0032e-01,  1.5485e-01,
          1.5230e-01,  1.8933e-01,  1.7145e-01,  2.3044e-01,  2.0768e-01],
        [ 1.3644e-02,  3.5207e-02,  1.7515e-02,  2.6252e-02, -1.9740e-02,
         -6.6545e-02, -6.0915e-02, -4.6327e-02, -5.7510e-02, -7.0514e-02],
        [-1.5344e-02, -1.3591e-02, -1.0522e-02, -6.5761e-03, -1.3152e-03,
          3.0688e-03,  8.3297e-03,  1.5344e-02,  2.1043e-02,  2.7181e-02]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.9735, 10.9744, 10.9752, 10.9756, 10.9761, 10.9767, 10.9770, 10.9775,
         10.9771, 10.9776]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0799e+01,  1.0799e+01,  1.0799e+01,  1.0799e+01,  1.0800e+01,
          1.0800e+01,  1.0800e+01,  1.0800e+01,  1.0800e+01,  1.0800e+01],
        [ 3.2564e-02,  3.2042e-02,  3.0983e-02,  2.9656e-02,  2.9856e-02,
          3.1275e-02,  3.1036e-02,  3.2105e-02,  3.1384e-02,  2.9878e-02],
        [ 3.5189e-02,  3.5105e-02,  3.4808e-02,  3.4282e-02,  3.3905e-02,
          3.3912e-02,  3.3865e-02,  3.4059e-02,  3.4058e-02,  3.3731e-02],
        [ 3.4680e-04, -7.9964e-04, -2.8261e-03, -4.9992e-03, -3.5861e-03,
          6.0466e-05, -4.4495e-04,  1.8495e-03, -8.5441e-06, -3.1149e-03],
        [ 7.3068e-01,  6.5197e-01,  8.1188e-01,  8.0868e-01,  8.1999e-01,
          8.1085e-01,  6.9228e-01,  7.5591e-01,  6.4591e-01,  5.9175e-01],
        [ 2.3970e-01,  1.2812e-01,  2.1369e-01,  1.6888e-01,  1.7514e-01,
          1.6449e-01,  8.1818e-02,  1.2588e-01,  3.6789e-02, -4.7327e-03],
        [-2.5046e-02, -8.5090e-03,  8.7571e-03,  4.3053e-03,  1.5137e-02,
          1.8634e-02,  1.7106e-02,  1.0369e-02,  2.7827e-03,  3.1034e-03],
        [ 1.0083e-02,  1.2275e-02,  1.3152e-02,  1.4029e-02,  1.4029e-02,
          1.4467e-02,  1.4467e-02,  1.3591e-02,  1.3152e-02,  1.2275e-02]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.7993, 10.7992, 10.7992, 10.7996, 10.8001, 10.7998, 10.8003, 10.7999,
         10.7998, 10.7998]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.1070e+01,  1.1070e+01,  1.1070e+01,  1.1070e+01,  1.1070e+01,
          1.1070e+01,  1.1072e+01,  1.1071e+01,  1.1071e+01,  1.1071e+01],
        [-3.0037e-02, -2.9843e-02, -2.7829e-02, -2.6171e-02, -2.3103e-02,
         -1.9768e-02, -1.1418e-02, -6.9664e-03, -5.1113e-03, -2.8411e-03],
        [-2.5078e-02, -2.6539e-02, -2.7270e-02, -2.7496e-02, -2.7011e-02,
         -2.5898e-02, -2.3197e-02, -2.0069e-02, -1.7165e-02, -1.4348e-02],
        [-1.7873e-02, -1.3898e-02, -6.9611e-03, -2.1450e-03,  4.6176e-03,
          1.0578e-02,  2.5699e-02,  2.9749e-02,  2.7629e-02,  2.6790e-02],
        [ 3.2378e-01,  3.0018e-01,  3.4165e-01,  3.6147e-01,  4.1040e-01,
          4.7037e-01,  5.8216e-01,  5.3868e-01,  5.2143e-01,  5.4269e-01],
        [ 4.9898e-02,  3.5393e-02,  6.6309e-02,  8.8015e-02,  1.2426e-01,
          1.6868e-01,  2.5150e-01,  1.4843e-01,  1.3979e-01,  1.5044e-01],
        [ 2.0804e-02,  1.4618e-03, -8.1682e-04,  2.8452e-03, -2.9364e-04,
         -4.6907e-03, -5.7227e-02, -5.7795e-02, -2.6978e-02, -4.3603e-02],
        [-1.3591e-02, -1.4467e-02, -1.5344e-02, -1.4906e-02, -1.4467e-02,
         -1.3152e-02, -1.0522e-02, -6.1377e-03, -2.1920e-03,  8.7681e-04]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[11.0697, 11.0700, 11.0700, 11.0703, 11.0705, 11.0717, 11.0712, 11.0708,
         11.0710, 11.0716]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0802e+01,  1.0803e+01,  1.0804e+01,  1.0804e+01,  1.0804e+01,
          1.0803e+01,  1.0802e+01,  1.0804e+01,  1.0801e+01,  1.0800e+01],
        [ 6.0150e-03,  1.0715e-02,  1.6794e-02,  1.9167e-02,  2.1177e-02,
          2.1071e-02,  1.8029e-02,  2.0996e-02,  1.1498e-02,  3.1536e-03],
        [ 6.2864e-03,  7.3545e-03,  9.5283e-03,  1.1782e-02,  1.4022e-02,
          1.5790e-02,  1.6545e-02,  1.7793e-02,  1.6730e-02,  1.4068e-02],
        [ 5.7202e-04,  1.0160e-02,  2.0678e-02,  2.1441e-02,  2.1303e-02,
          1.6823e-02,  7.1788e-03,  1.1868e-02, -1.0113e-02, -2.5317e-02],
        [ 5.6873e-01,  6.0758e-01,  6.3020e-01,  5.7460e-01,  6.0893e-01,
          5.7143e-01,  5.5827e-01,  5.7442e-01,  4.5241e-01,  4.6222e-01],
        [ 1.3354e-01,  1.5255e-01,  1.6362e-01,  1.3641e-01,  1.5322e-01,
          1.3487e-01,  1.2843e-01,  9.6816e-02, -3.2465e-02,  8.7334e-03],
        [-3.8495e-03,  5.5149e-03, -1.3329e-02,  1.9301e-02,  9.0713e-04,
         -1.7932e-02,  2.2616e-02, -1.1095e-02, -2.9482e-02, -1.1696e-03],
        [ 5.6993e-03,  6.5761e-03,  9.6449e-03,  1.2275e-02,  1.3591e-02,
          1.4467e-02,  1.4467e-02,  1.3591e-02,  1.3591e-02,  9.2065e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.8034, 10.8042, 10.8035, 10.8036, 10.8032, 10.8024, 10.8040, 10.8006,
         10.8003, 10.7993]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0426e+01,  1.0426e+01,  1.0428e+01,  1.0428e+01,  1.0428e+01,
          1.0428e+01,  1.0429e+01,  1.0429e+01,  1.0428e+01,  1.0429e+01],
        [-1.7012e-02, -1.7751e-02, -1.5064e-02, -1.1958e-02, -1.0742e-02,
         -7.7335e-03, -3.3974e-03, -7.5519e-04, -4.5252e-05,  1.4712e-03],
        [-1.6309e-02, -1.6899e-02, -1.6789e-02, -1.6026e-02, -1.5152e-02,
         -1.3800e-02, -1.1777e-02, -9.5857e-03, -7.6783e-03, -5.8234e-03],
        [-5.1155e-03, -5.6185e-03,  1.0522e-03,  7.2549e-03,  8.3135e-03,
          1.2861e-02,  1.9240e-02,  2.0847e-02,  1.8143e-02,  1.7645e-02],
        [ 1.4105e-01,  1.6466e-01,  4.4421e-01,  5.6536e-01,  5.1897e-01,
          6.0032e-01,  6.6461e-01,  6.2345e-01,  5.7311e-01,  5.9506e-01],
        [-5.1209e-02,  1.1066e-02,  1.4208e-01,  1.9886e-01,  1.5163e-01,
          1.8427e-01,  1.9408e-01,  1.5686e-01,  1.4048e-01,  1.4763e-01],
        [-8.5515e-03, -5.0923e-03, -3.4294e-03, -1.8958e-03, -3.6189e-03,
         -1.6670e-03, -3.7918e-03, -5.0746e-03, -1.2118e-03, -2.1605e-02],
        [-9.2065e-03, -9.6449e-03, -1.0083e-02, -8.3297e-03, -5.6993e-03,
         -4.3840e-03, -1.7536e-03,  2.1920e-03,  4.8224e-03,  6.1377e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.4264, 10.4278, 10.4281, 10.4275, 10.4284, 10.4292, 10.4289, 10.4283,
         10.4287, 10.4301]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0565e+01,  1.0564e+01,  1.0566e+01,  1.0566e+01,  1.0566e+01,
          1.0565e+01,  1.0563e+01,  1.0565e+01,  1.0564e+01,  1.0565e+01],
        [ 2.9018e-02,  2.0082e-02,  1.7166e-02,  1.4403e-02,  1.4017e-02,
          1.1061e-02,  3.8197e-03,  2.0138e-03, -2.8415e-03, -4.0694e-03],
        [ 3.9991e-02,  3.6351e-02,  3.2806e-02,  2.9371e-02,  2.6539e-02,
          2.3631e-02,  1.9734e-02,  1.6224e-02,  1.2363e-02,  9.0070e-03],
        [-2.0222e-02, -3.4623e-02, -3.3719e-02, -3.2679e-02, -2.6940e-02,
         -2.7655e-02, -3.7072e-02, -3.3385e-02, -3.6731e-02, -3.1920e-02],
        [ 4.9670e-01,  3.7693e-01,  4.7999e-01,  4.5626e-01,  4.6369e-01,
          4.8066e-01,  4.8799e-01,  4.9505e-01,  4.1476e-01,  4.1379e-01],
        [ 4.0501e-02, -5.0136e-02,  6.0266e-02,  4.6374e-02,  5.0732e-02,
          6.0657e-02,  6.4930e-02,  6.9067e-02,  2.2114e-02,  2.1553e-02],
        [ 2.8528e-02, -4.1805e-03, -4.8020e-02, -1.9500e-02,  7.4417e-03,
          2.6943e-02,  3.6168e-02,  6.6230e-02,  5.0843e-02,  3.5745e-04],
        [ 1.5783e-02,  1.2275e-02,  4.3840e-03,  2.6304e-03,  1.3152e-03,
         -0.0000e+00, -2.6304e-03, -7.0145e-03, -9.2065e-03, -1.4467e-02]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.5640, 10.5656, 10.5655, 10.5663, 10.5653, 10.5635, 10.5650, 10.5637,
         10.5647, 10.5629]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0912e+01,  1.0912e+01,  1.0911e+01,  1.0910e+01,  1.0909e+01,
          1.0909e+01,  1.0911e+01,  1.0910e+01,  1.0910e+01,  1.0910e+01],
        [-2.6592e-02, -2.6695e-02, -3.0444e-02, -3.5554e-02, -4.2062e-02,
         -4.8578e-02, -4.6678e-02, -4.5934e-02, -4.5894e-02, -4.5213e-02],
        [-2.5459e-02, -2.6160e-02, -2.7535e-02, -2.9744e-02, -3.2924e-02,
         -3.6881e-02, -3.9635e-02, -4.1677e-02, -4.3301e-02, -4.4453e-02],
        [-8.0762e-03, -6.6747e-03, -1.3078e-02, -2.1011e-02, -3.0245e-02,
         -3.7648e-02, -2.6195e-02, -1.9419e-02, -1.5453e-02, -1.0957e-02],
        [ 4.3669e-01,  3.8717e-01,  2.7019e-01,  2.7162e-01,  2.4489e-01,
          1.7823e-01,  3.4745e-01,  3.5057e-01,  3.4899e-01,  3.5037e-01],
        [ 1.1839e-01,  8.0252e-02, -9.8400e-03,  1.1236e-03, -1.9748e-02,
         -4.6987e-02,  9.3480e-02,  9.5199e-02,  9.4331e-02,  9.5097e-02],
        [-9.6404e-04,  1.7907e-02,  1.5861e-02,  7.9256e-03,  4.0772e-03,
          9.1531e-03,  1.8811e-02, -3.0996e-02,  9.3758e-03,  8.5869e-03],
        [-9.2065e-03, -8.7681e-03, -9.2065e-03, -1.1837e-02, -1.4906e-02,
         -1.8413e-02, -2.2359e-02, -2.2797e-02, -2.3674e-02, -2.2797e-02]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.9119, 10.9108, 10.9101, 10.9094, 10.9088, 10.9106, 10.9102, 10.9100,
         10.9100, 10.9098]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0655e+01,  1.0654e+01,  1.0654e+01,  1.0654e+01,  1.0654e+01,
          1.0655e+01,  1.0655e+01,  1.0654e+01,  1.0654e+01,  1.0654e+01],
        [ 2.1468e-03,  3.3767e-03,  4.6161e-03,  4.9724e-03,  4.8041e-03,
          7.4586e-03,  7.9113e-03,  6.2515e-03,  4.5143e-03,  2.9527e-03],
        [-7.8370e-03, -5.5368e-03, -3.4276e-03, -1.6630e-03, -2.8780e-04,
          1.3884e-03,  2.8277e-03,  3.6189e-03,  3.8748e-03,  3.7407e-03],
        [ 2.4176e-02,  2.1880e-02,  2.0063e-02,  1.6786e-02,  1.3081e-02,
          1.5945e-02,  1.3690e-02,  7.5261e-03,  2.4344e-03, -1.2759e-03],
        [ 6.2605e-01,  6.1339e-01,  6.3473e-01,  6.4643e-01,  7.0666e-01,
          6.8555e-01,  5.9530e-01,  5.5204e-01,  5.2448e-01,  5.1657e-01],
        [ 1.3979e-01,  1.2291e-01,  1.4355e-01,  1.5487e-01,  2.1313e-01,
          1.5014e-01,  6.4164e-02,  2.2966e-02, -3.0337e-02, -7.4055e-03],
        [-2.2254e-02,  7.3206e-03,  7.5491e-03, -2.5485e-03, -1.1055e-03,
         -2.5377e-03,  7.1952e-03,  2.8184e-03, -2.0659e-03,  1.7454e-02],
        [ 8.7681e-03,  9.6449e-03,  1.0522e-02,  1.0522e-02,  1.0522e-02,
          1.0522e-02,  1.0960e-02,  1.0522e-02,  8.7681e-03,  7.0145e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.6544, 10.6545, 10.6543, 10.6542, 10.6551, 10.6546, 10.6539, 10.6538,
         10.6538, 10.6536]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0801e+01,  1.0802e+01,  1.0800e+01,  1.0800e+01,  1.0799e+01,
          1.0798e+01,  1.0800e+01,  1.0803e+01,  1.0804e+01,  1.0803e+01],
        [ 8.4620e-03,  2.1533e-02,  2.7258e-02,  3.0668e-02,  2.9346e-02,
          2.4796e-02,  2.6730e-02,  3.9842e-02,  5.1625e-02,  5.8616e-02],
        [-2.0184e-02, -1.1474e-02, -3.2637e-03,  4.0446e-03,  9.6045e-03,
          1.3065e-02,  1.6253e-02,  2.1649e-02,  2.8523e-02,  3.5539e-02],
        [ 6.9834e-02,  8.2851e-02,  7.8098e-02,  6.9519e-02,  5.2886e-02,
          3.2915e-02,  3.0325e-02,  5.1328e-02,  6.5386e-02,  6.6741e-02],
        [ 6.1968e-01,  6.9104e-01,  6.4085e-01,  6.1755e-01,  6.1423e-01,
          6.1021e-01,  6.3590e-01,  7.4499e-01,  7.4634e-01,  6.7889e-01],
        [ 1.9149e-01,  2.0325e-01,  1.5080e-01,  1.4178e-01,  1.4048e-01,
          1.3893e-01,  1.4888e-01,  1.9115e-01,  1.7072e-01,  1.3759e-01],
        [-4.9156e-02, -7.7194e-02, -6.6385e-02, -1.0984e-01, -9.7850e-02,
         -3.8882e-03,  2.3269e-02, -2.9278e-02, -6.8130e-03,  4.3988e-02],
        [-8.3297e-03,  2.6304e-03,  1.5344e-02,  2.4551e-02,  3.0688e-02,
          3.5949e-02,  3.8141e-02,  3.9018e-02,  4.5594e-02,  5.2609e-02]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.8016, 10.8003, 10.8000, 10.7989, 10.7980, 10.7997, 10.8033, 10.8039,
         10.8034, 10.8045]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0603e+01,  1.0604e+01,  1.0603e+01,  1.0604e+01,  1.0605e+01,
          1.0606e+01,  1.0607e+01,  1.0606e+01,  1.0606e+01,  1.0604e+01],
        [ 2.8873e-02,  2.5775e-02,  1.9991e-02,  1.8668e-02,  2.0167e-02,
          2.3080e-02,  2.8233e-02,  2.9712e-02,  2.8396e-02,  2.3751e-02],
        [ 4.9124e-02,  4.4893e-02,  4.0253e-02,  3.6254e-02,  3.3380e-02,
          3.1713e-02,  3.1497e-02,  3.1646e-02,  3.1479e-02,  3.0338e-02],
        [-4.2314e-02, -4.0248e-02, -4.4137e-02, -3.8042e-02, -2.7338e-02,
         -1.5857e-02, -2.0475e-03,  1.4146e-03, -1.5853e-03, -1.0857e-02],
        [ 2.5732e-01,  4.2252e-01,  3.8227e-01,  4.6480e-01,  5.0042e-01,
          5.7182e-01,  6.2517e-01,  5.8806e-01,  5.5764e-01,  4.8197e-01],
        [-3.8270e-02,  6.3160e-02,  4.7770e-02,  9.7957e-02,  1.1478e-01,
          1.7237e-01,  1.9911e-01,  1.5306e-01,  1.3899e-01,  1.0397e-01],
        [ 6.6627e-03, -1.1274e-02, -1.7155e-02, -1.7201e-02, -1.9128e-02,
          3.8477e-04,  1.3447e-02,  1.6469e-03, -1.1033e-03,  9.3385e-03],
        [-4.3840e-03, -9.2065e-03, -1.0083e-02, -1.1399e-02, -1.0522e-02,
         -7.8913e-03, -3.5072e-03,  1.7536e-03,  4.8224e-03,  7.0145e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.6042, 10.6030, 10.6043, 10.6053, 10.6060, 10.6072, 10.6063, 10.6056,
         10.6044, 10.6048]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0308e+01,  1.0316e+01,  1.0319e+01,  1.0320e+01,  1.0324e+01,
          1.0328e+01,  1.0325e+01,  1.0326e+01,  1.0327e+01,  1.0329e+01],
        [-1.6478e-01, -1.5957e-01, -1.4722e-01, -1.3371e-01, -1.1277e-01,
         -8.8345e-02, -7.3229e-02, -5.8418e-02, -4.4774e-02, -2.9709e-02],
        [-1.5798e-01, -1.6102e-01, -1.6076e-01, -1.5763e-01, -1.5058e-01,
         -1.3963e-01, -1.2760e-01, -1.1476e-01, -1.0152e-01, -8.7666e-02],
        [-4.9528e-02, -2.8868e-02,  2.4125e-03,  2.9808e-02,  6.7082e-02,
          1.0409e-01,  1.1447e-01,  1.2216e-01,  1.2589e-01,  1.3181e-01],
        [ 2.8613e-01,  4.1697e-01,  4.2119e-01,  4.6989e-01,  5.5241e-01,
          6.0540e-01,  5.4264e-01,  5.6557e-01,  5.2512e-01,  5.9175e-01],
        [ 8.3231e-02,  2.2736e-01,  1.7373e-01,  2.0960e-01,  2.2441e-01,
          1.9663e-01,  1.4225e-01,  1.5247e-01,  1.2971e-01,  1.6324e-01],
        [-1.0835e-01, -1.0735e-01, -2.8705e-02, -2.8814e-02,  6.4031e-02,
          1.6899e-02,  1.2913e-02, -1.2459e-02, -3.5394e-02, -1.5506e-01],
        [-1.0916e-01, -1.0916e-01, -9.5134e-02, -8.0228e-02, -6.6199e-02,
         -4.5156e-02, -2.4112e-02, -9.2065e-03,  5.2609e-03,  1.6659e-02]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.3158, 10.3190, 10.3200, 10.3243, 10.3276, 10.3252, 10.3262, 10.3269,
         10.3287, 10.3260]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0763e+01,  1.0761e+01,  1.0762e+01,  1.0763e+01,  1.0761e+01,
          1.0761e+01,  1.0760e+01,  1.0760e+01,  1.0760e+01,  1.0760e+01],
        [ 6.8243e-02,  6.6338e-02,  6.6739e-02,  7.0098e-02,  6.5231e-02,
          5.9512e-02,  5.1688e-02,  4.3261e-02,  3.7484e-02,  3.0964e-02],
        [ 5.5172e-02,  5.8534e-02,  6.1311e-02,  6.4262e-02,  6.5566e-02,
          6.5368e-02,  6.3512e-02,  6.0198e-02,  5.6293e-02,  5.1755e-02],
        [ 4.4896e-02,  3.1984e-02,  2.6415e-02,  2.8067e-02,  1.2406e-02,
         -1.8812e-03, -1.7656e-02, -3.1521e-02, -3.7144e-02, -4.3175e-02],
        [ 7.9210e-01,  6.7293e-01,  6.8533e-01,  7.0942e-01,  6.3575e-01,
          5.8165e-01,  5.0362e-01,  4.9815e-01,  4.9846e-01,  4.7484e-01],
        [ 1.3463e-01,  8.0831e-02,  8.5104e-02,  7.2029e-02,  1.7109e-02,
         -1.4981e-02, -4.1284e-02, -2.3323e-03,  1.3619e-04, -9.7889e-03],
        [-2.6126e-02,  8.1781e-03,  4.0736e-02,  1.9276e-02,  1.8565e-02,
          1.6911e-02,  4.0583e-02,  7.6561e-02,  2.8216e-02,  1.9911e-02],
        [ 4.7348e-02,  4.9978e-02,  4.8663e-02,  4.6909e-02,  4.6032e-02,
          4.2087e-02,  3.6388e-02,  2.8935e-02,  2.0605e-02,  1.2714e-02]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.7614, 10.7623, 10.7634, 10.7614, 10.7610, 10.7602, 10.7596, 10.7600,
         10.7595, 10.7589]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0552e+01,  1.0552e+01,  1.0553e+01,  1.0552e+01,  1.0552e+01,
          1.0552e+01,  1.0551e+01,  1.0552e+01,  1.0550e+01,  1.0552e+01],
        [-1.1889e-02, -1.0750e-02, -7.3076e-03, -5.9561e-03, -5.1070e-03,
         -5.0147e-03, -5.7556e-03, -5.7179e-03, -9.3555e-03, -7.3513e-03],
        [-1.6922e-02, -1.5871e-02, -1.4282e-02, -1.2719e-02, -1.1283e-02,
         -1.0115e-02, -9.3409e-03, -8.7136e-03, -9.0012e-03, -8.7964e-03],
        [ 9.5618e-03,  1.0000e-02,  1.5107e-02,  1.4876e-02,  1.3654e-02,
          1.1113e-02,  7.3611e-03,  5.9669e-03, -2.7359e-03,  1.9487e-03],
        [ 5.1394e-01,  4.9565e-01,  5.5057e-01,  6.0797e-01,  5.8585e-01,
          5.3099e-01,  4.9119e-01,  5.3123e-01,  3.9049e-01,  5.3758e-01],
        [ 1.7162e-01,  1.5890e-01,  1.9295e-01,  2.0163e-01,  1.6003e-01,
          1.3098e-01,  1.1067e-01,  1.3110e-01,  1.7075e-02,  1.2067e-01],
        [-2.5946e-02, -1.0359e-02, -3.4015e-03, -1.1390e-02,  5.6735e-03,
         -6.8259e-03, -1.1931e-02, -1.8137e-03, -1.5793e-02,  1.9741e-02],
        [-8.7681e-03, -5.2609e-03, -3.0688e-03,  0.0000e+00,  2.6304e-03,
          4.3840e-03,  4.8224e-03,  4.3840e-03,  4.8224e-03,  1.7536e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.5517, 10.5527, 10.5521, 10.5520, 10.5518, 10.5514, 10.5517, 10.5502,
         10.5520, 10.5514]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0571e+01,  1.0571e+01,  1.0573e+01,  1.0574e+01,  1.0572e+01,
          1.0574e+01,  1.0574e+01,  1.0573e+01,  1.0572e+01,  1.0573e+01],
        [-3.6578e-02, -3.1784e-02, -2.3794e-02, -1.5510e-02, -1.2857e-02,
         -6.2914e-03, -5.4956e-04,  3.7526e-04, -5.9175e-05,  1.3221e-03],
        [-4.3807e-02, -4.1944e-02, -3.8719e-02, -3.4341e-02, -3.0263e-02,
         -2.5576e-02, -2.0580e-02, -1.6382e-02, -1.3119e-02, -1.0208e-02],
        [ 9.7876e-03,  1.7727e-02,  3.0677e-02,  4.1641e-02,  3.8791e-02,
          4.4586e-02,  4.7522e-02,  3.9927e-02,  3.1045e-02,  2.7687e-02],
        [ 4.2643e-01,  4.2994e-01,  5.1660e-01,  5.6363e-01,  5.6802e-01,
          6.1462e-01,  6.7248e-01,  5.7512e-01,  5.7813e-01,  5.6652e-01],
        [ 1.1529e-01,  1.1782e-01,  1.8066e-01,  2.0237e-01,  1.7276e-01,
          1.9665e-01,  1.9860e-01,  1.2932e-01,  1.3059e-01,  1.2571e-01],
        [-2.5755e-02, -1.9144e-02, -4.1467e-02, -1.7364e-02, -2.9291e-02,
         -6.6243e-03, -3.5758e-02, -3.7544e-02, -5.7314e-02, -1.8499e-02],
        [-2.4551e-02, -2.2359e-02, -1.8413e-02, -1.2275e-02, -4.8224e-03,
         -0.0000e+00,  7.0145e-03,  1.3591e-02,  1.6659e-02,  1.9290e-02]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.5715, 10.5730, 10.5736, 10.5721, 10.5737, 10.5739, 10.5726, 10.5721,
         10.5728, 10.5722]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0544e+01,  1.0545e+01,  1.0545e+01,  1.0545e+01,  1.0545e+01,
          1.0545e+01,  1.0544e+01,  1.0544e+01,  1.0545e+01,  1.0547e+01],
        [ 1.7648e-02,  2.1809e-02,  2.3232e-02,  2.4833e-02,  2.5792e-02,
          2.6984e-02,  2.3382e-02,  2.1339e-02,  2.3003e-02,  2.8067e-02],
        [ 1.0495e-02,  1.3129e-02,  1.5545e-02,  1.7825e-02,  1.9858e-02,
          2.1742e-02,  2.2468e-02,  2.2606e-02,  2.3077e-02,  2.4552e-02],
        [ 2.0583e-02,  2.5056e-02,  2.2983e-02,  2.1692e-02,  1.9332e-02,
          1.7927e-02,  6.9045e-03,  1.3068e-03,  4.4804e-03,  1.4039e-02],
        [ 6.2073e-01,  6.6179e-01,  6.0277e-01,  6.2731e-01,  6.5006e-01,
          6.7934e-01,  5.6639e-01,  6.2421e-01,  6.7895e-01,  7.0578e-01],
        [ 1.2455e-01,  1.3454e-01,  9.9847e-02,  9.8536e-02,  1.1197e-01,
          1.2937e-01,  6.2274e-02,  9.6612e-02,  1.1416e-01,  1.3590e-01],
        [-1.3193e-03, -8.8783e-03, -8.2676e-03, -2.7796e-02, -3.5184e-02,
         -2.7289e-02,  3.6574e-04,  1.5786e-02,  3.5707e-02,  2.3091e-02],
        [ 1.3591e-02,  1.4467e-02,  1.7536e-02,  1.8851e-02,  2.0167e-02,
          2.1920e-02,  2.4551e-02,  2.2797e-02,  2.1482e-02,  2.1482e-02]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.5453, 10.5446, 10.5449, 10.5449, 10.5452, 10.5436, 10.5440, 10.5453,
         10.5469, 10.5468]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0530e+01,  1.0529e+01,  1.0530e+01,  1.0530e+01,  1.0528e+01,
          1.0527e+01,  1.0527e+01,  1.0527e+01,  1.0527e+01,  1.0527e+01],
        [ 2.4034e-03, -2.4469e-03, -4.0898e-03, -6.0936e-03, -1.2472e-02,
         -1.8495e-02, -2.3177e-02, -2.7211e-02, -3.0762e-02, -3.0993e-02],
        [ 1.1151e-02,  8.3896e-03,  5.8241e-03,  3.3369e-03, -3.7311e-05,
         -4.0437e-03, -8.2648e-03, -1.2517e-02, -1.6690e-02, -2.0078e-02],
        [-2.0316e-02, -2.6265e-02, -2.4404e-02, -2.3660e-02, -3.2096e-02,
         -3.8109e-02, -4.0152e-02, -4.0450e-02, -3.9691e-02, -3.2229e-02],
        [ 4.9629e-01,  3.4084e-01,  3.7714e-01,  3.6185e-01,  2.2050e-01,
          2.1739e-01,  1.4343e-01,  1.5136e-01,  1.5668e-01,  2.4890e-01],
        [ 3.1324e-02, -1.3349e-01,  2.1570e-02,  1.2700e-02, -7.2761e-02,
         -1.3109e-03, -3.1086e-02,  2.8260e-03,  4.7157e-03,  3.7487e-02],
        [ 3.1931e-02,  2.6863e-02,  4.5694e-02,  3.1614e-02,  2.0349e-02,
          1.9905e-02,  2.8008e-02,  5.6326e-03,  3.7017e-03, -9.7396e-04],
        [ 1.0083e-02,  6.5761e-03,  8.7681e-04, -3.5072e-03, -8.3297e-03,
         -1.5344e-02, -2.1920e-02, -2.8058e-02, -3.2880e-02, -3.5949e-02]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.5290, 10.5298, 10.5295, 10.5276, 10.5271, 10.5271, 10.5268, 10.5265,
         10.5274, 10.5277]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0946e+01,  1.0947e+01,  1.0946e+01,  1.0945e+01,  1.0945e+01,
          1.0943e+01,  1.0942e+01,  1.0944e+01,  1.0943e+01,  1.0945e+01],
        [-3.5913e-04,  1.0261e-02,  1.4709e-02,  1.4470e-02,  1.4051e-02,
          8.1587e-03, -1.1295e-03, -1.4679e-03, -6.1349e-03, -2.0134e-03],
        [-3.1402e-02, -2.2894e-02, -1.5123e-02, -8.9584e-03, -4.1175e-03,
         -1.5234e-03, -1.4638e-03, -1.4896e-03, -2.5231e-03, -2.4554e-03],
        [ 7.3748e-02,  8.0921e-02,  7.3919e-02,  5.8643e-02,  4.6049e-02,
          2.4676e-02,  5.6654e-04, -2.4559e-04, -9.8308e-03,  6.4366e-04],
        [ 5.5226e-01,  6.0972e-01,  5.7216e-01,  5.8552e-01,  5.8145e-01,
          5.4983e-01,  5.5582e-01,  6.4590e-01,  5.5263e-01,  5.6901e-01],
        [ 1.0501e-01,  1.5031e-01,  1.2070e-01,  1.3122e-01,  1.2802e-01,
          1.0310e-01,  1.0781e-01,  1.7882e-01,  1.0026e-01,  7.6098e-02],
        [-3.0584e-03, -3.5031e-02, -8.3168e-02, -1.0835e-01, -7.1965e-02,
         -2.7838e-02, -2.1760e-02,  2.8326e-02,  3.3526e-02,  5.5396e-02],
        [ 2.6304e-03,  6.1377e-03,  1.0960e-02,  1.4467e-02,  1.7536e-02,
          2.0605e-02,  2.0167e-02,  1.7536e-02,  1.7975e-02,  1.4467e-02]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.9468, 10.9458, 10.9449, 10.9449, 10.9435, 10.9423, 10.9441, 10.9429,
         10.9449, 10.9434]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
  0%|          | 0/350 [00:03<?, ?it/s]
Traceback (most recent call last):
  File "C:\Users\dadou\Documents\Github\Advanced-Programming\Strategies\Transformer_strategy.py", line 417, in <module>
    trainer.train()
  File "C:\Users\dadou\Documents\Github\Advanced-Programming\utils\trainer.py", line 69, in train
    preds = self.model(signal.to(self.device))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\dadou\anaconda3\envs\Advanced-Programming\Lib\site-packages\torch\nn\modules\module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\dadou\anaconda3\envs\Advanced-Programming\Lib\site-packages\torch\nn\modules\module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\dadou\Documents\Github\Advanced-Programming\Strategies\Transformer_strategy.py", line 188, in forward
    x = self.transformer_encoder(x)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\dadou\anaconda3\envs\Advanced-Programming\Lib\site-packages\torch\nn\modules\module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\dadou\anaconda3\envs\Advanced-Programming\Lib\site-packages\torch\nn\modules\module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\dadou\anaconda3\envs\Advanced-Programming\Lib\site-packages\torch\nn\modules\transformer.py", line 391, in forward
    output = mod(output, src_mask=mask, is_causal=is_causal, src_key_padding_mask=src_key_padding_mask_for_layers)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\dadou\anaconda3\envs\Advanced-Programming\Lib\site-packages\torch\nn\modules\module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\dadou\anaconda3\envs\Advanced-Programming\Lib\site-packages\torch\nn\modules\module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\dadou\anaconda3\envs\Advanced-Programming\Lib\site-packages\torch\nn\modules\transformer.py", line 714, in forward
    x = self.norm1(x + self._sa_block(x, src_mask, src_key_padding_mask, is_causal=is_causal))
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\dadou\anaconda3\envs\Advanced-Programming\Lib\site-packages\torch\nn\modules\transformer.py", line 722, in _sa_block
    x = self.self_attn(x, x, x,
        ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\dadou\anaconda3\envs\Advanced-Programming\Lib\site-packages\torch\nn\modules\module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\dadou\anaconda3\envs\Advanced-Programming\Lib\site-packages\torch\nn\modules\module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\dadou\anaconda3\envs\Advanced-Programming\Lib\site-packages\torch\nn\modules\activation.py", line 1241, in forward
    attn_output, attn_output_weights = F.multi_head_attention_forward(
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\dadou\anaconda3\envs\Advanced-Programming\Lib\site-packages\torch\nn\functional.py", line 5336, in multi_head_attention_forward
    q, k, v = _in_projection_packed(query, key, value, in_proj_weight, in_proj_bias)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\dadou\anaconda3\envs\Advanced-Programming\Lib\site-packages\torch\nn\functional.py", line 4857, in _in_projection_packed
    proj = linear(q, w, b)
           ^^^^^^^^^^^^^^^
KeyboardInterrupt
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0777e+01,  1.0776e+01,  1.0776e+01,  1.0776e+01,  1.0775e+01,
          1.0775e+01,  1.0775e+01,  1.0776e+01,  1.0774e+01,  1.0774e+01],
        [-5.5747e-02, -5.6997e-02, -5.6281e-02, -5.6221e-02, -5.7459e-02,
         -5.7586e-02, -5.9415e-02, -5.6996e-02, -5.8930e-02, -6.0114e-02],
        [-5.4997e-02, -5.6367e-02, -5.7308e-02, -5.8047e-02, -5.8908e-02,
         -5.9623e-02, -6.0593e-02, -6.0844e-02, -6.1464e-02, -6.2217e-02],
        [-1.3068e-02, -1.3035e-02, -8.9483e-03, -7.0358e-03, -8.1846e-03,
         -6.8097e-03, -9.2239e-03, -2.3856e-03, -5.8994e-03, -7.1648e-03],
        [ 2.7054e-01,  2.5665e-01,  2.8364e-01,  3.4562e-01,  3.5216e-01,
          3.6678e-01,  3.6209e-01,  4.3258e-01,  3.4266e-01,  3.9594e-01],
        [ 3.6755e-02,  3.0065e-02,  4.3071e-02,  9.1386e-02,  1.5305e-01,
          1.8601e-01,  1.6561e-01,  2.3517e-01,  1.0601e-01,  1.4406e-01],
        [-3.6333e-02, -3.8847e-02, -4.9386e-02, -4.6911e-02, -2.1218e-02,
         -5.4068e-02, -1.6413e-03,  2.2932e-03, -3.2803e-03, -1.7292e-02],
        [-3.9895e-02, -3.8580e-02, -3.7703e-02, -3.5949e-02, -3.2004e-02,
         -2.8935e-02, -2.6743e-02, -2.4112e-02, -2.1482e-02, -2.1920e-02]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.7758, 10.7761, 10.7758, 10.7752, 10.7753, 10.7745, 10.7755, 10.7741,
         10.7740, 10.7746]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0914e+01,  1.0915e+01,  1.0913e+01,  1.0913e+01,  1.0914e+01,
          1.0914e+01,  1.0913e+01,  1.0914e+01,  1.0915e+01,  1.0916e+01],
        [ 2.4061e-02,  2.4101e-02,  1.8223e-02,  1.3760e-02,  1.0818e-02,
          8.6747e-03,  6.5130e-03,  8.3528e-03,  1.0834e-02,  1.5531e-02],
        [ 3.0290e-02,  2.9462e-02,  2.7524e-02,  2.5006e-02,  2.2352e-02,
          1.9764e-02,  1.7225e-02,  1.5593e-02,  1.4825e-02,  1.5231e-02],
        [-9.9414e-03, -7.8711e-03, -1.8432e-02, -2.3958e-02, -2.5241e-02,
         -2.4616e-02, -2.4156e-02, -1.5526e-02, -7.2987e-03,  3.8560e-03],
        [ 4.8591e-01,  5.4192e-01,  4.2766e-01,  4.4936e-01,  4.4222e-01,
          4.6669e-01,  3.5380e-01,  4.4327e-01,  5.3321e-01,  5.9056e-01],
        [-4.3582e-03,  2.9299e-02, -3.0473e-02,  9.6357e-03,  6.4692e-03,
          1.9663e-02, -3.7198e-02,  3.7266e-02,  8.7130e-02,  1.3948e-01],
        [ 1.6179e-02,  1.7507e-03,  3.7389e-02,  3.3920e-02,  2.7629e-03,
         -1.3488e-03,  1.6038e-02,  2.3541e-02, -2.0553e-02, -2.7441e-03],
        [ 9.6449e-03,  7.0145e-03,  5.2609e-03,  1.7536e-03, -1.3152e-03,
         -3.9456e-03, -4.8224e-03, -7.0145e-03, -7.0145e-03, -5.6993e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.9147, 10.9132, 10.9133, 10.9135, 10.9136, 10.9135, 10.9144, 10.9148,
         10.9155, 10.9153]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0764e+01,  1.0764e+01,  1.0765e+01,  1.0762e+01,  1.0764e+01,
          1.0763e+01,  1.0762e+01,  1.0764e+01,  1.0764e+01,  1.0765e+01],
        [-3.2612e-02, -3.4350e-02, -3.4182e-02, -4.0956e-02, -4.0791e-02,
         -4.3797e-02, -4.9214e-02, -4.3981e-02, -4.1137e-02, -3.3139e-02],
        [-2.8687e-02, -3.0405e-02, -3.1742e-02, -3.4282e-02, -3.6278e-02,
         -3.8527e-02, -4.1502e-02, -4.2747e-02, -4.3125e-02, -4.1692e-02],
        [-1.5934e-02, -1.6335e-02, -1.2721e-02, -2.4161e-02, -1.8988e-02,
         -2.1395e-02, -2.8298e-02, -1.1837e-02, -3.5986e-03,  1.3633e-02],
        [ 4.1696e-01,  5.3748e-01,  4.8987e-01,  3.8068e-01,  4.3790e-01,
          4.0477e-01,  3.3279e-01,  4.1739e-01,  3.6796e-01,  4.4899e-01],
        [ 1.5020e-01,  2.6944e-01,  1.3604e-01,  5.7593e-02,  9.8706e-02,
          7.4906e-02,  2.3187e-02,  7.0361e-02,  2.9248e-02,  9.6646e-02],
        [-2.8647e-02, -2.2484e-02,  1.0655e-02,  3.7653e-02,  7.0440e-02,
          5.3442e-02,  1.4987e-02, -8.0400e-03, -3.4708e-03,  9.6846e-03],
        [-1.1837e-02, -1.1399e-02, -8.7681e-03, -7.4529e-03, -1.1399e-02,
         -1.3152e-02, -1.7536e-02, -2.2797e-02, -2.2797e-02, -2.3235e-02]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.7642, 10.7645, 10.7623, 10.7638, 10.7627, 10.7616, 10.7644, 10.7638,
         10.7655, 10.7661]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.1018e+01,  1.1018e+01,  1.1018e+01,  1.1018e+01,  1.1018e+01,
          1.1019e+01,  1.1019e+01,  1.1019e+01,  1.1020e+01,  1.1020e+01],
        [-1.0444e-03, -3.1642e-04, -1.1023e-03, -1.7984e-03, -1.9425e-03,
          7.2522e-04,  2.8070e-03,  4.9634e-03,  9.1754e-03,  1.4149e-02],
        [-2.1559e-03, -1.7934e-03, -1.6740e-03, -1.7295e-03, -1.8051e-03,
         -1.2867e-03, -4.2019e-04,  7.4106e-04,  2.5840e-03,  5.1379e-03],
        [ 2.4318e-03,  3.4485e-03,  1.1364e-03, -5.2777e-04, -7.1990e-04,
          4.9313e-03,  8.2425e-03,  1.1046e-02,  1.7532e-02,  2.4292e-02],
        [ 4.8605e-01,  5.3155e-01,  5.0773e-01,  4.8302e-01,  5.9365e-01,
          6.3561e-01,  5.6060e-01,  7.2108e-01,  7.1903e-01,  7.1685e-01],
        [ 1.2835e-01,  1.7715e-01,  1.4821e-01,  1.2537e-01,  2.2768e-01,
          2.1243e-01,  1.0981e-01,  2.3912e-01,  1.6902e-01,  1.6771e-01],
        [-3.3538e-02, -2.6959e-02,  1.5659e-03, -2.7147e-02, -2.3689e-03,
          1.5398e-02,  1.4789e-02,  9.1509e-03,  8.1331e-03, -8.4037e-03],
        [-2.6304e-03, -1.7536e-03, -4.3840e-04,  4.3840e-04,  4.3840e-04,
          1.7536e-03,  3.0688e-03,  3.0688e-03,  4.3840e-03,  5.6993e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[11.0184, 11.0180, 11.0180, 11.0181, 11.0188, 11.0188, 11.0189, 11.0195,
         11.0200, 11.0195]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0571e+01,  1.0571e+01,  1.0572e+01,  1.0571e+01,  1.0572e+01,
          1.0570e+01,  1.0571e+01,  1.0571e+01,  1.0570e+01,  1.0570e+01],
        [-4.0867e-02, -3.6366e-02, -3.1355e-02, -2.8204e-02, -2.3448e-02,
         -2.5269e-02, -2.4442e-02, -2.3624e-02, -2.4901e-02, -2.4512e-02],
        [-5.4024e-02, -5.1112e-02, -4.7694e-02, -4.4276e-02, -4.0510e-02,
         -3.7892e-02, -3.5618e-02, -3.3621e-02, -3.2301e-02, -3.1160e-02],
        [ 2.3019e-02,  2.7706e-02,  3.2509e-02,  3.2513e-02,  3.5827e-02,
          2.4903e-02,  2.1629e-02,  1.8993e-02,  1.2557e-02,  1.0848e-02],
        [ 3.6871e-01,  4.5138e-01,  5.4707e-01,  5.5477e-01,  6.7332e-01,
          5.0628e-01,  6.1648e-01,  5.6399e-01,  4.8397e-01,  4.9760e-01],
        [ 1.6788e-01,  2.2336e-01,  2.1919e-01,  1.7331e-01,  2.1651e-01,
          1.1898e-01,  1.5279e-01,  1.2954e-01,  9.9591e-02,  1.0466e-01],
        [-3.6537e-02, -3.6357e-02, -5.6489e-02, -3.4433e-02, -2.4466e-02,
         -1.7668e-02, -1.7511e-02, -1.4342e-02,  7.4334e-03,  1.5002e-02],
        [-2.4551e-02, -2.0605e-02, -1.5344e-02, -9.2065e-03, -3.5072e-03,
          2.6304e-03,  3.5072e-03,  6.1377e-03,  7.4529e-03,  6.1377e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.5714, 10.5718, 10.5713, 10.5721, 10.5699, 10.5706, 10.5706, 10.5698,
         10.5702, 10.5694]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0989e+01,  1.0989e+01,  1.0988e+01,  1.0989e+01,  1.0989e+01,
          1.0989e+01,  1.0988e+01,  1.0988e+01,  1.0989e+01,  1.0988e+01],
        [ 4.6665e-02,  4.1691e-02,  3.3675e-02,  3.0589e-02,  2.9203e-02,
          2.6680e-02,  1.8912e-02,  1.4723e-02,  1.3131e-02,  9.5948e-03],
        [ 4.7810e-02,  4.7296e-02,  4.5145e-02,  4.2754e-02,  4.0541e-02,
          3.8223e-02,  3.4683e-02,  3.0942e-02,  2.7603e-02,  2.4165e-02],
        [ 6.7210e-03, -4.8925e-03, -2.0461e-02, -2.2740e-02, -2.1051e-02,
         -2.2050e-02, -3.3676e-02, -3.5588e-02, -3.1758e-02, -3.2706e-02],
        [ 4.9261e-01,  4.9815e-01,  4.1177e-01,  5.2526e-01,  5.3634e-01,
          5.1024e-01,  4.8430e-01,  5.2830e-01,  4.9701e-01,  4.6731e-01],
        [-3.9768e-02,  2.8090e-03, -4.3718e-02,  6.3858e-02,  8.0014e-02,
          6.3245e-02,  4.6578e-02,  7.4838e-02,  5.4750e-02,  3.5683e-02],
        [ 6.0740e-04,  1.0966e-03, -3.4422e-02, -4.3401e-02, -1.1077e-02,
         -1.3103e-02,  4.9695e-02,  4.8519e-02,  5.2214e-02,  4.4300e-02],
        [ 1.3152e-02,  1.1399e-02,  9.2065e-03,  5.6993e-03,  5.2609e-03,
          5.6993e-03,  4.8224e-03,  2.1920e-03, -0.0000e+00, -2.1920e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.9890, 10.9881, 10.9890, 10.9894, 10.9891, 10.9877, 10.9882, 10.9887,
         10.9882, 10.9888]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0758e+01,  1.0758e+01,  1.0758e+01,  1.0757e+01,  1.0757e+01,
          1.0758e+01,  1.0758e+01,  1.0759e+01,  1.0759e+01,  1.0759e+01],
        [ 3.7225e-02,  3.4935e-02,  3.2411e-02,  2.6858e-02,  2.0646e-02,
          1.8626e-02,  1.7860e-02,  1.9562e-02,  2.0791e-02,  2.0819e-02],
        [ 4.5446e-02,  4.3938e-02,  4.2185e-02,  3.9576e-02,  3.6142e-02,
          3.2956e-02,  3.0240e-02,  2.8438e-02,  2.7262e-02,  2.6328e-02],
        [-1.2015e-02, -1.4341e-02, -1.6684e-02, -2.4810e-02, -3.2672e-02,
         -3.0307e-02, -2.5827e-02, -1.7148e-02, -1.1180e-02, -8.8872e-03],
        [ 6.3797e-01,  5.6083e-01,  4.4857e-01,  3.9470e-01,  3.5115e-01,
          4.5992e-01,  4.6203e-01,  5.5089e-01,  5.4218e-01,  4.6569e-01],
        [ 6.1559e-02, -2.3323e-03, -9.1709e-02, -2.8601e-02, -1.9799e-02,
          4.4297e-02,  4.5148e-02,  8.9939e-02,  8.6023e-02,  5.2349e-02],
        [ 3.0239e-02,  1.5243e-02,  1.8296e-02,  1.4963e-03,  5.3061e-03,
          2.8927e-02,  3.4717e-02,  1.4071e-02, -1.3342e-02,  2.0494e-04],
        [ 1.7098e-02,  1.4906e-02,  1.1837e-02,  8.3297e-03,  3.9456e-03,
         -4.3840e-04, -2.6304e-03, -4.3840e-03, -3.9456e-03, -3.0688e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.7582, 10.7581, 10.7571, 10.7566, 10.7576, 10.7579, 10.7587, 10.7587,
         10.7585, 10.7587]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.1028e+01,  1.1029e+01,  1.1029e+01,  1.1030e+01,  1.1029e+01,
          1.1029e+01,  1.1028e+01,  1.1028e+01,  1.1028e+01,  1.1028e+01],
        [-5.0697e-02, -4.7883e-02, -4.4053e-02, -3.8659e-02, -3.6659e-02,
         -3.2480e-02, -3.6530e-02, -3.7759e-02, -3.8738e-02, -3.7839e-02],
        [-3.0574e-02, -3.4851e-02, -3.7441e-02, -3.8343e-02, -3.8630e-02,
         -3.7953e-02, -3.8290e-02, -3.8827e-02, -3.9468e-02, -3.9786e-02],
        [-5.8112e-02, -4.0682e-02, -2.4638e-02, -8.5759e-03, -2.7317e-03,
          6.4418e-03, -3.2073e-03, -5.1041e-03, -6.1036e-03, -3.0266e-03],
        [ 3.0789e-01,  3.9209e-01,  3.7337e-01,  3.6022e-01,  2.7788e-01,
          3.7077e-01,  3.7176e-01,  4.8414e-01,  4.4587e-01,  5.1815e-01],
        [-1.1866e-02,  3.8900e-02,  3.0252e-02,  2.4174e-02, -1.3858e-02,
          5.4205e-02,  7.9639e-02,  2.2353e-01,  1.3866e-01,  1.9831e-01],
        [ 1.3508e-01,  5.9443e-02, -3.9382e-03, -7.7688e-02, -5.5947e-02,
         -8.3518e-02, -5.2559e-02, -6.4176e-02, -7.9252e-02, -5.7113e-02],
        [-2.9811e-02, -3.5511e-02, -3.7264e-02, -3.6826e-02, -3.4196e-02,
         -3.2004e-02, -2.7181e-02, -2.4112e-02, -1.9290e-02, -1.5344e-02]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[11.0288, 11.0291, 11.0295, 11.0289, 11.0294, 11.0276, 11.0280, 11.0279,
         11.0281, 11.0276]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0368e+01,  1.0368e+01,  1.0367e+01,  1.0368e+01,  1.0367e+01,
          1.0367e+01,  1.0367e+01,  1.0367e+01,  1.0367e+01,  1.0366e+01],
        [ 1.3046e-02,  1.3617e-02,  1.2708e-02,  1.2362e-02,  1.1265e-02,
          9.5830e-03,  7.6960e-03,  6.2375e-03,  4.6620e-03,  2.8403e-03],
        [ 1.7490e-02,  1.6947e-02,  1.6316e-02,  1.5735e-02,  1.5033e-02,
          1.4106e-02,  1.2955e-02,  1.1718e-02,  1.0386e-02,  8.9252e-03],
        [-7.9274e-03, -5.1629e-03, -6.0070e-03, -5.5208e-03, -6.6800e-03,
         -8.8167e-03, -1.0949e-02, -1.1770e-02, -1.2668e-02, -1.3895e-02],
        [ 5.6282e-01,  6.5383e-01,  5.4864e-01,  5.8400e-01,  5.4403e-01,
          4.8004e-01,  4.9566e-01,  5.3318e-01,  4.4027e-01,  3.7582e-01],
        [ 1.0712e-01,  1.5410e-01,  1.1563e-01,  1.3400e-01,  1.1324e-01,
          8.0014e-02,  8.8134e-02,  1.0761e-01,  5.9380e-02,  2.5928e-02],
        [-7.5096e-03, -3.9288e-03, -1.0268e-02, -1.4499e-02, -4.6186e-03,
          3.4283e-04, -5.3977e-04,  1.5982e-03, -3.6197e-03,  6.7154e-03],
        [-4.8224e-03, -3.0688e-03, -4.3840e-04,  4.3840e-04,  2.1920e-03,
          3.0688e-03,  2.6304e-03,  2.1920e-03,  1.7536e-03,  4.3840e-04]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.3679, 10.3674, 10.3676, 10.3673, 10.3670, 10.3668, 10.3668, 10.3666,
         10.3664, 10.3662]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0745e+01,  1.0744e+01,  1.0744e+01,  1.0744e+01,  1.0744e+01,
          1.0745e+01,  1.0745e+01,  1.0744e+01,  1.0744e+01,  1.0745e+01],
        [-7.4983e-02, -7.8712e-02, -8.1887e-02, -8.0887e-02, -7.9073e-02,
         -7.5893e-02, -7.1645e-02, -7.1426e-02, -7.0440e-02, -6.5713e-02],
        [-1.0249e-01, -9.9074e-02, -9.7031e-02, -9.5179e-02, -9.3303e-02,
         -9.1113e-02, -8.8439e-02, -8.6252e-02, -8.4289e-02, -8.1692e-02],
        [ 5.0237e-02,  3.2491e-02,  1.9440e-02,  1.7616e-02,  1.7837e-02,
          2.0835e-02,  2.5437e-02,  2.0801e-02,  1.8677e-02,  2.4699e-02],
        [ 5.2436e-01,  3.9644e-01,  2.6518e-01,  3.3619e-01,  3.8480e-01,
          3.4133e-01,  3.7523e-01,  3.4359e-01,  2.3935e-01,  3.2893e-01],
        [ 1.3769e-01, -7.5587e-03, -1.1898e-01,  3.7879e-02,  6.3824e-02,
          4.0637e-02,  5.8716e-02,  4.1828e-02, -1.3773e-02,  4.5795e-02],
        [-1.4063e-03,  2.8121e-02,  1.9870e-02,  1.2817e-02,  5.2918e-02,
          4.5432e-02,  2.0575e-02,  3.8966e-02,  1.2072e-02, -6.1437e-03],
        [ 8.7681e-03,  5.6993e-03, -0.0000e+00, -8.7681e-03, -1.4029e-02,
         -1.7098e-02, -2.1482e-02, -2.3235e-02, -2.5427e-02, -2.8935e-02]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.7440, 10.7436, 10.7444, 10.7445, 10.7447, 10.7450, 10.7438, 10.7438,
         10.7448, 10.7449]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0504e+01,  1.0504e+01,  1.0503e+01,  1.0503e+01,  1.0504e+01,
          1.0503e+01,  1.0504e+01,  1.0503e+01,  1.0503e+01,  1.0504e+01],
        [-3.6659e-03,  2.4880e-03,  3.0407e-03,  3.7513e-03,  6.1556e-03,
          5.8208e-03,  7.7841e-03,  7.5498e-03,  7.4354e-03,  1.0318e-02],
        [-1.5214e-02, -1.1631e-02, -8.6451e-03, -6.1020e-03, -3.5456e-03,
         -1.5733e-03,  4.3069e-04,  1.9830e-03,  3.2001e-03,  4.7993e-03],
        [ 2.6720e-02,  3.4080e-02,  2.8405e-02,  2.4191e-02,  2.4316e-02,
          1.8762e-02,  1.9062e-02,  1.4766e-02,  1.1577e-02,  1.5213e-02],
        [ 6.1936e-01,  6.4112e-01,  5.4587e-01,  5.5010e-01,  5.7814e-01,
          5.7454e-01,  5.6761e-01,  5.5009e-01,  5.9301e-01,  6.4428e-01],
        [ 1.6830e-01,  1.7831e-01,  1.2846e-01,  1.3032e-01,  1.4261e-01,
          1.4105e-01,  1.3624e-01,  1.2816e-01,  1.4799e-01,  1.7177e-01],
        [-1.0243e-02, -2.7012e-02, -2.7502e-03, -7.1391e-03, -2.7446e-02,
         -3.6249e-02, -4.5103e-03, -4.5692e-02, -1.4218e-03,  3.3185e-02],
        [-7.4529e-03, -4.3840e-04,  6.1377e-03,  9.2065e-03,  1.1399e-02,
          1.4029e-02,  1.6221e-02,  1.8413e-02,  1.7975e-02,  1.9290e-02]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.5043, 10.5026, 10.5027, 10.5035, 10.5026, 10.5036, 10.5029, 10.5030,
         10.5042, 10.5030]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.1023e+01,  1.1023e+01,  1.1023e+01,  1.1023e+01,  1.1022e+01,
          1.1022e+01,  1.1022e+01,  1.1021e+01,  1.1021e+01,  1.1021e+01],
        [ 5.2530e-02,  5.5735e-02,  5.6895e-02,  5.5920e-02,  5.0761e-02,
          4.7053e-02,  4.2277e-02,  3.6015e-02,  2.9628e-02,  2.3028e-02],
        [ 2.9760e-02,  3.5903e-02,  4.1070e-02,  4.4992e-02,  4.7010e-02,
          4.7819e-02,  4.7430e-02,  4.5760e-02,  4.3038e-02,  3.9428e-02],
        [ 6.4781e-02,  5.8440e-02,  4.9148e-02,  3.7305e-02,  1.9193e-02,
          7.7002e-03, -3.6994e-03, -1.5886e-02, -2.5894e-02, -3.4340e-02],
        [ 6.6612e-01,  6.4169e-01,  6.4081e-01,  6.2608e-01,  6.0453e-01,
          5.8994e-01,  5.3745e-01,  5.0671e-01,  4.7545e-01,  5.1970e-01],
        [ 1.5838e-01,  1.4535e-01,  1.4494e-01,  1.3425e-01,  1.2004e-01,
          1.1159e-01,  8.2584e-02,  6.5577e-02,  4.8298e-02,  7.8584e-02],
        [-5.2711e-02, -3.2049e-02,  1.2122e-02,  2.1469e-02,  3.9730e-02,
         -1.9362e-02, -1.2972e-01,  1.0298e-01,  9.7278e-02,  8.3186e-02],
        [ 2.5427e-02,  3.0250e-02,  3.3757e-02,  3.5511e-02,  3.5072e-02,
          3.3319e-02,  3.0250e-02,  2.6743e-02,  2.4112e-02,  1.5783e-02]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[11.0233, 11.0231, 11.0228, 11.0219, 11.0221, 11.0218, 11.0213, 11.0210,
         11.0207, 11.0204]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0514e+01,  1.0517e+01,  1.0521e+01,  1.0522e+01,  1.0522e+01,
          1.0523e+01,  1.0525e+01,  1.0523e+01,  1.0523e+01,  1.0525e+01],
        [-4.8362e-02, -4.3899e-02, -3.0120e-02, -1.4683e-02, -2.6327e-03,
          9.2741e-03,  2.2531e-02,  2.7136e-02,  3.2073e-02,  3.9460e-02],
        [-4.5186e-02, -4.5676e-02, -4.3077e-02, -3.7649e-02, -3.0690e-02,
         -2.2540e-02, -1.3142e-02, -4.6243e-03,  3.2612e-03,  1.1173e-02],
        [-1.7341e-02, -4.6596e-03,  2.4718e-02,  5.1641e-02,  6.6189e-02,
          7.7531e-02,  8.9393e-02,  8.1019e-02,  7.5009e-02,  7.5255e-02],
        [ 3.0598e-01,  4.5009e-01,  5.9836e-01,  5.9821e-01,  6.0836e-01,
          6.9051e-01,  7.6092e-01,  6.6735e-01,  7.0316e-01,  7.6595e-01],
        [ 5.3933e-02,  2.0827e-01,  3.0005e-01,  1.7017e-01,  1.7521e-01,
          2.0989e-01,  1.9780e-01,  1.3871e-01,  1.5078e-01,  1.7194e-01],
        [ 5.9627e-03, -1.9102e-02, -3.5910e-02, -2.9650e-02, -4.4653e-02,
         -6.6028e-02, -6.6847e-02, -5.1922e-02, -4.3294e-02, -4.5004e-02],
        [-4.2525e-02, -4.2087e-02, -3.6826e-02, -2.3674e-02, -1.0083e-02,
          2.1920e-03,  1.5783e-02,  3.1565e-02,  4.1210e-02,  4.9540e-02]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.5167, 10.5206, 10.5223, 10.5222, 10.5232, 10.5248, 10.5226, 10.5233,
         10.5248, 10.5238]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0665e+01,  1.0665e+01,  1.0664e+01,  1.0664e+01,  1.0664e+01,
          1.0664e+01,  1.0665e+01,  1.0665e+01,  1.0665e+01,  1.0666e+01],
        [ 1.8472e-02,  2.1443e-02,  2.3048e-02,  2.3142e-02,  2.3312e-02,
          2.3156e-02,  2.5320e-02,  2.6726e-02,  2.7894e-02,  3.0581e-02],
        [ 6.8660e-03,  1.0146e-02,  1.3119e-02,  1.5517e-02,  1.7473e-02,
          1.9004e-02,  2.0698e-02,  2.2359e-02,  2.3941e-02,  2.5789e-02],
        [ 3.1338e-02,  3.1204e-02,  2.8276e-02,  2.2815e-02,  1.8603e-02,
          1.4561e-02,  1.6115e-02,  1.5796e-02,  1.5048e-02,  1.7585e-02],
        [ 6.5227e-01,  6.0508e-01,  7.3887e-01,  6.9156e-01,  6.8625e-01,
          6.7559e-01,  8.2576e-01,  7.6357e-01,  7.3581e-01,  7.6313e-01],
        [ 1.5821e-01,  1.3269e-01,  2.0499e-01,  1.4738e-01,  1.4336e-01,
          1.3791e-01,  2.1462e-01,  1.3226e-01,  1.0085e-01,  1.2193e-01],
        [-4.2026e-03, -2.6527e-03, -3.2462e-02,  5.7980e-03,  1.7066e-02,
          1.7454e-02,  1.2185e-02, -6.1851e-03,  1.2014e-02,  1.0443e-02],
        [ 1.9728e-02,  2.2359e-02,  2.2797e-02,  2.3674e-02,  2.4551e-02,
          2.3235e-02,  2.1920e-02,  2.2359e-02,  2.1482e-02,  2.1043e-02]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.6646, 10.6645, 10.6642, 10.6643, 10.6643, 10.6652, 10.6652, 10.6653,
         10.6660, 10.6659]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0523e+01,  1.0525e+01,  1.0526e+01,  1.0528e+01,  1.0528e+01,
          1.0528e+01,  1.0528e+01,  1.0529e+01,  1.0529e+01,  1.0526e+01],
        [-1.3624e-01, -1.3302e-01, -1.2538e-01, -1.1445e-01, -1.0497e-01,
         -9.6400e-02, -8.8563e-02, -7.9173e-02, -7.0064e-02, -6.8466e-02],
        [-1.0504e-01, -1.1290e-01, -1.1753e-01, -1.1886e-01, -1.1787e-01,
         -1.1522e-01, -1.1140e-01, -1.0630e-01, -1.0024e-01, -9.5054e-02],
        [-1.0176e-01, -7.4767e-02, -4.4030e-02, -1.2661e-02,  9.4290e-03,
          2.5244e-02,  3.6374e-02,  4.8484e-02,  5.7591e-02,  4.9370e-02],
        [ 2.0318e-01,  2.2602e-01,  2.6398e-01,  3.5944e-01,  3.3014e-01,
          3.4508e-01,  3.3705e-01,  3.4891e-01,  4.9551e-01,  4.9401e-01],
        [ 3.6432e-02,  4.8281e-02,  6.7995e-02,  1.3378e-01,  1.1648e-01,
          1.2530e-01,  1.2055e-01,  1.2756e-01,  2.7256e-01,  1.6953e-01],
        [ 4.1154e-02,  3.4751e-02,  5.5135e-02,  7.7319e-02, -4.4112e-02,
         -8.8492e-02, -1.1990e-01, -1.2717e-01, -1.2516e-01, -1.6390e-01],
        [-1.0259e-01, -1.0829e-01, -1.1092e-01, -1.0960e-01, -1.0215e-01,
         -9.5134e-02, -8.2420e-02, -6.9268e-02, -5.5239e-02, -3.7264e-02]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.5250, 10.5264, 10.5278, 10.5277, 10.5277, 10.5277, 10.5286, 10.5289,
         10.5264, 10.5269]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0364e+01,  1.0364e+01,  1.0364e+01,  1.0364e+01,  1.0365e+01,
          1.0366e+01,  1.0368e+01,  1.0368e+01,  1.0370e+01,  1.0369e+01],
        [ 1.4482e-02,  9.9841e-03,  6.7104e-03,  3.1231e-03,  2.7027e-03,
          5.5651e-03,  1.1409e-02,  1.7132e-02,  2.3776e-02,  2.6907e-02],
        [ 2.2780e-02,  2.0391e-02,  1.7769e-02,  1.4893e-02,  1.2501e-02,
          1.1208e-02,  1.1443e-02,  1.2872e-02,  1.5458e-02,  1.8206e-02],
        [-1.6802e-02, -2.2727e-02, -2.4940e-02, -2.7357e-02, -2.2753e-02,
         -1.2294e-02,  2.2287e-03,  1.3597e-02,  2.4594e-02,  2.6137e-02],
        [ 4.6805e-01,  4.6179e-01,  4.7149e-01,  4.0596e-01,  4.6292e-01,
          5.1620e-01,  5.7951e-01,  5.8107e-01,  5.8520e-01,  5.2094e-01],
        [-3.2005e-02, -2.9622e-03,  4.5114e-03, -2.5945e-02,  2.2966e-02,
          4.4450e-02,  6.9969e-02,  7.0599e-02,  7.2268e-02,  4.6357e-02],
        [ 3.2109e-03,  1.0203e-02,  1.0675e-02,  2.1083e-02,  3.9650e-02,
          5.4826e-02,  1.9354e-02,  6.1577e-03, -1.0763e-02, -6.4383e-03],
        [ 1.5344e-02,  1.0522e-02,  5.6993e-03,  1.7536e-03, -3.0688e-03,
         -5.6993e-03, -6.5761e-03, -4.8224e-03, -8.7681e-04,  4.3840e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.3638, 10.3640, 10.3636, 10.3647, 10.3662, 10.3679, 10.3685, 10.3696,
         10.3688, 10.3675]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0784e+01,  1.0784e+01,  1.0784e+01,  1.0785e+01,  1.0785e+01,
          1.0785e+01,  1.0785e+01,  1.0785e+01,  1.0785e+01,  1.0785e+01],
        [-1.5916e-02, -1.6280e-02, -1.6857e-02, -1.4890e-02, -1.2681e-02,
         -1.0879e-02, -8.5648e-03, -6.1085e-03, -4.5816e-03, -2.9539e-03],
        [-1.8668e-02, -1.8468e-02, -1.8433e-02, -1.7977e-02, -1.7134e-02,
         -1.6068e-02, -1.4713e-02, -1.3096e-02, -1.1471e-02, -9.8181e-03],
        [ 3.3230e-03,  1.9069e-03,  3.3541e-04,  4.3297e-03,  8.0221e-03,
          1.0139e-02,  1.2888e-02,  1.5381e-02,  1.5457e-02,  1.5726e-02],
        [ 4.3711e-01,  4.3297e-01,  4.1709e-01,  4.1486e-01,  5.7082e-01,
          4.9725e-01,  6.0389e-01,  6.4414e-01,  5.4963e-01,  5.4070e-01],
        [ 5.0238e-02,  4.5829e-02,  2.8924e-02,  2.6541e-02,  2.1112e-01,
          1.0100e-01,  2.0136e-01,  2.0228e-01,  1.0695e-01,  9.3429e-02],
        [-1.8083e-02,  9.8423e-04, -1.0132e-02, -1.1472e-02,  4.4031e-03,
          8.4604e-03,  1.5264e-02, -1.3309e-03, -5.2785e-03, -8.0908e-03],
        [-2.6304e-03, -3.5072e-03, -3.5072e-03, -4.3840e-03, -3.9456e-03,
         -2.6304e-03, -2.1920e-03, -8.7681e-04,  0.0000e+00,  8.7681e-04]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.7842, 10.7841, 10.7848, 10.7849, 10.7849, 10.7851, 10.7853, 10.7852,
         10.7853, 10.7852]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0856e+01,  1.0856e+01,  1.0855e+01,  1.0855e+01,  1.0854e+01,
          1.0855e+01,  1.0855e+01,  1.0855e+01,  1.0855e+01,  1.0855e+01],
        [ 2.8380e-02,  2.5240e-02,  1.9547e-02,  1.3146e-02,  3.7082e-03,
         -9.7245e-04, -1.8911e-03, -2.5892e-03, -3.7359e-03, -5.7708e-03],
        [ 3.2933e-02,  3.1824e-02,  2.9701e-02,  2.6614e-02,  2.2096e-02,
          1.7466e-02,  1.3562e-02,  1.0288e-02,  7.4194e-03,  4.6832e-03],
        [-5.0831e-03, -1.0547e-02, -2.0191e-02, -2.9367e-02, -4.2976e-02,
         -4.4044e-02, -3.7131e-02, -3.1146e-02, -2.7284e-02, -2.6028e-02],
        [ 4.6316e-01,  4.2765e-01,  3.9548e-01,  3.1934e-01,  2.8434e-01,
          3.3520e-01,  3.4822e-01,  3.3014e-01,  3.3201e-01,  3.1508e-01],
        [-9.9132e-02, -1.6633e-02, -1.3721e-02, -3.0065e-02, -1.1747e-02,
          1.5969e-02,  2.0054e-02,  1.4385e-02,  1.6582e-02,  1.1100e-02],
        [ 1.5174e-02,  1.7586e-02,  3.1652e-02,  3.3475e-02,  2.6047e-02,
          2.5737e-02,  1.1946e-02,  1.7294e-02,  2.3526e-02,  2.4329e-02],
        [ 2.1043e-02,  1.5344e-02,  1.0522e-02,  5.2609e-03, -4.3840e-04,
         -7.0145e-03, -1.0960e-02, -1.3591e-02, -1.4906e-02, -1.6221e-02]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.8563, 10.8555, 10.8550, 10.8538, 10.8545, 10.8553, 10.8553, 10.8551,
         10.8548, 10.8547]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0596e+01,  1.0594e+01,  1.0594e+01,  1.0596e+01,  1.0597e+01,
          1.0598e+01,  1.0597e+01,  1.0597e+01,  1.0597e+01,  1.0597e+01],
        [-1.3021e-02, -2.2964e-02, -2.8574e-02, -2.7231e-02, -2.3928e-02,
         -1.9507e-02, -1.8429e-02, -1.5218e-02, -1.3307e-02, -1.1069e-02],
        [ 6.5546e-03,  2.6007e-04, -5.9932e-03, -1.0704e-02, -1.3756e-02,
         -1.5239e-02, -1.6190e-02, -1.6255e-02, -1.5892e-02, -1.5116e-02],
        [-4.9187e-02, -5.9875e-02, -5.9483e-02, -4.4812e-02, -2.9033e-02,
         -1.4100e-02, -9.0533e-03, -6.1452e-04,  3.4531e-03,  7.3837e-03],
        [ 3.7484e-01,  3.2840e-01,  3.3874e-01,  4.6524e-01,  4.8097e-01,
          4.2590e-01,  3.5156e-01,  4.1157e-01,  4.4821e-01,  4.7065e-01],
        [-7.5077e-03, -4.4654e-02,  7.8822e-03,  1.0422e-01,  1.1621e-01,
          7.4259e-02,  1.7637e-02,  6.3347e-02,  1.2017e-01,  1.5873e-01],
        [-2.3217e-02,  3.1926e-02,  6.6989e-02,  4.7665e-02,  1.6392e-02,
          8.6070e-03,  2.8587e-02,  3.2319e-03, -3.7118e-02, -5.1122e-02],
        [-1.1837e-02, -1.4906e-02, -2.1482e-02, -2.7619e-02, -2.9373e-02,
         -2.8058e-02, -2.6304e-02, -2.6743e-02, -2.5427e-02, -2.1920e-02]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.5936, 10.5943, 10.5963, 10.5970, 10.5976, 10.5966, 10.5974, 10.5971,
         10.5973, 10.5967]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
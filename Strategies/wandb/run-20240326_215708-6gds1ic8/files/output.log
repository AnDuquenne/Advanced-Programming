  0%|          | 0/350 [00:00<?, ?it/s]C:\Users\dadou\anaconda3\envs\Advanced-Programming\Lib\site-packages\torch\nn\functional.py:5476: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\aten\src\ATen\native\transformers\cuda\sdp_utils.cpp:263.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0785e+01,  1.0785e+01,  1.0785e+01,  1.0784e+01,  1.0785e+01,
          1.0785e+01,  1.0785e+01,  1.0786e+01,  1.0785e+01,  1.0786e+01],
        [ 6.5306e+01,  5.7068e+01,  5.1463e+01,  4.3326e+01,  3.7061e+01,
          3.3215e+01,  3.1310e+01,  3.1381e+01,  2.8512e+01,  2.7762e+01],
        [ 6.1259e+01,  6.0421e+01,  5.8629e+01,  5.5569e+01,  5.1867e+01,
          4.8137e+01,  4.4771e+01,  4.2093e+01,  3.9377e+01,  3.7054e+01],
        [ 4.0474e+00, -3.3526e+00, -7.1661e+00, -1.2242e+01, -1.4806e+01,
         -1.4922e+01, -1.3461e+01, -1.0712e+01, -1.0865e+01, -9.2915e+00],
        [ 5.7866e+01,  6.1609e+01,  5.9386e+01,  5.0802e+01,  4.8341e+01,
          4.9655e+01,  4.4261e+01,  5.1047e+01,  5.0175e+01,  5.0200e+01],
        [-1.1770e-01,  1.5640e-01,  6.3500e-02, -2.9520e-01, -7.9400e-02,
          3.9300e-02, -1.2200e-01,  2.4860e-01,  2.1670e-01,  2.1760e-01],
        [ 3.1836e+01,  2.5131e+01,  9.6449e+01,  3.9211e+01,  1.3456e+01,
          3.2890e+01,  1.3121e+02,  1.6334e+02,  5.7150e+01,  6.9710e+01],
        [ 8.6000e-03,  7.7000e-03,  6.8000e-03,  6.0000e-03,  4.4000e-03,
          3.1000e-03,  2.2000e-03,  1.1000e-03,  2.0000e-04, -8.0000e-04]])
preds tensor([[-0.0038, -0.0046, -0.0016, -0.0040, -0.0051, -0.0058, -0.0047, -0.0063,
         -0.0054, -0.0054]], grad_fn=<ToCopyBackward0>)
targets tensor([[10.7848, 10.7852, 10.7844, 10.7845, 10.7849, 10.7853, 10.7858, 10.7851,
         10.7856, 10.7847]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0710e+01,  1.0710e+01,  1.0710e+01,  1.0709e+01,  1.0708e+01,
          1.0708e+01,  1.0709e+01,  1.0710e+01,  1.0709e+01,  1.0709e+01],
        [-2.5386e+01, -2.1765e+01, -1.7117e+01, -1.7579e+01, -2.0655e+01,
         -2.3179e+01, -2.1581e+01, -1.8666e+01, -1.9917e+01, -2.0670e+01],
        [-2.9299e+01, -2.7792e+01, -2.5657e+01, -2.4041e+01, -2.3364e+01,
         -2.3327e+01, -2.2978e+01, -2.2116e+01, -2.1676e+01, -2.1475e+01],
        [ 3.9126e+00,  6.0268e+00,  8.5402e+00,  6.4620e+00,  2.7093e+00,
          1.4800e-01,  1.3965e+00,  3.4494e+00,  1.7588e+00,  8.0460e-01],
        [ 4.0493e+01,  4.8434e+01,  5.1253e+01,  4.9694e+01,  4.2060e+01,
          4.2058e+01,  5.5967e+01,  5.7346e+01,  5.7437e+01,  5.1315e+01],
        [ 6.2680e-01,  1.4637e+00,  1.1125e+00,  9.4410e-01,  6.7030e-01,
          6.7030e-01,  1.1690e+00,  1.0423e+00,  1.0027e+00,  7.5170e-01],
        [-1.7438e+01, -1.9422e+01, -7.7753e+01, -6.9672e+01, -1.1136e+02,
         -5.7324e+01, -1.1857e+01, -8.1157e+00,  2.3433e+01,  1.3664e+01],
        [-5.1000e-03, -4.3000e-03, -3.4000e-03, -2.4000e-03, -1.5000e-03,
         -1.2000e-03, -8.0000e-04, -2.0000e-04,  3.0000e-04,  5.0000e-04]])
preds tensor([[ 0.0032,  0.0017,  0.0027,  0.0029,  0.0027,  0.0024,  0.0027,  0.0015,
         -0.0005,  0.0029]], grad_fn=<ToCopyBackward0>)
targets tensor([[10.7101, 10.7105, 10.7093, 10.7085, 10.7084, 10.7093, 10.7097, 10.7087,
         10.7087, 10.7089]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0815e+01,  1.0815e+01,  1.0816e+01,  1.0817e+01,  1.0818e+01,
          1.0818e+01,  1.0818e+01,  1.0819e+01,  1.0819e+01,  1.0818e+01],
        [-6.2816e+01, -6.6906e+01, -6.5674e+01, -6.2793e+01, -5.5589e+01,
         -4.9766e+01, -4.3919e+01, -3.3872e+01, -2.6876e+01, -2.4464e+01],
        [-1.8825e+01, -2.8441e+01, -3.5888e+01, -4.1269e+01, -4.4133e+01,
         -4.5259e+01, -4.4991e+01, -4.2768e+01, -3.9589e+01, -3.6564e+01],
        [-4.3991e+01, -3.8465e+01, -2.9786e+01, -2.1524e+01, -1.1456e+01,
         -4.5064e+00,  1.0724e+00,  8.8950e+00,  1.2713e+01,  1.2100e+01],
        [ 2.1709e+01,  2.0198e+01,  2.5269e+01,  2.5078e+01,  3.0727e+01,
          3.6956e+01,  3.5238e+01,  4.8629e+01,  4.9924e+01,  4.9364e+01],
        [ 8.4500e-02,  6.4000e-02,  1.3270e-01,  1.3010e-01,  2.0660e-01,
          4.7190e-01,  4.8160e-01,  1.1158e+00,  1.0391e+00,  9.8370e-01],
        [ 1.4619e+02,  3.4141e+01,  7.0900e+01, -9.2719e+00, -2.7218e+01,
         -5.4434e+01, -6.0967e+01, -1.0607e+02, -1.3456e+02, -2.2398e+02],
        [-9.1000e-03, -1.1000e-02, -1.2300e-02, -1.2500e-02, -1.2600e-02,
         -1.1800e-02, -1.0500e-02, -9.1000e-03, -6.9000e-03, -4.7000e-03]])
preds tensor([[0.0058, 0.0067, 0.0057, 0.0078, 0.0075, 0.0081, 0.0064, 0.0078, 0.0076,
         0.0082]], grad_fn=<ToCopyBackward0>)
targets tensor([[10.8154, 10.8163, 10.8166, 10.8177, 10.8176, 10.8178, 10.8190, 10.8187,
         10.8179, 10.8187]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0945e+01,  1.0946e+01,  1.0947e+01,  1.0947e+01,  1.0946e+01,
          1.0947e+01,  1.0947e+01,  1.0947e+01,  1.0949e+01,  1.0948e+01],
        [ 3.8030e+01,  4.0503e+01,  4.5799e+01,  5.1473e+01,  5.2707e+01,
          5.8043e+01,  5.7239e+01,  5.9701e+01,  6.8098e+01,  7.1365e+01],
        [ 1.8671e+01,  2.3038e+01,  2.7590e+01,  3.2367e+01,  3.6435e+01,
          4.0756e+01,  4.4053e+01,  4.7182e+01,  5.1366e+01,  5.5365e+01],
        [ 1.9359e+01,  1.7466e+01,  1.8209e+01,  1.9106e+01,  1.6272e+01,
          1.7287e+01,  1.3186e+01,  1.2518e+01,  1.6732e+01,  1.6000e+01],
        [ 6.2846e+01,  6.1076e+01,  6.8046e+01,  6.7520e+01,  6.3317e+01,
          6.3549e+01,  6.5926e+01,  6.0701e+01,  6.8304e+01,  6.4645e+01],
        [ 6.0300e-01,  4.2920e-01,  6.5690e-01,  6.3970e-01,  4.7280e-01,
          1.4150e-01,  2.7750e-01, -2.1500e-02,  4.2590e-01,  2.2090e-01],
        [ 2.7659e+01,  6.8877e+01, -2.8827e+01,  8.8041e+01,  4.4491e+01,
          3.6915e+01,  1.0136e+02, -1.8180e+01, -1.3075e+01,  1.4457e+01],
        [ 8.4000e-03,  8.0000e-03,  7.4000e-03,  7.1000e-03,  7.2000e-03,
          6.6000e-03,  6.3000e-03,  6.1000e-03,  5.5000e-03,  6.0000e-03]])
preds tensor([[0.0109, 0.0104, 0.0107, 0.0081, 0.0108, 0.0104, 0.0091, 0.0109, 0.0100,
         0.0105]], grad_fn=<ToCopyBackward0>)
targets tensor([[10.9457, 10.9465, 10.9470, 10.9464, 10.9475, 10.9465, 10.9474, 10.9489,
         10.9484, 10.9471]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0919e+01,  1.0918e+01,  1.0918e+01,  1.0920e+01,  1.0917e+01,
          1.0919e+01,  1.0918e+01,  1.0919e+01,  1.0921e+01,  1.0921e+01],
        [ 6.1897e+01,  5.9037e+01,  5.6278e+01,  6.0530e+01,  5.3044e+01,
          5.2851e+01,  4.9667e+01,  4.7728e+01,  5.7107e+01,  6.4248e+01],
        [ 4.0645e+01,  4.4324e+01,  4.6715e+01,  4.9478e+01,  5.0191e+01,
          5.0723e+01,  5.0512e+01,  4.9955e+01,  5.1386e+01,  5.3958e+01],
        [ 2.1252e+01,  1.4714e+01,  9.5634e+00,  1.1052e+01,  2.8532e+00,
          2.1277e+00, -8.4430e-01, -2.2267e+00,  5.7215e+00,  1.0290e+01],
        [ 5.2552e+01,  5.3992e+01,  5.3968e+01,  5.7921e+01,  4.9588e+01,
          5.9192e+01,  5.7694e+01,  5.9009e+01,  6.2366e+01,  5.8685e+01],
        [ 7.0600e-02,  1.5030e-01,  1.4890e-01,  3.6770e-01, -9.4800e-02,
          6.7400e-01,  5.6890e-01,  6.6120e-01,  8.9670e-01,  6.3840e-01],
        [ 6.9067e+01, -5.4900e+01, -7.2247e+01, -9.6296e+01, -6.3634e+01,
          3.2147e+01, -1.1258e+02,  3.0667e+01,  1.2985e+02,  1.3522e+02],
        [ 4.9000e-03,  4.5000e-03,  4.0000e-03,  3.9000e-03,  4.4000e-03,
          4.0000e-03,  4.3000e-03,  4.1000e-03,  4.5000e-03,  5.1000e-03]])
preds tensor([[0.0130, 0.0133, 0.0127, 0.0128, 0.0135, 0.0093, 0.0131, 0.0121, 0.0134,
         0.0132]], grad_fn=<ToCopyBackward0>)
targets tensor([[10.9181, 10.9181, 10.9197, 10.9174, 10.9188, 10.9183, 10.9186, 10.9211,
         10.9212, 10.9252]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0601e+01,  1.0601e+01,  1.0602e+01,  1.0601e+01,  1.0600e+01,
          1.0599e+01,  1.0600e+01,  1.0600e+01,  1.0602e+01,  1.0601e+01],
        [ 2.8593e+00,  5.9327e+00,  9.0755e+00,  9.1346e+00,  4.9350e+00,
          8.8890e-01, -1.4393e+00, -2.8561e+00,  1.4734e+00,  2.7467e+00],
        [-1.6114e+00, -1.0260e-01,  1.7331e+00,  3.2134e+00,  3.5577e+00,
          3.0239e+00,  2.1313e+00,  1.1338e+00,  1.2017e+00,  1.5107e+00],
        [ 4.4707e+00,  6.0353e+00,  7.3425e+00,  5.9212e+00,  1.3773e+00,
         -2.1350e+00, -3.5706e+00, -3.9899e+00,  2.7170e-01,  1.2359e+00],
        [ 5.5256e+01,  6.9901e+01,  6.9024e+01,  6.1528e+01,  4.9532e+01,
          5.1958e+01,  4.6836e+01,  4.7243e+01,  6.3057e+01,  5.2306e+01],
        [ 9.3480e-01,  1.6207e+00,  9.7710e-01,  7.8100e-01,  4.6730e-01,
          5.2450e-01,  2.6150e-01,  2.7450e-01,  7.8080e-01,  2.3710e-01],
        [-2.1812e+01, -4.3509e+01, -6.6414e+00, -5.0048e+00, -3.0302e+01,
          1.0779e+01,  1.8448e+01,  3.1062e+01,  1.8886e+01,  6.6957e+00],
        [ 0.0000e+00,  5.0000e-04,  1.3000e-03,  2.1000e-03,  2.3000e-03,
          1.9000e-03,  1.7000e-03,  1.1000e-03,  7.0000e-04,  9.0000e-04]])
preds tensor([[0.0158, 0.0148, 0.0159, 0.0153, 0.0152, 0.0153, 0.0160, 0.0159, 0.0143,
         0.0160]], grad_fn=<ToCopyBackward0>)
targets tensor([[10.6014, 10.6017, 10.6010, 10.5997, 10.5995, 10.5997, 10.5998, 10.6015,
         10.6009, 10.5999]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.1000e+01,  1.0999e+01,  1.1002e+01,  1.1000e+01,  1.1001e+01,
          1.1002e+01,  1.1003e+01,  1.1000e+01,  1.1001e+01,  1.1002e+01],
        [-2.9305e+01, -2.8788e+01, -1.5549e+01, -1.4583e+01, -7.8179e+00,
          1.2018e+00,  1.1282e+01,  7.8577e+00,  7.8134e+00,  1.0574e+01],
        [-3.6652e+01, -3.5079e+01, -3.1173e+01, -2.7855e+01, -2.3848e+01,
         -1.8838e+01, -1.2814e+01, -8.6794e+00, -5.3809e+00, -2.1899e+00],
        [ 7.3466e+00,  6.2913e+00,  1.5624e+01,  1.3272e+01,  1.6030e+01,
          2.0039e+01,  2.4096e+01,  1.6537e+01,  1.3194e+01,  1.2764e+01],
        [ 4.6474e+01,  4.5310e+01,  6.0659e+01,  5.0186e+01,  5.3219e+01,
          6.3124e+01,  7.1416e+01,  5.8220e+01,  5.9617e+01,  5.7860e+01],
        [ 8.1580e-01,  7.6770e-01,  1.4021e+00,  6.9130e-01,  7.8070e-01,
          1.0727e+00,  1.2279e+00,  7.0470e-01,  7.3590e-01,  6.9660e-01],
        [-1.9848e+00, -9.8336e+01, -1.6333e+02, -1.3282e+02, -1.1791e+02,
         -4.0494e+01, -6.1126e+01, -4.7090e+01,  2.8663e+01,  1.8522e+01],
        [-5.3000e-03, -4.4000e-03, -3.7000e-03, -1.8000e-03, -6.0000e-04,
          6.0000e-04,  2.2000e-03,  3.7000e-03,  4.1000e-03,  4.5000e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.9994, 11.0021, 11.0001, 11.0013, 11.0020, 11.0027, 11.0003, 11.0009,
         11.0015, 11.0019]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0911e+01,  1.0911e+01,  1.0912e+01,  1.0913e+01,  1.0914e+01,
          1.0913e+01,  1.0912e+01,  1.0912e+01,  1.0912e+01,  1.0913e+01],
        [ 5.7266e+01,  5.8962e+01,  6.0958e+01,  6.7292e+01,  7.4039e+01,
          7.8334e+01,  7.2324e+01,  6.8600e+01,  6.4764e+01,  6.4630e+01],
        [ 5.1548e+01,  5.3031e+01,  5.4616e+01,  5.7151e+01,  6.0529e+01,
          6.4090e+01,  6.5737e+01,  6.6309e+01,  6.6000e+01,  6.5726e+01],
        [ 5.7184e+00,  5.9312e+00,  6.3417e+00,  1.0141e+01,  1.3510e+01,
          1.4244e+01,  6.5872e+00,  2.2908e+00, -1.2365e+00, -1.0964e+00],
        [ 5.7380e+01,  5.4606e+01,  5.6852e+01,  5.6170e+01,  5.5269e+01,
          5.8533e+01,  5.8966e+01,  7.1476e+01,  6.4917e+01,  6.5725e+01],
        [ 1.8110e-01,  6.1700e-02,  1.6470e-01,  1.3420e-01,  9.3900e-02,
          2.4000e-01,  2.8980e-01,  9.5760e-01,  6.1450e-01,  6.8580e-01],
        [ 1.8197e+02,  1.1921e+02, -1.8520e+01, -1.3649e+02, -5.0452e+01,
         -2.9972e+01,  7.0548e+00, -1.3120e+01, -5.7599e+01, -4.1620e+01],
        [ 5.1000e-03,  4.0000e-03,  2.9000e-03,  2.4000e-03,  2.7000e-03,
          3.4000e-03,  3.9000e-03,  3.9000e-03,  4.3000e-03,  4.4000e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.9114, 10.9117, 10.9129, 10.9135, 10.9135, 10.9115, 10.9120, 10.9119,
         10.9128, 10.9128]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0687e+01,  1.0688e+01,  1.0690e+01,  1.0689e+01,  1.0688e+01,
          1.0688e+01,  1.0688e+01,  1.0687e+01,  1.0684e+01,  1.0684e+01],
        [ 9.2257e+01,  9.6176e+01,  1.0714e+02,  1.1108e+02,  1.0649e+02,
          1.0209e+02,  9.7406e+01,  9.0100e+01,  7.2992e+01,  5.8462e+01],
        [ 9.3703e+01,  9.4197e+01,  9.6785e+01,  9.9645e+01,  1.0101e+02,
          1.0123e+02,  1.0046e+02,  9.8391e+01,  9.3311e+01,  8.6341e+01],
        [-1.4451e+00,  1.9790e+00,  1.0351e+01,  1.1440e+01,  5.4746e+00,
          8.5850e-01, -3.0576e+00, -8.2914e+00, -2.0319e+01, -2.7879e+01],
        [ 5.8384e+01,  6.2930e+01,  6.6907e+01,  7.0623e+01,  6.1203e+01,
          5.8482e+01,  5.7102e+01,  6.4256e+01,  5.0315e+01,  4.6762e+01],
        [ 4.3740e-01,  6.2250e-01,  7.8560e-01,  9.3720e-01,  5.5310e-01,
          4.4210e-01,  3.8590e-01,  7.2300e-01,  1.1650e-01, -3.8100e-02],
        [-7.5362e+00,  3.0070e+01,  3.6193e+01, -9.8907e+01, -6.0427e+01,
         -2.0184e+01, -9.7718e+01, -5.2419e+01,  4.5219e+00,  2.2503e+01],
        [ 2.6000e-03,  3.3000e-03,  4.1000e-03,  5.5000e-03,  6.8000e-03,
          7.6000e-03,  7.8000e-03,  7.7000e-03,  8.0000e-03,  6.6000e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.6879, 10.6904, 10.6895, 10.6876, 10.6877, 10.6877, 10.6870, 10.6840,
         10.6839, 10.6852]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0821e+01,  1.0820e+01,  1.0822e+01,  1.0821e+01,  1.0821e+01,
          1.0822e+01,  1.0822e+01,  1.0821e+01,  1.0821e+01,  1.0821e+01],
        [ 9.0436e+01,  8.0776e+01,  7.8812e+01,  7.3616e+01,  6.9304e+01,
          6.8150e+01,  6.5651e+01,  5.9472e+01,  5.3143e+01,  4.7489e+01],
        [ 1.1868e+02,  1.1110e+02,  1.0464e+02,  9.8437e+01,  9.2611e+01,
          8.7719e+01,  8.3305e+01,  7.8538e+01,  7.3459e+01,  6.8265e+01],
        [-2.8247e+01, -3.0325e+01, -2.5831e+01, -2.4822e+01, -2.3307e+01,
         -1.9569e+01, -1.7654e+01, -1.9066e+01, -2.0316e+01, -2.0776e+01],
        [ 4.7399e+01,  4.8362e+01,  5.7429e+01,  4.7429e+01,  4.8699e+01,
          5.2456e+01,  4.9608e+01,  4.1671e+01,  4.1225e+01,  4.6226e+01],
        [ 3.8600e-02,  6.1100e-02,  2.7290e-01,  3.9300e-02,  6.8900e-02,
          1.5670e-01,  9.5100e-02, -1.0040e-01, -1.1000e-02,  2.1260e-01],
        [ 4.3577e+01,  3.4890e+01,  4.2805e+01,  6.5880e+01,  5.7314e+01,
          5.5610e+00, -1.8159e+01,  4.4038e+00, -4.9736e+01, -3.1549e+01],
        [ 2.9000e-03,  1.7000e-03,  7.0000e-04,  4.0000e-04, -1.0000e-04,
         -5.0000e-04, -5.0000e-04, -3.0000e-04, -5.0000e-04, -9.0000e-04]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.8204, 10.8220, 10.8213, 10.8214, 10.8222, 10.8220, 10.8211, 10.8209,
         10.8209, 10.8195]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0925e+01,  1.0923e+01,  1.0923e+01,  1.0923e+01,  1.0921e+01,
          1.0920e+01,  1.0921e+01,  1.0921e+01,  1.0922e+01,  1.0922e+01],
        [ 1.2156e+02,  1.1179e+02,  1.0440e+02,  9.3598e+01,  7.6704e+01,
          5.8778e+01,  4.9013e+01,  3.9050e+01,  3.4444e+01,  3.3032e+01],
        [ 1.1281e+02,  1.1260e+02,  1.1096e+02,  1.0749e+02,  1.0133e+02,
          9.2822e+01,  8.4060e+01,  7.5058e+01,  6.6935e+01,  6.0155e+01],
        [ 8.7553e+00, -8.1350e-01, -6.5633e+00, -1.3893e+01, -2.4629e+01,
         -3.4045e+01, -3.5048e+01, -3.6008e+01, -3.2491e+01, -2.7123e+01],
        [ 7.5956e+01,  6.0959e+01,  6.2990e+01,  5.7582e+01,  5.0212e+01,
          4.3092e+01,  4.5106e+01,  4.1838e+01,  4.4551e+01,  4.9601e+01],
        [ 4.7870e-01, -2.1260e-01,  7.7200e-02, -1.2840e-01, -2.4830e-01,
         -1.9210e-01,  4.5600e-02, -2.8400e-02,  5.9700e-02,  1.7090e-01],
        [-3.0056e+01,  9.0943e+00,  3.1149e+01,  4.5262e+01,  4.4915e+01,
         -1.4457e+00,  7.2789e+01,  1.7740e+02,  1.7135e+02,  9.6036e+01],
        [ 8.9000e-03,  8.9000e-03,  8.2000e-03,  7.5000e-03,  6.4000e-03,
          4.7000e-03,  2.7000e-03,  1.3000e-03, -4.0000e-04, -1.8000e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.9230, 10.9234, 10.9225, 10.9209, 10.9200, 10.9211, 10.9207, 10.9215,
         10.9221, 10.9231]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0940e+01,  1.0940e+01,  1.0939e+01,  1.0940e+01,  1.0940e+01,
          1.0941e+01,  1.0942e+01,  1.0941e+01,  1.0941e+01,  1.0940e+01],
        [-1.9761e+01, -1.9976e+01, -2.0599e+01, -1.8856e+01, -1.6587e+01,
         -1.2480e+01, -1.5290e+00,  3.1700e+00,  3.3302e+00,  2.4613e+00],
        [-2.9173e+01, -2.7334e+01, -2.5987e+01, -2.4561e+01, -2.2966e+01,
         -2.0869e+01, -1.7001e+01, -1.2967e+01, -9.7073e+00, -7.2736e+00],
        [ 9.4120e+00,  7.3574e+00,  5.3881e+00,  5.7050e+00,  6.3786e+00,
          8.3886e+00,  1.5472e+01,  1.6137e+01,  1.3038e+01,  9.7348e+00],
        [ 5.5626e+01,  5.5295e+01,  7.0262e+01,  5.4287e+01,  3.9876e+01,
          4.8923e+01,  6.0062e+01,  6.1215e+01,  5.1343e+01,  5.0056e+01],
        [ 9.9940e-01,  9.9160e-01,  1.3437e+00,  4.9410e-01, -2.5420e-01,
          2.9770e-01,  6.6430e-01,  7.0230e-01,  3.7740e-01,  3.3500e-01],
        [ 7.4135e+01,  5.7571e+01,  8.2642e+01,  2.6431e+01,  4.1993e+01,
          3.7742e+01,  2.8700e+01,  1.0519e+01, -1.6734e+01, -2.7981e+00],
        [ 2.4000e-03,  2.4000e-03,  1.9000e-03,  2.0000e-03,  1.5000e-03,
          1.0000e-03,  7.0000e-04,  1.1000e-03,  1.2000e-03,  1.1000e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.9396, 10.9395, 10.9399, 10.9401, 10.9406, 10.9423, 10.9414, 10.9406,
         10.9404, 10.9414]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0696e+01,  1.0696e+01,  1.0698e+01,  1.0700e+01,  1.0697e+01,
          1.0695e+01,  1.0695e+01,  1.0692e+01,  1.0682e+01,  1.0678e+01],
        [-5.8509e+01, -6.6505e+01, -6.2747e+01, -5.4005e+01, -5.7331e+01,
         -6.3107e+01, -6.8007e+01, -8.2337e+01, -1.2593e+02, -1.7331e+02],
        [-2.2373e+01, -3.1199e+01, -3.7509e+01, -4.0808e+01, -4.4113e+01,
         -4.7912e+01, -5.1931e+01, -5.8012e+01, -7.1597e+01, -9.1939e+01],
        [-3.6136e+01, -3.5306e+01, -2.5238e+01, -1.3197e+01, -1.3218e+01,
         -1.5195e+01, -1.6077e+01, -2.4325e+01, -5.4338e+01, -8.1369e+01],
        [ 4.0090e+01,  3.8507e+01,  4.2416e+01,  4.7873e+01,  4.2159e+01,
          3.5358e+01,  3.5046e+01,  2.4757e+01,  1.8941e+01,  1.8960e+01],
        [ 3.3970e-01,  2.8410e-01,  4.4360e-01,  6.4530e-01,  4.4550e-01,
          1.8740e-01,  1.7560e-01, -2.1490e-01, -2.1650e-01,  7.0000e-04],
        [-3.8983e+01,  7.3573e+01,  8.6632e+01,  2.0860e+02,  1.6320e+02,
         -7.2576e+00, -3.9772e+01,  3.3981e+00, -1.4582e+02, -1.5677e+02],
        [-8.0000e-03, -8.6000e-03, -9.3000e-03, -9.5000e-03, -8.9000e-03,
         -9.7000e-03, -1.0800e-02, -1.1100e-02, -1.2800e-02, -1.7500e-02]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.6955, 10.6982, 10.6996, 10.6965, 10.6954, 10.6951, 10.6919, 10.6824,
         10.6782, 10.6750]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0601e+01,  1.0601e+01,  1.0599e+01,  1.0600e+01,  1.0600e+01,
          1.0600e+01,  1.0602e+01,  1.0602e+01,  1.0601e+01,  1.0600e+01],
        [-8.6160e+00, -7.7400e+00, -1.4008e+01, -1.5828e+01, -1.6438e+01,
         -1.6117e+01, -1.0988e+01, -7.4812e+00, -7.8786e+00, -1.0413e+01],
        [ 3.1935e+00,  1.0068e+00, -1.9961e+00, -4.7625e+00, -7.0975e+00,
         -8.9015e+00, -9.3187e+00, -8.9512e+00, -8.7367e+00, -9.0719e+00],
        [-1.1809e+01, -8.7468e+00, -1.2012e+01, -1.1065e+01, -9.3402e+00,
         -7.2158e+00, -1.6691e+00,  1.4700e+00,  8.5810e-01, -1.3408e+00],
        [ 4.0201e+01,  4.1660e+01,  3.3934e+01,  4.2602e+01,  4.0464e+01,
          4.1881e+01,  4.0844e+01,  4.4695e+01,  4.6706e+01,  4.4714e+01],
        [ 7.7300e-02,  1.4500e-01, -2.1380e-01,  3.3170e-01,  2.4990e-01,
          3.0410e-01,  2.6440e-01,  5.3190e-01,  9.4190e-01,  7.9500e-01],
        [ 2.2077e+01,  1.8990e+01,  8.7876e+01,  4.4393e+01, -1.0616e+01,
         -1.6588e+01, -7.5993e+01, -5.0160e+01, -4.4153e+01, -9.0352e+00],
        [-2.7000e-03, -3.0000e-03, -3.2000e-03, -4.1000e-03, -4.6000e-03,
         -4.7000e-03, -4.4000e-03, -3.9000e-03, -3.0000e-03, -2.3000e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.6013, 10.5991, 10.6000, 10.6002, 10.6004, 10.6019, 10.6017, 10.6007,
         10.6000, 10.5995]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0958e+01,  1.0958e+01,  1.0959e+01,  1.0958e+01,  1.0959e+01,
          1.0959e+01,  1.0959e+01,  1.0960e+01,  1.0960e+01,  1.0961e+01],
        [ 1.7094e+01,  1.9091e+01,  2.2015e+01,  2.2114e+01,  2.3639e+01,
          2.7638e+01,  3.1252e+01,  3.6082e+01,  4.0279e+01,  4.7994e+01],
        [ 1.1888e+01,  1.3329e+01,  1.5066e+01,  1.6476e+01,  1.7908e+01,
          1.9854e+01,  2.2134e+01,  2.4924e+01,  2.7995e+01,  3.1994e+01],
        [ 5.2059e+00,  5.7625e+00,  6.9488e+00,  5.6387e+00,  5.7311e+00,
          7.7835e+00,  9.1185e+00,  1.1159e+01,  1.2285e+01,  1.6000e+01],
        [ 5.5358e+01,  5.9407e+01,  5.9344e+01,  5.8676e+01,  6.2553e+01,
          6.2597e+01,  6.5677e+01,  7.9327e+01,  7.5654e+01,  7.9121e+01],
        [ 6.7500e-01,  8.2960e-01,  8.9540e-01,  8.6780e-01,  1.0281e+00,
          1.0018e+00,  1.1236e+00,  1.4876e+00,  8.7940e-01,  9.9170e-01],
        [-2.0808e+01,  1.6317e+01,  1.2576e+00, -6.1853e+01, -1.7276e+00,
          3.6857e+00,  1.3853e+01, -1.3926e+01, -1.1475e+01,  1.8374e+01],
        [ 1.4000e-03,  1.5000e-03,  1.8000e-03,  2.0000e-03,  2.1000e-03,
          2.5000e-03,  2.7000e-03,  3.0000e-03,  3.5000e-03,  3.9000e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.9583, 10.9586, 10.9582, 10.9586, 10.9592, 10.9594, 10.9599, 10.9601,
         10.9612, 10.9597]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0542e+01,  1.0541e+01,  1.0542e+01,  1.0542e+01,  1.0542e+01,
          1.0540e+01,  1.0539e+01,  1.0538e+01,  1.0538e+01,  1.0539e+01],
        [ 1.6969e+00, -3.0285e+00, -3.4558e+00, -4.3894e+00, -5.7394e+00,
         -1.0698e+01, -1.7563e+01, -2.6186e+01, -3.3160e+01, -3.4687e+01],
        [ 5.0666e+00,  3.4476e+00,  2.0669e+00,  7.7560e-01, -5.2740e-01,
         -2.5615e+00, -5.5618e+00, -9.6867e+00, -1.4381e+01, -1.8443e+01],
        [-3.3697e+00, -6.4761e+00, -5.5227e+00, -5.1651e+00, -5.2120e+00,
         -8.1364e+00, -1.2001e+01, -1.6500e+01, -1.8779e+01, -1.6245e+01],
        [ 4.9604e+01,  4.4801e+01,  4.3238e+01,  4.6990e+01,  3.9748e+01,
          3.6893e+01,  3.7271e+01,  3.5293e+01,  3.4371e+01,  4.5208e+01],
        [ 6.5510e-01,  4.8260e-01,  1.8240e-01,  3.6200e-01, -1.3650e-01,
         -1.4670e-01,  1.7000e-02, -7.1700e-02, -3.8500e-02,  4.3640e-01],
        [ 6.2933e+01,  4.5463e+01,  4.0095e+00, -1.2005e+01, -9.2781e+00,
         -7.5159e+01,  3.1058e+01,  1.5588e+01,  4.8799e+01,  2.1361e+01],
        [ 6.0000e-04,  4.0000e-04, -5.0000e-04, -1.1000e-03, -1.3000e-03,
         -1.7000e-03, -2.4000e-03, -3.0000e-03, -4.2000e-03, -5.3000e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.5410, 10.5421, 10.5419, 10.5417, 10.5404, 10.5393, 10.5382, 10.5380,
         10.5392, 10.5366]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0900e+01,  1.0901e+01,  1.0901e+01,  1.0899e+01,  1.0900e+01,
          1.0901e+01,  1.0901e+01,  1.0903e+01,  1.0903e+01,  1.0906e+01],
        [ 1.4290e+01,  1.7466e+01,  2.1168e+01,  1.6477e+01,  1.6609e+01,
          2.1582e+01,  2.5749e+01,  3.4550e+01,  4.3062e+01,  6.1008e+01],
        [ 8.1363e+00,  1.0002e+01,  1.2235e+01,  1.3084e+01,  1.3789e+01,
          1.5347e+01,  1.7428e+01,  2.0852e+01,  2.5294e+01,  3.2437e+01],
        [ 6.1534e+00,  7.4640e+00,  8.9325e+00,  3.3930e+00,  2.8205e+00,
          6.2347e+00,  8.3215e+00,  1.3698e+01,  1.7768e+01,  2.8571e+01],
        [ 4.8209e+01,  4.8347e+01,  5.5461e+01,  4.7360e+01,  4.8223e+01,
          5.8781e+01,  6.3648e+01,  6.4727e+01,  7.5489e+01,  8.0383e+01],
        [ 5.7500e-02,  6.3500e-02,  3.7410e-01,  2.1200e-02,  5.8800e-02,
          5.1870e-01,  7.3060e-01,  7.7760e-01,  1.6028e+00,  1.1710e+00],
        [ 7.3375e+01,  9.7133e+00, -3.8657e+01,  7.1590e+00, -6.3616e+01,
         -4.0907e+01, -3.2983e+01, -6.1410e+01, -2.9388e+01,  1.1716e+01],
        [ 1.0000e-03,  6.0000e-04,  3.0000e-04,  5.0000e-04,  3.0000e-04,
          2.0000e-04,  9.0000e-04,  1.8000e-03,  2.8000e-03,  4.1000e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.9006, 10.9009, 10.8992, 10.9001, 10.9013, 10.9014, 10.9028, 10.9032,
         10.9059, 10.9061]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0957e+01,  1.0956e+01,  1.0955e+01,  1.0955e+01,  1.0956e+01,
          1.0955e+01,  1.0956e+01,  1.0955e+01,  1.0954e+01,  1.0953e+01],
        [ 3.7462e+01,  1.3766e+01, -9.2064e+00, -2.7100e+01, -3.8517e+01,
         -5.1266e+01, -5.7185e+01, -6.2647e+01, -7.3305e+01, -8.3293e+01],
        [ 9.1588e+01,  7.6024e+01,  5.8978e+01,  4.1762e+01,  2.5706e+01,
          1.0312e+01, -3.1877e+00, -1.5080e+01, -2.6725e+01, -3.8038e+01],
        [-5.4126e+01, -6.2257e+01, -6.8184e+01, -6.8862e+01, -6.4223e+01,
         -6.1578e+01, -5.3998e+01, -4.7567e+01, -4.6580e+01, -4.5255e+01],
        [ 4.4427e+01,  4.4880e+01,  3.8156e+01,  3.4802e+01,  3.2005e+01,
          1.4979e+01,  1.7170e+01,  7.9105e+00,  1.0164e+01,  9.9272e+00],
        [ 1.3200e-02,  2.5600e-02, -1.5810e-01, -7.9100e-02, -6.1200e-02,
         -3.5070e-01,  3.3400e-02, -1.0780e-01,  4.1100e-02,  3.7900e-02],
        [ 9.7862e+01,  3.1389e+02,  3.3535e+02,  4.4826e+02,  1.6809e+02,
          1.6102e+02,  1.6502e+02,  1.4875e+02, -1.0747e+02, -1.2930e+02],
        [ 6.2000e-03,  3.0000e-03, -0.0000e+00, -3.9000e-03, -7.5000e-03,
         -1.0600e-02, -1.3400e-02, -1.5300e-02, -1.7200e-02, -1.8100e-02]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.9564, 10.9554, 10.9554, 10.9559, 10.9550, 10.9558, 10.9555, 10.9539,
         10.9534, 10.9542]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0759e+01,  1.0759e+01,  1.0760e+01,  1.0759e+01,  1.0759e+01,
          1.0759e+01,  1.0759e+01,  1.0759e+01,  1.0759e+01,  1.0760e+01],
        [-2.0327e+01, -2.4583e+01, -2.5879e+01, -2.8149e+01, -2.9607e+01,
         -3.0411e+01, -3.0743e+01, -3.0700e+01, -3.0540e+01, -2.9357e+01],
        [-6.4942e+00, -1.0112e+01, -1.3266e+01, -1.6242e+01, -1.8915e+01,
         -2.1214e+01, -2.3120e+01, -2.4636e+01, -2.5817e+01, -2.6525e+01],
        [-1.3833e+01, -1.4471e+01, -1.2614e+01, -1.1907e+01, -1.0691e+01,
         -9.1969e+00, -7.6228e+00, -6.0641e+00, -4.7234e+00, -2.8320e+00],
        [ 2.8150e+01,  2.7114e+01,  2.8147e+01,  1.9714e+01,  2.2544e+01,
          1.5768e+01,  1.7021e+01,  1.9065e+01,  2.0366e+01,  2.5151e+01],
        [ 7.8600e-02,  3.8300e-02,  7.8500e-02, -2.5010e-01,  1.0200e-01,
         -1.4220e-01,  4.1700e-02,  1.2480e-01,  1.7400e-01,  3.5520e-01],
        [ 3.9710e+00,  2.7721e+01,  2.0414e+01,  7.1081e+00,  3.4300e-02,
          4.6190e+00,  1.9184e+01,  1.5578e+01, -1.5520e+01, -3.3088e+01],
        [-2.6000e-03, -3.2000e-03, -3.6000e-03, -3.9000e-03, -4.3000e-03,
         -4.5000e-03, -4.6000e-03, -4.6000e-03, -4.6000e-03, -4.4000e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.7594, 10.7598, 10.7594, 10.7594, 10.7594, 10.7594, 10.7594, 10.7593,
         10.7595, 10.7587]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0519e+01,  1.0520e+01,  1.0520e+01,  1.0521e+01,  1.0520e+01,
          1.0521e+01,  1.0522e+01,  1.0521e+01,  1.0522e+01,  1.0523e+01],
        [-1.0023e+01, -1.3324e+01, -1.5486e+01, -1.4667e+01, -1.4382e+01,
         -1.3445e+01, -8.7135e+00, -8.0371e+00, -3.2802e+00,  3.3958e+00],
        [-4.3149e+00, -6.1167e+00, -7.9905e+00, -9.3259e+00, -1.0337e+01,
         -1.0959e+01, -1.0510e+01, -1.0015e+01, -8.6682e+00, -6.2554e+00],
        [-5.7076e+00, -7.2075e+00, -7.4950e+00, -5.3416e+00, -4.0448e+00,
         -2.4867e+00,  1.7962e+00,  1.9781e+00,  5.3880e+00,  9.6512e+00],
        [ 4.6932e+01,  4.4029e+01,  4.4731e+01,  5.3115e+01,  4.5211e+01,
          4.9230e+01,  5.0926e+01,  4.6974e+01,  5.2607e+01,  5.4816e+01],
        [ 7.0080e-01,  6.1290e-01,  6.3410e-01,  8.8810e-01,  5.0280e-01,
          6.6260e-01,  6.5360e-01,  4.2080e-01,  7.5260e-01,  8.8270e-01],
        [-5.3786e+00, -1.9431e+01,  2.2829e+01,  2.0343e+01,  3.1034e+01,
          4.8005e+01, -2.0371e+00,  4.7201e+01,  2.7717e+01, -1.2696e+01],
        [-2.0000e-04, -1.0000e-04, -5.0000e-04, -7.0000e-04, -7.0000e-04,
         -1.0000e-03, -1.1000e-03, -1.0000e-03, -1.0000e-03, -7.0000e-04]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.5197, 10.5198, 10.5206, 10.5204, 10.5206, 10.5219, 10.5208, 10.5222,
         10.5232, 10.5231]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0412e+01,  1.0411e+01,  1.0412e+01,  1.0411e+01,  1.0412e+01,
          1.0412e+01,  1.0412e+01,  1.0412e+01,  1.0412e+01,  1.0412e+01],
        [ 8.7922e+00,  8.6844e+00,  9.3561e+00,  9.3577e+00,  1.0017e+01,
          1.1010e+01,  1.2047e+01,  1.2261e+01,  1.2156e+01,  1.2329e+01],
        [ 1.2758e+01,  1.1943e+01,  1.1426e+01,  1.1012e+01,  1.0813e+01,
          1.0852e+01,  1.1092e+01,  1.1325e+01,  1.1491e+01,  1.1659e+01],
        [-3.9655e+00, -3.2587e+00, -2.0696e+00, -1.6543e+00, -7.9640e-01,
          1.5810e-01,  9.5600e-01,  9.3540e-01,  6.6430e-01,  6.7000e-01],
        [ 5.1977e+01,  4.3666e+01,  5.2842e+01,  4.3911e+01,  5.7067e+01,
          5.9417e+01,  6.4741e+01,  6.5362e+01,  6.5119e+01,  6.6515e+01],
        [ 5.6130e-01,  2.9430e-01,  6.2810e-01,  3.1210e-01,  9.2300e-01,
          1.0217e+00,  1.2189e+00,  1.0209e+00,  9.9200e-01,  1.0381e+00],
        [-1.0295e+00, -1.7257e+00, -8.5167e+00, -1.4783e+01, -1.5460e+01,
         -1.5886e+01, -9.7790e+00, -2.8632e+01, -2.5607e+01, -2.2024e+00],
        [-1.4000e-03, -1.2000e-03, -1.1000e-03, -8.0000e-04, -6.0000e-04,
         -2.0000e-04,  3.0000e-04,  8.0000e-04,  1.1000e-03,  1.5000e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.4113, 10.4116, 10.4114, 10.4117, 10.4119, 10.4121, 10.4119, 10.4119,
         10.4120, 10.4125]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0772e+01,  1.0773e+01,  1.0773e+01,  1.0773e+01,  1.0773e+01,
          1.0774e+01,  1.0774e+01,  1.0774e+01,  1.0775e+01,  1.0775e+01],
        [ 1.0359e+01,  1.2185e+01,  1.6318e+01,  1.9267e+01,  2.0433e+01,
          2.4488e+01,  2.8163e+01,  2.9614e+01,  3.5268e+01,  3.9603e+01],
        [ 8.3133e+00,  9.0876e+00,  1.0534e+01,  1.2280e+01,  1.3911e+01,
          1.6026e+01,  1.8454e+01,  2.0686e+01,  2.3602e+01,  2.6802e+01],
        [ 2.0460e+00,  3.0972e+00,  5.7847e+00,  6.9862e+00,  6.5222e+00,
          8.4614e+00,  9.7095e+00,  8.9281e+00,  1.1666e+01,  1.2801e+01],
        [ 4.9338e+01,  5.5186e+01,  6.3191e+01,  6.5285e+01,  6.7130e+01,
          7.0898e+01,  6.9890e+01,  7.0125e+01,  7.3993e+01,  7.2432e+01],
        [ 4.6500e-01,  7.0270e-01,  1.0280e+00,  1.0828e+00,  1.0674e+00,
          1.1289e+00,  9.6360e-01,  9.6760e-01,  1.1333e+00,  9.3670e-01],
        [-3.1257e+01, -2.6362e+01, -7.6752e+00, -2.7350e+01, -1.6097e+01,
          4.6343e+00, -1.5923e+01,  3.0709e+01,  2.5852e+00, -1.3741e+01],
        [ 9.0000e-04,  9.0000e-04,  1.2000e-03,  1.8000e-03,  2.2000e-03,
          2.6000e-03,  3.1000e-03,  3.5000e-03,  3.9000e-03,  4.4000e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.7727, 10.7734, 10.7734, 10.7732, 10.7741, 10.7743, 10.7740, 10.7752,
         10.7753, 10.7752]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0781e+01,  1.0781e+01,  1.0780e+01,  1.0780e+01,  1.0780e+01,
          1.0779e+01,  1.0780e+01,  1.0779e+01,  1.0779e+01,  1.0779e+01],
        [ 2.9791e+01,  3.2562e+01,  2.9387e+01,  2.5630e+01,  2.2395e+01,
          1.8027e+01,  1.6521e+01,  1.3100e+01,  1.0003e+01,  7.0820e+00],
        [ 1.5265e+01,  1.8724e+01,  2.0857e+01,  2.1812e+01,  2.1928e+01,
          2.1148e+01,  2.0223e+01,  1.8798e+01,  1.7039e+01,  1.5048e+01],
        [ 1.4526e+01,  1.3838e+01,  8.5300e+00,  3.8186e+00,  4.6660e-01,
         -3.1211e+00, -3.7014e+00, -5.6981e+00, -7.0361e+00, -7.9656e+00],
        [ 7.9822e+01,  7.7976e+01,  6.3564e+01,  6.0383e+01,  6.6531e+01,
          5.5364e+01,  5.8846e+01,  5.4380e+01,  5.0299e+01,  3.7120e+01],
        [ 9.3110e-01,  9.0070e-01,  6.6360e-01,  6.1120e-01,  7.1240e-01,
          3.6740e-01,  3.8650e-01,  1.5610e-01, -1.3770e-01, -3.9090e-01],
        [-6.0249e+01, -1.2009e+01, -1.6041e+01, -2.0857e+01,  4.2670e-01,
          5.7483e+01,  4.8896e+01,  6.3965e+01,  6.4516e+01,  4.1169e+01],
        [ 4.1000e-03,  4.9000e-03,  5.5000e-03,  5.3000e-03,  4.9000e-03,
          4.6000e-03,  3.8000e-03,  3.1000e-03,  2.2000e-03,  1.3000e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.7814, 10.7801, 10.7798, 10.7798, 10.7794, 10.7800, 10.7794, 10.7794,
         10.7793, 10.7793]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0752e+01,  1.0753e+01,  1.0752e+01,  1.0751e+01,  1.0752e+01,
          1.0751e+01,  1.0751e+01,  1.0751e+01,  1.0751e+01,  1.0752e+01],
        [-3.4374e+01, -3.1455e+01, -3.2341e+01, -3.5633e+01, -3.2845e+01,
         -3.4427e+01, -3.7328e+01, -3.7516e+01, -3.8689e+01, -3.5684e+01],
        [-2.7184e+01, -2.8038e+01, -2.8899e+01, -3.0246e+01, -3.0765e+01,
         -3.1498e+01, -3.2664e+01, -3.3634e+01, -3.4645e+01, -3.4853e+01],
        [-7.1896e+00, -3.4165e+00, -3.4428e+00, -5.3874e+00, -2.0792e+00,
         -2.9290e+00, -4.6643e+00, -3.8816e+00, -4.0436e+00, -8.3110e-01],
        [ 3.4294e+01,  4.0957e+01,  3.5670e+01,  2.7694e+01,  3.9419e+01,
          3.7505e+01,  3.6943e+01,  4.4941e+01,  4.5888e+01,  5.3894e+01],
        [ 5.2160e-01,  6.8240e-01,  5.5480e-01,  3.6240e-01,  6.6410e-01,
          7.1490e-01,  7.6110e-01,  1.1408e+00,  1.0294e+00,  1.2410e+00],
        [ 1.7020e+01, -2.9071e+00, -1.5181e+01, -6.9213e+01, -8.3520e+01,
         -1.0030e+02, -8.9126e+01, -3.6650e+01, -8.6843e+00,  3.0070e+01],
        [-7.1000e-03, -6.9000e-03, -6.2000e-03, -5.8000e-03, -5.7000e-03,
         -4.8000e-03, -4.3000e-03, -3.8000e-03, -3.1000e-03, -2.8000e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.7529, 10.7520, 10.7512, 10.7525, 10.7514, 10.7508, 10.7513, 10.7509,
         10.7518, 10.7525]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0585e+01,  1.0585e+01,  1.0584e+01,  1.0582e+01,  1.0579e+01,
          1.0581e+01,  1.0581e+01,  1.0581e+01,  1.0581e+01,  1.0579e+01],
        [-2.0511e+01, -1.9189e+01, -1.8635e+01, -2.4587e+01, -3.9683e+01,
         -4.5827e+01, -4.7538e+01, -4.9446e+01, -5.0991e+01, -5.6471e+01],
        [-2.9060e+01, -2.7086e+01, -2.5396e+01, -2.5234e+01, -2.8124e+01,
         -3.1665e+01, -3.4839e+01, -3.7761e+01, -4.0407e+01, -4.3620e+01],
        [ 8.5493e+00,  7.8969e+00,  6.7606e+00,  6.4660e-01, -1.1559e+01,
         -1.4163e+01, -1.2699e+01, -1.1686e+01, -1.0584e+01, -1.2851e+01],
        [ 4.9236e+01,  4.5129e+01,  5.2773e+01,  4.7206e+01,  3.1102e+01,
          3.8301e+01,  3.7581e+01,  4.0141e+01,  4.0709e+01,  3.8238e+01],
        [ 8.6490e-01,  6.8650e-01,  1.0185e+00,  7.6260e-01, -1.3140e-01,
          3.3220e-01,  2.9900e-01,  4.1710e-01,  4.4330e-01,  3.2930e-01],
        [-1.0133e+01, -9.3924e+00,  3.1596e+01, -2.1209e+01, -3.1639e+01,
         -4.1344e+01, -6.0488e+01,  5.3126e+01,  5.5583e+01,  1.0406e+02],
        [-2.1000e-03, -1.2000e-03, -1.0000e-03, -5.0000e-04, -9.0000e-04,
         -2.6000e-03, -3.5000e-03, -4.1000e-03, -4.4000e-03, -5.2000e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.5846, 10.5844, 10.5823, 10.5789, 10.5806, 10.5814, 10.5810, 10.5808,
         10.5793, 10.5808]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0949e+01,  1.0950e+01,  1.0949e+01,  1.0948e+01,  1.0949e+01,
          1.0948e+01,  1.0948e+01,  1.0949e+01,  1.0947e+01,  1.0947e+01],
        [ 1.2652e+01,  2.0889e+01,  2.6238e+01,  2.5615e+01,  2.6690e+01,
          2.5141e+01,  2.2513e+01,  2.5387e+01,  1.8556e+01,  1.2374e+01],
        [-1.2570e+01, -5.8781e+00,  5.4510e-01,  5.5590e+00,  9.7851e+00,
          1.2856e+01,  1.4788e+01,  1.6908e+01,  1.7237e+01,  1.6264e+01],
        [ 2.5222e+01,  2.6767e+01,  2.5693e+01,  2.0056e+01,  1.6904e+01,
          1.2285e+01,  7.7253e+00,  8.4796e+00,  1.3185e+00, -3.8908e+00],
        [ 5.5425e+01,  5.7877e+01,  5.8472e+01,  6.0714e+01,  6.5669e+01,
          6.3229e+01,  6.6809e+01,  6.8632e+01,  6.0633e+01,  5.4749e+01],
        [ 6.1450e-01,  6.8240e-01,  6.9890e-01,  7.6100e-01,  8.9810e-01,
          8.1210e-01,  9.2200e-01,  9.7800e-01,  7.3230e-01,  3.7610e-01],
        [-5.5144e+01, -6.2599e+01, -1.1372e+02, -8.7181e+01, -1.2636e+02,
         -5.9505e+01,  2.1327e+01,  5.0142e+01,  6.3824e+01,  1.1419e+02],
        [ 2.1000e-03,  2.8000e-03,  3.6000e-03,  4.3000e-03,  4.8000e-03,
          5.3000e-03,  5.6000e-03,  5.6000e-03,  5.6000e-03,  4.9000e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.9496, 10.9494, 10.9484, 10.9488, 10.9484, 10.9481, 10.9493, 10.9473,
         10.9472, 10.9493]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0734e+01,  1.0734e+01,  1.0734e+01,  1.0734e+01,  1.0734e+01,
          1.0735e+01,  1.0735e+01,  1.0734e+01,  1.0737e+01,  1.0737e+01],
        [-2.6828e+01, -2.9083e+01, -3.0675e+01, -3.0413e+01, -3.0037e+01,
         -2.8830e+01, -2.6903e+01, -2.6305e+01, -1.7442e+01, -1.0300e+01],
        [-1.1138e+01, -1.4727e+01, -1.7916e+01, -2.0416e+01, -2.2340e+01,
         -2.3638e+01, -2.4291e+01, -2.4694e+01, -2.3244e+01, -2.0655e+01],
        [-1.5690e+01, -1.4356e+01, -1.2759e+01, -9.9970e+00, -7.6969e+00,
         -5.1925e+00, -2.6124e+00, -1.6113e+00,  5.8013e+00,  1.0355e+01],
        [ 3.2465e+01,  3.5673e+01,  3.4174e+01,  2.8699e+01,  2.9475e+01,
          4.4057e+01,  4.0551e+01,  3.8876e+01,  5.7693e+01,  5.2974e+01],
        [ 2.7760e-01,  4.9120e-01,  4.1200e-01,  1.2250e-01,  1.6360e-01,
          1.4731e+00,  8.0160e-01,  7.0690e-01,  1.7714e+00,  8.4930e-01],
        [ 2.5978e+01, -6.1027e+01, -3.1680e+01, -2.8794e+01, -1.7059e+01,
          2.4503e+01,  2.0782e+01, -5.8099e+01, -3.4357e+01, -3.5294e+01],
        [-5.6000e-03, -5.8000e-03, -5.8000e-03, -5.4000e-03, -5.1000e-03,
         -4.9000e-03, -4.2000e-03, -3.8000e-03, -3.4000e-03, -2.0000e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.7342, 10.7342, 10.7345, 10.7344, 10.7346, 10.7348, 10.7344, 10.7366,
         10.7366, 10.7359]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0718e+01,  1.0718e+01,  1.0718e+01,  1.0718e+01,  1.0718e+01,
          1.0718e+01,  1.0718e+01,  1.0717e+01,  1.0717e+01,  1.0717e+01],
        [-2.6904e+01, -2.4851e+01, -2.2611e+01, -1.9492e+01, -1.6622e+01,
         -1.6137e+01, -1.4184e+01, -1.5092e+01, -1.6874e+01, -1.6392e+01],
        [-4.1842e+01, -3.8444e+01, -3.5278e+01, -3.2120e+01, -2.9021e+01,
         -2.6444e+01, -2.3992e+01, -2.2212e+01, -2.1144e+01, -2.0194e+01],
        [ 1.4939e+01,  1.3593e+01,  1.2666e+01,  1.2629e+01,  1.2399e+01,
          1.0307e+01,  9.8082e+00,  7.1200e+00,  4.2707e+00,  3.8015e+00],
        [ 6.2235e+01,  5.2778e+01,  5.7519e+01,  5.8902e+01,  6.8682e+01,
          6.0859e+01,  6.0053e+01,  5.5120e+01,  4.5157e+01,  4.5548e+01],
        [ 1.2788e+00,  7.8120e-01,  8.9090e-01,  9.2290e-01,  1.1492e+00,
          8.4180e-01,  7.7220e-01,  6.4190e-01,  7.3000e-02,  8.8400e-02],
        [-4.1707e+01, -4.0283e+01, -1.7688e+01, -3.1476e+01, -3.4719e+00,
          1.4574e+01,  4.9243e+00,  1.0023e+01,  3.9371e+00,  1.4790e+01],
        [-5.0000e-04,  2.0000e-04,  6.0000e-04,  1.0000e-03,  1.3000e-03,
          1.7000e-03,  1.7000e-03,  1.6000e-03,  1.4000e-03,  1.0000e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.7176, 10.7177, 10.7180, 10.7181, 10.7176, 10.7179, 10.7172, 10.7169,
         10.7173, 10.7177]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0630e+01,  1.0630e+01,  1.0631e+01,  1.0632e+01,  1.0634e+01,
          1.0634e+01,  1.0638e+01,  1.0633e+01,  1.0632e+01,  1.0636e+01],
        [-6.6651e+01, -5.6572e+01, -4.3357e+01, -2.9973e+01, -1.2081e+01,
          1.9771e+00,  2.5842e+01,  2.8170e+01,  2.6252e+01,  3.7819e+01],
        [-5.0884e+01, -5.2022e+01, -5.0289e+01, -4.6226e+01, -3.9397e+01,
         -3.1122e+01, -1.9729e+01, -1.0149e+01, -2.8691e+00,  5.2686e+00],
        [-1.5766e+01, -4.5501e+00,  6.9319e+00,  1.6253e+01,  2.7316e+01,
          3.3099e+01,  4.5571e+01,  3.8320e+01,  2.9121e+01,  3.2551e+01],
        [ 4.1604e+01,  4.3055e+01,  5.1894e+01,  4.6755e+01,  5.2648e+01,
          5.3956e+01,  6.5812e+01,  5.9362e+01,  5.9652e+01,  6.7852e+01],
        [ 4.8230e-01,  6.5980e-01,  1.2095e+00,  8.3030e-01,  1.0249e+00,
          1.0421e+00,  1.3665e+00,  8.5410e-01,  8.6060e-01,  1.0462e+00],
        [ 4.6029e+01,  2.8064e+01, -9.9116e+01, -1.5920e+02, -2.0058e+02,
         -2.8181e+02, -3.0338e+02, -6.1292e+01, -2.4554e+02, -1.1790e+02],
        [-1.8500e-02, -1.7400e-02, -1.5800e-02, -1.2600e-02, -9.4000e-03,
         -5.2000e-03, -1.3000e-03,  4.5000e-03,  7.9000e-03,  9.5000e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.6296, 10.6310, 10.6318, 10.6339, 10.6339, 10.6378, 10.6329, 10.6319,
         10.6359, 10.6333]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0895e+01,  1.0894e+01,  1.0896e+01,  1.0896e+01,  1.0896e+01,
          1.0897e+01,  1.0896e+01,  1.0897e+01,  1.0896e+01,  1.0895e+01],
        [ 1.3668e+01,  6.7009e+00,  6.5318e+00,  9.0962e+00,  9.8130e+00,
          1.3691e+01,  1.3378e+01,  1.5483e+01,  1.3125e+01,  9.4327e+00],
        [ 2.1162e+01,  1.8269e+01,  1.5922e+01,  1.4557e+01,  1.3608e+01,
          1.3625e+01,  1.3575e+01,  1.3957e+01,  1.3791e+01,  1.2919e+01],
        [-7.4939e+00, -1.1568e+01, -9.3900e+00, -5.4605e+00, -3.7949e+00,
          6.6800e-02, -1.9700e-01,  1.5261e+00, -6.6560e-01, -3.4863e+00],
        [ 4.3737e+01,  4.2029e+01,  5.0935e+01,  6.0101e+01,  5.4080e+01,
          5.8350e+01,  5.0050e+01,  5.1070e+01,  4.3175e+01,  3.9296e+01],
        [ 1.5160e-01,  1.1080e-01,  3.2330e-01,  5.4210e-01,  3.5030e-01,
          4.3800e-01,  2.1530e-01,  2.4260e-01,  3.0800e-02, -7.3300e-02],
        [-1.5295e+00,  5.1000e-01,  3.9056e+01,  5.3254e+01,  7.6364e+01,
          8.9254e+01,  2.7942e+01,  1.6176e+01, -3.0422e+01, -1.0616e+01],
        [ 2.7000e-03,  2.2000e-03,  1.4000e-03,  1.0000e-03,  1.0000e-03,
          6.0000e-04,  6.0000e-04,  2.0000e-04,  2.0000e-04, -1.0000e-04]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.8944, 10.8957, 10.8963, 10.8960, 10.8968, 10.8961, 10.8967, 10.8958,
         10.8954, 10.8965]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0700e+01,  1.0701e+01,  1.0702e+01,  1.0701e+01,  1.0701e+01,
          1.0703e+01,  1.0703e+01,  1.0705e+01,  1.0704e+01,  1.0700e+01],
        [ 1.6658e+01,  9.1491e+00,  7.1913e+00,  1.7193e+00, -2.1942e+00,
          2.5632e+00,  5.9669e+00,  1.7279e+01,  2.1309e+01,  9.4485e+00],
        [ 4.6847e+00,  5.5776e+00,  5.9003e+00,  5.0641e+00,  3.6125e+00,
          3.4026e+00,  3.9155e+00,  6.5882e+00,  9.5323e+00,  9.5156e+00],
        [ 1.1973e+01,  3.5715e+00,  1.2910e+00, -3.3448e+00, -5.8067e+00,
         -8.3940e-01,  2.0515e+00,  1.0691e+01,  1.1776e+01, -6.7100e-02],
        [ 5.7089e+01,  5.8886e+01,  5.5933e+01,  5.7464e+01,  5.0620e+01,
          5.0119e+01,  4.7539e+01,  5.6771e+01,  5.1620e+01,  3.8664e+01],
        [ 5.6880e-01,  6.1830e-01,  3.5680e-01,  9.1300e-02, -3.1670e-01,
         -2.2700e-02, -1.1420e-01,  3.6680e-01,  1.6210e-01, -3.5260e-01],
        [-1.6108e+01,  8.3508e+01,  1.0797e+02,  9.8042e+01,  1.0137e+02,
          1.2584e+02,  1.8030e+02,  7.8145e+01,  6.5462e+01,  2.1744e+01],
        [ 1.0000e-02,  9.2000e-03,  8.1000e-03,  6.6000e-03,  5.0000e-03,
          3.3000e-03,  2.1000e-03,  8.0000e-04,  5.0000e-04,  3.0000e-04]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.7005, 10.7017, 10.7006, 10.7007, 10.7029, 10.7028, 10.7053, 10.7040,
         10.6998, 10.6987]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.1015e+01,  1.1015e+01,  1.1016e+01,  1.1017e+01,  1.1018e+01,
          1.1018e+01,  1.1017e+01,  1.1017e+01,  1.1017e+01,  1.1018e+01],
        [ 4.7380e+00,  9.0704e+00,  1.6943e+01,  2.5007e+01,  3.7472e+01,
          4.7571e+01,  5.0224e+01,  5.2855e+01,  5.4671e+01,  5.7589e+01],
        [-1.0006e+01, -6.1904e+00, -1.5638e+00,  3.7505e+00,  1.0495e+01,
          1.7910e+01,  2.4373e+01,  3.0069e+01,  3.4989e+01,  3.9509e+01],
        [ 1.4744e+01,  1.5261e+01,  1.8507e+01,  2.1257e+01,  2.6977e+01,
          2.9662e+01,  2.5851e+01,  2.2785e+01,  1.9681e+01,  1.8080e+01],
        [ 6.8093e+01,  7.0715e+01,  7.3296e+01,  7.3276e+01,  7.1822e+01,
          7.9849e+01,  7.3653e+01,  7.0586e+01,  7.1153e+01,  7.5309e+01],
        [ 1.0550e+00,  1.0596e+00,  1.0610e+00,  9.9950e-01,  9.5090e-01,
          1.2183e+00,  8.3060e-01,  6.8240e-01,  7.0180e-01,  8.4430e-01],
        [ 5.9264e+01,  1.2416e+01, -1.5921e+01,  3.8247e+01,  2.8143e+01,
          1.4948e+00, -4.8159e+01, -6.0588e+01, -5.9481e+01, -1.0033e+00],
        [ 2.0000e-03,  2.7000e-03,  3.0000e-03,  3.7000e-03,  4.4000e-03,
          5.0000e-03,  5.7000e-03,  6.0000e-03,  6.2000e-03,  6.4000e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[11.0151, 11.0161, 11.0165, 11.0178, 11.0180, 11.0170, 11.0173, 11.0173,
         11.0178, 11.0179]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0941e+01,  1.0940e+01,  1.0940e+01,  1.0940e+01,  1.0939e+01,
          1.0939e+01,  1.0939e+01,  1.0939e+01,  1.0939e+01,  1.0938e+01],
        [-2.8785e+01, -4.0445e+01, -4.9026e+01, -5.6940e+01, -6.3793e+01,
         -6.9697e+01, -7.2779e+01, -7.5810e+01, -7.7244e+01, -8.2790e+01],
        [ 5.3153e+00, -3.8367e+00, -1.2875e+01, -2.1688e+01, -3.0109e+01,
         -3.8026e+01, -4.4977e+01, -5.1144e+01, -5.6364e+01, -6.1649e+01],
        [-3.4100e+01, -3.6608e+01, -3.6151e+01, -3.5252e+01, -3.3685e+01,
         -3.1671e+01, -2.7802e+01, -2.4667e+01, -2.0881e+01, -2.1141e+01],
        [ 3.5045e+01,  2.4608e+01,  2.3089e+01,  2.3606e+01,  2.6647e+01,
          1.9555e+01,  7.3848e+00,  7.5558e+00,  9.1028e+00,  9.6521e+00],
        [-1.1200e-02, -3.3030e-01, -3.9300e-02,  1.5900e-02,  1.3720e-01,
         -1.3620e-01, -4.1290e-01,  4.4000e-03,  4.4100e-02,  6.0700e-02],
        [-3.2025e+01,  2.9236e+01,  1.2264e+02,  1.0690e+02,  5.7511e+01,
         -1.7116e+01,  7.9871e+00,  3.3859e+01, -2.6488e+01, -7.3847e+01],
        [-4.1000e-03, -5.0000e-03, -6.2000e-03, -7.3000e-03, -8.6000e-03,
         -9.3000e-03, -1.0000e-02, -1.0300e-02, -1.0700e-02, -1.0700e-02]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.9399, 10.9399, 10.9395, 10.9392, 10.9389, 10.9391, 10.9388, 10.9388,
         10.9376, 10.9384]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0642e+01,  1.0643e+01,  1.0644e+01,  1.0644e+01,  1.0644e+01,
          1.0644e+01,  1.0644e+01,  1.0644e+01,  1.0643e+01,  1.0641e+01],
        [ 2.8680e+01,  3.4844e+01,  4.0724e+01,  4.5920e+01,  4.9724e+01,
          5.0801e+01,  5.1093e+01,  5.0739e+01,  4.6659e+01,  3.7320e+01],
        [ 1.6575e+01,  2.0229e+01,  2.4328e+01,  2.8646e+01,  3.2862e+01,
          3.6450e+01,  3.9378e+01,  4.1650e+01,  4.2652e+01,  4.1586e+01],
        [ 1.2105e+01,  1.4616e+01,  1.6396e+01,  1.7274e+01,  1.6862e+01,
          1.4352e+01,  1.1714e+01,  9.0883e+00,  4.0066e+00, -4.2656e+00],
        [ 6.5753e+01,  7.0334e+01,  7.7002e+01,  8.0169e+01,  7.7995e+01,
          7.8665e+01,  7.4591e+01,  7.4185e+01,  7.0241e+01,  5.4335e+01],
        [ 8.4280e-01,  9.8620e-01,  1.1949e+00,  1.0830e+00,  9.3930e-01,
          9.5800e-01,  8.0420e-01,  7.8990e-01,  5.5200e-01, -2.5090e-01],
        [-2.0825e+01, -4.4733e+01,  5.2676e+00, -6.7140e-01, -3.5400e+01,
         -1.7583e+01,  5.2028e+01,  4.2135e+01,  1.7354e+01, -1.1186e+01],
        [ 4.5000e-03,  5.1000e-03,  5.9000e-03,  6.9000e-03,  7.6000e-03,
          8.1000e-03,  8.4000e-03,  8.3000e-03,  7.8000e-03,  7.1000e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.6433, 10.6437, 10.6440, 10.6441, 10.6437, 10.6437, 10.6437, 10.6427,
         10.6410, 10.6403]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0924e+01,  1.0923e+01,  1.0924e+01,  1.0925e+01,  1.0924e+01,
          1.0925e+01,  1.0924e+01,  1.0925e+01,  1.0922e+01,  1.0923e+01],
        [-6.2821e+00, -7.1483e+00, -4.4572e+00,  6.3120e-01,  3.5193e+00,
          7.7036e+00,  8.6525e+00,  1.2980e+01,  3.5970e+00, -1.4607e+00],
        [-1.2350e+01, -1.1309e+01, -9.9391e+00, -7.8250e+00, -5.5561e+00,
         -2.9042e+00, -5.9290e-01,  2.1218e+00,  2.4168e+00,  1.6413e+00],
        [ 6.0677e+00,  4.1612e+00,  5.4818e+00,  8.4562e+00,  9.0755e+00,
          1.0608e+01,  9.2454e+00,  1.0859e+01,  1.1802e+00, -3.1021e+00],
        [ 4.6523e+01,  5.1017e+01,  4.8109e+01,  4.9962e+01,  5.2867e+01,
          5.1158e+01,  5.1949e+01,  5.9587e+01,  4.9760e+01,  5.4686e+01],
        [ 1.6060e-01,  4.8050e-01,  2.8580e-01,  4.0980e-01,  6.0430e-01,
          4.8990e-01,  5.4280e-01,  1.0540e+00,  2.4780e-01,  6.2490e-01],
        [ 2.1927e+01,  6.8872e+01,  3.2190e+01, -1.2250e+01, -6.3610e+01,
         -1.0839e+02, -6.9900e+00,  7.5895e+00, -3.2780e+01, -2.6483e+01],
        [ 4.0000e-04,  2.0000e-04,  0.0000e+00, -2.0000e-04, -0.0000e+00,
          3.0000e-04,  7.0000e-04,  1.2000e-03,  1.7000e-03,  1.2000e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.9231, 10.9239, 10.9245, 10.9243, 10.9247, 10.9242, 10.9251, 10.9222,
         10.9227, 10.9225]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0668e+01,  1.0668e+01,  1.0669e+01,  1.0668e+01,  1.0667e+01,
          1.0668e+01,  1.0668e+01,  1.0667e+01,  1.0669e+01,  1.0668e+01],
        [-2.9096e+01, -3.0282e+01, -2.9271e+01, -3.2047e+01, -3.7060e+01,
         -3.6178e+01, -3.6334e+01, -3.6298e+01, -3.2075e+01, -2.9722e+01],
        [ 1.6947e+01,  7.5011e+00,  1.4680e-01, -6.2920e+00, -1.2446e+01,
         -1.7192e+01, -2.1020e+01, -2.4076e+01, -2.5676e+01, -2.6485e+01],
        [-4.6043e+01, -3.7783e+01, -2.9417e+01, -2.5755e+01, -2.4614e+01,
         -1.8986e+01, -1.5313e+01, -1.2222e+01, -6.3988e+00, -3.2375e+00],
        [ 3.8664e+01,  3.6908e+01,  3.1267e+01,  2.1559e+01,  2.5563e+01,
          3.1533e+01,  3.4006e+01,  3.4646e+01,  4.4231e+01,  4.4894e+01],
        [ 2.1490e-01,  1.7650e-01,  5.3300e-02, -1.5940e-01,  1.0500e-01,
          2.7240e-01,  3.4000e-01,  4.8490e-01,  1.0070e+00,  1.0293e+00],
        [ 1.1907e+02,  1.1457e+02,  5.4508e+01,  4.6194e+01, -3.4459e+01,
         -4.9095e+01, -6.5171e+01, -1.7444e+02, -2.3958e+02, -1.5045e+02],
        [-9.2000e-03, -1.1200e-02, -1.2100e-02, -1.2900e-02, -1.3900e-02,
         -1.4200e-02, -1.3400e-02, -1.2300e-02, -1.1100e-02, -8.6000e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.6682, 10.6687, 10.6675, 10.6666, 10.6679, 10.6675, 10.6674, 10.6685,
         10.6682, 10.6670]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0956e+01,  1.0955e+01,  1.0956e+01,  1.0956e+01,  1.0957e+01,
          1.0958e+01,  1.0958e+01,  1.0958e+01,  1.0959e+01,  1.0958e+01],
        [ 3.5583e+01,  2.8718e+01,  2.9826e+01,  2.8894e+01,  3.0080e+01,
          3.5780e+01,  3.9504e+01,  4.4179e+01,  5.1037e+01,  5.2928e+01],
        [ 3.0100e+01,  2.9824e+01,  2.9824e+01,  2.9638e+01,  2.9727e+01,
          3.0937e+01,  3.2651e+01,  3.4956e+01,  3.8173e+01,  4.1124e+01],
        [ 5.4829e+00, -1.1060e+00,  2.3000e-03, -7.4430e-01,  3.5370e-01,
          4.8431e+00,  6.8530e+00,  9.2229e+00,  1.2865e+01,  1.1805e+01],
        [ 7.1802e+01,  5.1298e+01,  5.6930e+01,  5.3310e+01,  5.6585e+01,
          5.8984e+01,  5.8960e+01,  5.8298e+01,  6.3851e+01,  6.4149e+01],
        [ 8.9920e-01, -2.2170e-01,  2.5090e-01,  8.9600e-02,  2.3550e-01,
          3.7490e-01,  3.7370e-01,  3.4140e-01,  6.1220e-01,  6.2670e-01],
        [ 6.1871e+00,  3.5985e+01,  3.2163e+01,  6.3274e+01,  3.7571e+01,
         -7.0686e+00,  4.8558e+01,  2.3665e+01,  3.2052e+01, -3.4496e+01],
        [ 3.8000e-03,  3.9000e-03,  3.1000e-03,  2.8000e-03,  2.4000e-03,
          2.1000e-03,  2.2000e-03,  2.4000e-03,  2.5000e-03,  3.0000e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.9550, 10.9565, 10.9562, 10.9566, 10.9578, 10.9577, 10.9582, 10.9590,
         10.9583, 10.9585]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0368e+01,  1.0366e+01,  1.0366e+01,  1.0367e+01,  1.0366e+01,
          1.0365e+01,  1.0364e+01,  1.0364e+01,  1.0363e+01,  1.0363e+01],
        [ 4.4594e+00, -2.5472e+00, -8.9243e+00, -1.0899e+01, -1.5607e+01,
         -2.1432e+01, -2.7228e+01, -3.1669e+01, -3.6954e+01, -4.0624e+01],
        [ 9.4654e+00,  7.0629e+00,  3.8654e+00,  9.1250e-01, -2.3915e+00,
         -6.1995e+00, -1.0405e+01, -1.4658e+01, -1.9117e+01, -2.3419e+01],
        [-5.0059e+00, -9.6101e+00, -1.2790e+01, -1.1812e+01, -1.3216e+01,
         -1.5232e+01, -1.6823e+01, -1.7011e+01, -1.7837e+01, -1.7206e+01],
        [ 4.0203e+01,  3.6405e+01,  3.2844e+01,  4.0821e+01,  3.3596e+01,
          3.4738e+01,  3.2621e+01,  2.6462e+01,  2.6121e+01,  2.6237e+01],
        [ 3.1860e-01,  2.0900e-01,  1.0610e-01,  3.4840e-01,  1.3730e-01,
          1.7270e-01,  1.0710e-01, -2.1400e-01, -9.7000e-03,  3.3000e-03],
        [ 1.4920e+01, -2.3615e+01, -1.7157e+01,  1.8871e+01, -8.3380e-01,
          3.5681e+00,  1.9021e+01,  7.2333e+01,  5.2424e+01,  4.0298e+01],
        [-2.0000e-04, -7.0000e-04, -1.6000e-03, -2.4000e-03, -2.7000e-03,
         -3.7000e-03, -4.6000e-03, -5.6000e-03, -6.6000e-03, -7.9000e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.3664, 10.3660, 10.3672, 10.3659, 10.3650, 10.3644, 10.3643, 10.3634,
         10.3634, 10.3606]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0806e+01,  1.0806e+01,  1.0806e+01,  1.0805e+01,  1.0807e+01,
          1.0806e+01,  1.0808e+01,  1.0805e+01,  1.0808e+01,  1.0808e+01],
        [ 1.6559e+01,  1.8780e+01,  1.8227e+01,  1.5157e+01,  1.8395e+01,
          2.0393e+01,  2.7456e+01,  2.2040e+01,  2.7759e+01,  3.1426e+01],
        [ 1.7215e+01,  1.7528e+01,  1.7668e+01,  1.7166e+01,  1.7412e+01,
          1.8008e+01,  1.9898e+01,  2.0326e+01,  2.1813e+01,  2.3735e+01],
        [-6.5640e-01,  1.2516e+00,  5.5900e-01, -2.0088e+00,  9.8290e-01,
          2.3855e+00,  7.5588e+00,  1.7135e+00,  5.9466e+00,  7.6903e+00],
        [ 4.1870e+01,  4.3737e+01,  5.0847e+01,  5.5459e+01,  7.0467e+01,
          6.5960e+01,  6.7137e+01,  4.8229e+01,  5.8391e+01,  6.0955e+01],
        [ 9.3200e-02,  1.4000e-01,  4.0790e-01,  6.9070e-01,  1.6672e+00,
          8.6050e-01,  8.9690e-01,  3.1180e-01,  6.2630e-01,  7.0560e-01],
        [-1.0189e+02, -6.1931e+01, -8.1224e+00, -2.6052e+00,  3.7438e+00,
         -2.8811e+01, -1.4632e+01, -4.4069e+01, -9.8662e+00, -3.4248e+00],
        [-1.3000e-03, -1.2000e-03, -8.0000e-04, -5.0000e-04, -3.0000e-04,
          6.0000e-04,  1.2000e-03,  2.2000e-03,  2.0000e-03,  2.7000e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.8063, 10.8057, 10.8051, 10.8066, 10.8065, 10.8080, 10.8053, 10.8078,
         10.8077, 10.8085]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0910e+01,  1.0910e+01,  1.0909e+01,  1.0909e+01,  1.0908e+01,
          1.0910e+01,  1.0909e+01,  1.0910e+01,  1.0910e+01,  1.0910e+01],
        [-2.2369e+01, -2.2736e+01, -2.6310e+01, -3.0148e+01, -3.4302e+01,
         -2.9333e+01, -2.9830e+01, -2.4858e+01, -2.0212e+01, -1.6008e+01],
        [-1.8735e+01, -1.9535e+01, -2.0890e+01, -2.2742e+01, -2.5054e+01,
         -2.5910e+01, -2.6694e+01, -2.6326e+01, -2.5104e+01, -2.3285e+01],
        [-3.6341e+00, -3.2010e+00, -5.4197e+00, -7.4060e+00, -9.2481e+00,
         -3.4233e+00, -3.1367e+00,  1.4687e+00,  4.8917e+00,  7.2763e+00],
        [ 4.9007e+01,  4.6625e+01,  3.9871e+01,  4.0684e+01,  3.2655e+01,
          4.3621e+01,  4.2338e+01,  5.2327e+01,  5.1269e+01,  4.4634e+01],
        [ 5.3350e-01,  2.7830e-01, -2.1700e-02,  3.5400e-02, -3.1370e-01,
          3.6290e-01,  4.1510e-01,  8.4340e-01,  7.9800e-01,  5.1360e-01],
        [ 5.1133e+01,  5.4831e+01,  1.7949e+01, -3.6503e+01, -1.1886e+01,
          7.0229e+01,  8.4285e+01,  2.6714e+00, -7.5238e+00, -6.9063e+01],
        [-4.0000e-04, -6.0000e-04, -1.0000e-03, -1.7000e-03, -2.2000e-03,
         -2.8000e-03, -2.7000e-03, -3.1000e-03, -2.8000e-03, -2.3000e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.9098, 10.9089, 10.9086, 10.9083, 10.9101, 10.9090, 10.9102, 10.9103,
         10.9103, 10.9101]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0987e+01,  1.0987e+01,  1.0987e+01,  1.0985e+01,  1.0985e+01,
          1.0985e+01,  1.0984e+01,  1.0984e+01,  1.0984e+01,  1.0984e+01],
        [ 2.9784e+01,  3.2075e+01,  3.1342e+01,  2.0817e+01,  1.1859e+01,
          4.1414e+00, -2.6905e+00, -1.0232e+01, -1.6311e+01, -2.1445e+01],
        [ 2.4392e+01,  2.5929e+01,  2.7011e+01,  2.5772e+01,  2.2990e+01,
          1.9220e+01,  1.4838e+01,  9.8239e+00,  4.5969e+00, -6.1160e-01],
        [ 5.3920e+00,  6.1468e+00,  4.3306e+00, -4.9557e+00, -1.1130e+01,
         -1.5079e+01, -1.7528e+01, -2.0056e+01, -2.0908e+01, -2.0834e+01],
        [ 5.8972e+01,  6.0780e+01,  5.3695e+01,  4.2386e+01,  4.5212e+01,
          4.5290e+01,  3.9423e+01,  3.8080e+01,  3.5068e+01,  3.5918e+01],
        [ 4.9570e-01,  5.5730e-01,  3.1590e-01, -7.9800e-02,  1.2170e-01,
          1.2510e-01, -1.2770e-01, -5.5700e-02, -1.1830e-01,  3.1300e-02],
        [-2.7011e+01, -4.2532e+01, -1.0311e+01, -2.7002e+01, -6.2557e+00,
         -1.8942e+01,  4.9348e+01,  4.0038e+00, -1.2124e+00,  8.7547e+01],
        [ 8.0000e-04,  1.0000e-03,  1.4000e-03,  1.5000e-03,  8.0000e-04,
          3.0000e-04, -2.0000e-04, -8.0000e-04, -1.6000e-03, -2.3000e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.9873, 10.9869, 10.9848, 10.9847, 10.9846, 10.9844, 10.9840, 10.9839,
         10.9838, 10.9845]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0683e+01,  1.0683e+01,  1.0684e+01,  1.0684e+01,  1.0685e+01,
          1.0683e+01,  1.0684e+01,  1.0683e+01,  1.0684e+01,  1.0683e+01],
        [ 1.4499e+01,  1.1590e+01,  1.1210e+01,  1.2594e+01,  1.5481e+01,
          1.1873e+01,  1.0148e+01,  6.8390e+00,  5.3479e+00,  3.2852e+00],
        [ 2.1146e+01,  1.9235e+01,  1.7630e+01,  1.6623e+01,  1.6395e+01,
          1.5490e+01,  1.4422e+01,  1.2905e+01,  1.1394e+01,  9.7720e+00],
        [-6.6468e+00, -7.6444e+00, -6.4195e+00, -4.0286e+00, -9.1320e-01,
         -3.6174e+00, -4.2742e+00, -6.0661e+00, -6.0457e+00, -6.4868e+00],
        [ 3.3691e+01,  3.9024e+01,  4.7256e+01,  4.9396e+01,  5.7027e+01,
          4.3712e+01,  4.8747e+01,  4.1823e+01,  4.6112e+01,  4.3149e+01],
        [-9.3030e-01,  1.0600e-01,  2.6950e-01,  3.1200e-01,  5.0460e-01,
          2.2730e-01,  4.0160e-01,  2.1690e-01,  3.4270e-01,  2.6090e-01],
        [ 1.9735e+01,  1.8554e+01,  3.2000e+00,  2.1102e+01,  6.9138e+00,
          1.0868e+01,  2.5794e+01,  1.4082e+01,  5.5333e+00, -1.7105e+01],
        [ 1.9000e-03,  9.0000e-04,  3.0000e-04,  0.0000e+00, -1.0000e-04,
          1.0000e-04, -3.0000e-04, -5.0000e-04, -9.0000e-04, -1.0000e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.6834, 10.6840, 10.6845, 10.6850, 10.6834, 10.6838, 10.6832, 10.6836,
         10.6833, 10.6832]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
  0%|          | 0/350 [00:03<?, ?it/s]
Traceback (most recent call last):
  File "C:\Users\dadou\Documents\Github\Advanced-Programming\Strategies\Transformer_strategy.py", line 417, in <module>
    trainer.train()
  File "C:\Users\dadou\Documents\Github\Advanced-Programming\utils\trainer.py", line 69, in train
    preds = self.model(signal.to(self.device))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\dadou\anaconda3\envs\Advanced-Programming\Lib\site-packages\torch\nn\modules\module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\dadou\anaconda3\envs\Advanced-Programming\Lib\site-packages\torch\nn\modules\module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\dadou\Documents\Github\Advanced-Programming\Strategies\Transformer_strategy.py", line 188, in forward
    x = self.transformer_encoder(x)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\dadou\anaconda3\envs\Advanced-Programming\Lib\site-packages\torch\nn\modules\module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\dadou\anaconda3\envs\Advanced-Programming\Lib\site-packages\torch\nn\modules\module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\dadou\anaconda3\envs\Advanced-Programming\Lib\site-packages\torch\nn\modules\transformer.py", line 391, in forward
    output = mod(output, src_mask=mask, is_causal=is_causal, src_key_padding_mask=src_key_padding_mask_for_layers)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\dadou\anaconda3\envs\Advanced-Programming\Lib\site-packages\torch\nn\modules\module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\dadou\anaconda3\envs\Advanced-Programming\Lib\site-packages\torch\nn\modules\module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\dadou\anaconda3\envs\Advanced-Programming\Lib\site-packages\torch\nn\modules\transformer.py", line 714, in forward
    x = self.norm1(x + self._sa_block(x, src_mask, src_key_padding_mask, is_causal=is_causal))
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\dadou\anaconda3\envs\Advanced-Programming\Lib\site-packages\torch\nn\modules\transformer.py", line 722, in _sa_block
    x = self.self_attn(x, x, x,
        ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\dadou\anaconda3\envs\Advanced-Programming\Lib\site-packages\torch\nn\modules\module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\dadou\anaconda3\envs\Advanced-Programming\Lib\site-packages\torch\nn\modules\module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\dadou\anaconda3\envs\Advanced-Programming\Lib\site-packages\torch\nn\modules\activation.py", line 1241, in forward
    attn_output, attn_output_weights = F.multi_head_attention_forward(
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\dadou\anaconda3\envs\Advanced-Programming\Lib\site-packages\torch\nn\functional.py", line 5479, in multi_head_attention_forward
    attn_output = linear(attn_output, out_proj_weight, out_proj_bias)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
signal tensor([[ 1.0796e+01,  1.0796e+01,  1.0797e+01,  1.0797e+01,  1.0797e+01,
          1.0795e+01,  1.0795e+01,  1.0795e+01,  1.0795e+01,  1.0795e+01],
        [-1.8143e+01, -2.1438e+01, -2.2312e+01, -2.0396e+01, -1.8663e+01,
         -2.5629e+01, -3.2639e+01, -3.6479e+01, -3.9371e+01, -4.0190e+01],
        [-1.2587e+01, -1.4357e+01, -1.5948e+01, -1.6838e+01, -1.7203e+01,
         -1.8888e+01, -2.1638e+01, -2.4606e+01, -2.7559e+01, -3.0086e+01],
        [-5.5558e+00, -7.0813e+00, -6.3637e+00, -3.5587e+00, -1.4605e+00,
         -6.7411e+00, -1.1001e+01, -1.1873e+01, -1.1812e+01, -1.0104e+01],
        [ 2.8044e+01,  2.9659e+01,  3.5502e+01,  4.0726e+01,  2.9898e+01,
          2.1502e+01,  2.2226e+01,  2.6970e+01,  2.7980e+01,  2.9685e+01],
        [-3.4700e-01,  8.3500e-02,  3.8550e-01,  6.5560e-01,  9.5800e-02,
         -3.6850e-01,  2.9800e-02,  2.2500e-01,  2.6660e-01,  3.3680e-01],
        [ 4.7264e+01,  2.6136e+01, -3.7760e-01, -1.8300e+00, -1.4016e+01,
         -6.6267e+00,  6.8710e+00,  9.0614e+00,  1.6865e+01,  1.3769e+01],
        [-1.2000e-03, -1.7000e-03, -2.2000e-03, -2.4000e-03, -2.3000e-03,
         -2.3000e-03, -2.9000e-03, -3.6000e-03, -4.0000e-03, -4.3000e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.7964, 10.7968, 10.7974, 10.7974, 10.7952, 10.7947, 10.7951, 10.7950,
         10.7952, 10.7951]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0420e+01,  1.0420e+01,  1.0421e+01,  1.0420e+01,  1.0419e+01,
          1.0422e+01,  1.0421e+01,  1.0421e+01,  1.0422e+01,  1.0419e+01],
        [-6.2394e+01, -5.9875e+01, -5.3204e+01, -5.2519e+01, -5.1631e+01,
         -4.4637e+01, -3.9155e+01, -3.6521e+01, -3.1209e+01, -3.3162e+01],
        [-5.9000e+01, -5.9175e+01, -5.7981e+01, -5.6888e+01, -5.5837e+01,
         -5.3597e+01, -5.0708e+01, -4.7871e+01, -4.4539e+01, -4.2263e+01],
        [-3.3939e+00, -7.0060e-01,  4.7762e+00,  4.3698e+00,  4.2061e+00,
          8.9601e+00,  1.1554e+01,  1.1350e+01,  1.3329e+01,  9.1014e+00],
        [ 3.5956e+01,  4.0815e+01,  4.6766e+01,  4.4898e+01,  4.6020e+01,
          5.8688e+01,  6.7455e+01,  5.6175e+01,  4.2343e+01,  4.1740e+01],
        [ 6.2680e-01,  8.1510e-01,  1.0456e+00,  9.3080e-01,  9.7240e-01,
          1.4417e+00,  1.2253e+00,  6.6290e-01,  2.0280e-01,  1.8360e-01],
        [-3.1233e+01, -1.9513e+02, -3.1357e+02, -1.2395e+02,  8.2375e+01,
          1.6311e+01, -7.3935e+01, -6.3970e+01, -9.6430e-01,  3.4910e+00],
        [-1.2900e-02, -1.2600e-02, -1.1300e-02, -8.4000e-03, -6.0000e-03,
         -4.8000e-03, -3.0000e-03, -3.0000e-04,  1.1000e-03,  1.6000e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.4200, 10.4215, 10.4195, 10.4194, 10.4216, 10.4214, 10.4206, 10.4217,
         10.4192, 10.4190]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.1039e+01,  1.1038e+01,  1.1039e+01,  1.1038e+01,  1.1038e+01,
          1.1037e+01,  1.1037e+01,  1.1037e+01,  1.1037e+01,  1.1039e+01],
        [-9.5214e+01, -1.0262e+02, -1.0587e+02, -1.1305e+02, -1.1501e+02,
         -1.2130e+02, -1.2505e+02, -1.2656e+02, -1.2377e+02, -1.1317e+02],
        [-7.2554e+01, -7.8568e+01, -8.4029e+01, -8.9832e+01, -9.4868e+01,
         -1.0015e+02, -1.0513e+02, -1.0942e+02, -1.1229e+02, -1.1247e+02],
        [-2.2660e+01, -2.4053e+01, -2.1845e+01, -2.3213e+01, -2.0142e+01,
         -2.1144e+01, -1.9921e+01, -1.7145e+01, -1.1478e+01, -7.0320e-01],
        [ 2.4326e+01,  2.1552e+01,  2.4538e+01,  1.2418e+01,  1.2683e+01,
          1.3927e+01,  1.5209e+01,  1.6701e+01,  2.3512e+01,  3.9900e+01],
        [-1.3590e-01, -8.9800e-02,  8.8700e-02, -2.7130e-01,  6.2000e-03,
          3.5400e-02,  6.7300e-02,  1.1110e-01,  2.8780e-01,  7.1300e-01],
        [ 2.3008e+02,  1.0379e+02,  6.1169e+01,  1.9002e+01, -1.9571e+01,
         -9.0849e+01, -9.3573e+01, -3.1549e+01, -2.1627e+01, -4.3789e+01],
        [-4.2000e-03, -6.1000e-03, -8.1000e-03, -9.1000e-03, -1.0500e-02,
         -1.1300e-02, -1.1800e-02, -1.1700e-02, -1.1400e-02, -1.0800e-02]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[11.0384, 11.0387, 11.0375, 11.0380, 11.0368, 11.0367, 11.0367, 11.0373,
         11.0387, 11.0384]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0424e+01,  1.0425e+01,  1.0424e+01,  1.0424e+01,  1.0425e+01,
          1.0424e+01,  1.0423e+01,  1.0424e+01,  1.0423e+01,  1.0423e+01],
        [-8.7179e+00, -5.2627e+00, -3.5350e+00, -1.9306e+00,  1.0372e+00,
          1.9090e-01, -2.9761e+00, -2.8875e+00, -4.7403e+00, -6.6325e+00],
        [-1.0645e+01, -9.5688e+00, -8.3620e+00, -7.0758e+00, -5.4532e+00,
         -4.3244e+00, -4.0547e+00, -3.8213e+00, -4.0051e+00, -4.5306e+00],
        [ 1.9275e+00,  4.3062e+00,  4.8270e+00,  5.1452e+00,  6.4904e+00,
          4.5152e+00,  1.0786e+00,  9.3380e-01, -7.3520e-01, -2.1020e+00],
        [ 5.2345e+01,  5.6281e+01,  5.3686e+01,  6.1978e+01,  6.2892e+01,
          6.2535e+01,  5.6813e+01,  5.0581e+01,  4.6304e+01,  3.5857e+01],
        [ 1.0456e+00,  1.1033e+00,  9.3820e-01,  1.1356e+00,  1.0199e+00,
          9.9240e-01,  8.7050e-01,  5.3970e-01,  2.3580e-01, -3.9440e-01],
        [-5.7420e+01, -9.0844e+01, -8.0584e+01,  3.6500e+00,  1.1374e+01,
          6.7979e+01,  4.1820e+01,  1.9718e+01, -1.8573e+01, -1.8432e+01],
        [-2.0000e-03, -9.0000e-04,  3.0000e-04,  1.3000e-03,  2.3000e-03,
          2.8000e-03,  3.0000e-03,  2.4000e-03,  2.0000e-03,  1.3000e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.4247, 10.4243, 10.4244, 10.4251, 10.4239, 10.4229, 10.4239, 10.4232,
         10.4230, 10.4223]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0772e+01,  1.0771e+01,  1.0772e+01,  1.0773e+01,  1.0773e+01,
          1.0772e+01,  1.0773e+01,  1.0773e+01,  1.0773e+01,  1.0773e+01],
        [-2.6942e+01, -2.3425e+01, -1.8425e+01, -1.1210e+01, -4.4544e+00,
         -8.7790e-01,  5.6556e+00,  7.4752e+00,  1.0712e+01,  1.4719e+01],
        [-3.7298e+01, -3.4523e+01, -3.1303e+01, -2.7285e+01, -2.2719e+01,
         -1.8351e+01, -1.3549e+01, -9.3444e+00, -5.3331e+00, -1.3226e+00],
        [ 1.0355e+01,  1.1098e+01,  1.2878e+01,  1.6075e+01,  1.8264e+01,
          1.7473e+01,  1.9205e+01,  1.6820e+01,  1.6045e+01,  1.6042e+01],
        [ 5.1318e+01,  5.4770e+01,  5.8841e+01,  7.2802e+01,  7.2438e+01,
          6.1778e+01,  6.3696e+01,  6.4666e+01,  7.1330e+01,  7.1581e+01],
        [ 1.1010e+00,  1.0970e+00,  1.1043e+00,  1.3238e+00,  9.9360e-01,
          7.5480e-01,  7.9750e-01,  8.1910e-01,  9.6650e-01,  9.7200e-01],
        [-1.3432e+02, -3.1580e+01,  7.8950e-01, -3.9951e+01, -6.6936e+01,
         -5.0945e+01,  9.0862e+00, -3.0771e+01, -1.6657e+00,  2.6878e+01],
        [-4.0000e-03, -2.2000e-03, -8.0000e-04,  4.0000e-04,  1.9000e-03,
          3.3000e-03,  4.0000e-03,  4.7000e-03,  4.9000e-03,  5.3000e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.7713, 10.7718, 10.7726, 10.7729, 10.7724, 10.7734, 10.7725, 10.7730,
         10.7734, 10.7739]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0945e+01,  1.0944e+01,  1.0945e+01,  1.0946e+01,  1.0944e+01,
          1.0942e+01,  1.0942e+01,  1.0942e+01,  1.0942e+01,  1.0941e+01],
        [-4.4250e+01, -4.9039e+01, -4.9650e+01, -4.3318e+01, -4.6284e+01,
         -5.8285e+01, -6.6148e+01, -7.4408e+01, -7.7801e+01, -8.2548e+01],
        [-1.9702e+01, -2.5570e+01, -3.0386e+01, -3.2972e+01, -3.5635e+01,
         -4.0165e+01, -4.5361e+01, -5.1171e+01, -5.6497e+01, -6.1707e+01],
        [-2.4547e+01, -2.3469e+01, -1.9265e+01, -1.0346e+01, -1.0649e+01,
         -1.8120e+01, -2.0787e+01, -2.3237e+01, -2.1304e+01, -2.0841e+01],
        [ 2.9566e+01,  3.0749e+01,  3.5988e+01,  4.7374e+01,  4.5482e+01,
          3.4898e+01,  4.2020e+01,  3.2259e+01,  3.3395e+01,  3.2005e+01],
        [ 5.3400e-02,  1.0140e-01,  3.7460e-01,  9.5780e-01,  9.0580e-01,
          3.7870e-01,  7.3340e-01,  2.4730e-01,  3.0380e-01,  2.3460e-01],
        [-1.2914e+02, -4.8483e+01, -1.7108e+02, -6.2824e+01, -3.7891e+01,
         -2.6966e+01,  5.8934e+01, -6.4615e+01, -5.4658e+01, -1.3457e+00],
        [-9.5000e-03, -9.6000e-03, -9.3000e-03, -8.7000e-03, -6.9000e-03,
         -6.1000e-03, -6.4000e-03, -6.1000e-03, -6.6000e-03, -6.5000e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.9442, 10.9447, 10.9461, 10.9442, 10.9420, 10.9422, 10.9415, 10.9420,
         10.9414, 10.9402]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0738e+01,  1.0736e+01,  1.0736e+01,  1.0737e+01,  1.0736e+01,
          1.0737e+01,  1.0738e+01,  1.0737e+01,  1.0737e+01,  1.0737e+01],
        [-3.1903e+01, -2.9703e+01, -2.7875e+01, -2.3713e+01, -2.4321e+01,
         -1.8296e+01, -1.2788e+01, -9.6774e+00, -8.3643e+00, -8.7241e+00],
        [-3.9721e+01, -3.7717e+01, -3.5749e+01, -3.3342e+01, -3.1538e+01,
         -2.8889e+01, -2.5669e+01, -2.2471e+01, -1.9649e+01, -1.7464e+01],
        [ 7.8187e+00,  8.0147e+00,  7.8737e+00,  9.6289e+00,  7.2168e+00,
          1.0593e+01,  1.2881e+01,  1.2793e+01,  1.1285e+01,  8.7403e+00],
        [ 5.4308e+01,  4.8796e+01,  5.4189e+01,  5.3640e+01,  4.6495e+01,
          5.1609e+01,  5.3968e+01,  5.4185e+01,  4.9572e+01,  5.5173e+01],
        [ 1.1475e+00,  8.2760e-01,  9.9630e-01,  9.7910e-01,  6.4130e-01,
          8.7610e-01,  9.8440e-01,  9.9430e-01,  7.8260e-01,  1.0397e+00],
        [ 5.1552e+00,  1.3189e+01, -7.4852e+00, -2.0569e+01,  3.5428e+01,
         -4.9546e+01, -8.7416e+01,  1.6993e+01, -5.5853e+01, -2.0939e+01],
        [-3.2000e-03, -1.8000e-03, -1.4000e-03, -8.0000e-04, -2.0000e-04,
         -1.0000e-04,  2.0000e-04,  1.0000e-03,  1.7000e-03,  1.5000e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.7363, 10.7363, 10.7369, 10.7358, 10.7375, 10.7376, 10.7373, 10.7369,
         10.7365, 10.7365]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0981e+01,  1.0981e+01,  1.0980e+01,  1.0980e+01,  1.0982e+01,
          1.0981e+01,  1.0981e+01,  1.0981e+01,  1.0981e+01,  1.0981e+01],
        [-4.3007e+01, -4.0942e+01, -4.4708e+01, -4.2857e+01, -3.5002e+01,
         -2.9610e+01, -2.5832e+01, -2.1961e+01, -1.8660e+01, -1.7816e+01],
        [-4.7548e+01, -4.6227e+01, -4.5923e+01, -4.5310e+01, -4.3249e+01,
         -4.0521e+01, -3.7583e+01, -3.4458e+01, -3.1299e+01, -2.8602e+01],
        [ 4.5406e+00,  5.2846e+00,  1.2150e+00,  2.4526e+00,  8.2461e+00,
          1.0911e+01,  1.1751e+01,  1.2498e+01,  1.2639e+01,  1.0786e+01],
        [ 3.7958e+01,  4.2479e+01,  3.5068e+01,  5.2317e+01,  5.6273e+01,
          5.5085e+01,  5.0230e+01,  5.9937e+01,  5.5846e+01,  5.4984e+01],
        [ 4.7920e-01,  6.5960e-01,  3.6380e-01,  1.0523e+00,  1.1640e+00,
          9.5770e-01,  7.6780e-01,  1.1408e+00,  8.3550e-01,  8.0080e-01],
        [-4.1489e+01, -3.6571e+01,  6.9286e+00, -5.0297e+01, -8.3557e+00,
         -2.9560e+01,  7.2471e+00,  9.4300e+00, -7.0362e+00,  4.7181e+00],
        [-2.4000e-03, -2.0000e-03, -1.6000e-03, -1.8000e-03, -1.5000e-03,
         -7.0000e-04, -3.0000e-04,  0.0000e+00,  4.0000e-04,  6.0000e-04]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.9808, 10.9795, 10.9805, 10.9817, 10.9815, 10.9813, 10.9814, 10.9814,
         10.9810, 10.9805]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0771e+01,  1.0772e+01,  1.0772e+01,  1.0771e+01,  1.0771e+01,
          1.0772e+01,  1.0774e+01,  1.0775e+01,  1.0777e+01,  1.0777e+01],
        [ 2.6901e+01,  4.0057e+01,  4.8968e+01,  5.2453e+01,  5.4886e+01,
          6.0351e+01,  7.0883e+01,  8.3323e+01,  9.9406e+01,  1.1204e+02],
        [-1.1291e+01, -1.0214e+00,  8.9765e+00,  1.7672e+01,  2.5115e+01,
          3.2162e+01,  3.9906e+01,  4.8590e+01,  5.8753e+01,  6.9410e+01],
        [ 3.8192e+01,  4.1078e+01,  3.9992e+01,  3.4782e+01,  2.9771e+01,
          2.8189e+01,  3.0977e+01,  3.4734e+01,  4.0653e+01,  4.2628e+01],
        [ 6.7822e+01,  7.0262e+01,  7.0032e+01,  7.1285e+01,  7.0553e+01,
          7.0858e+01,  6.8202e+01,  7.5711e+01,  7.5434e+01,  8.0159e+01],
        [ 1.0334e+00,  1.0560e+00,  9.9500e-01,  1.0222e+00,  9.8180e-01,
          9.8680e-01,  7.8190e-01,  1.3131e+00,  9.8500e-01,  1.2397e+00],
        [-1.2226e+02, -9.6130e+01,  4.9834e+01, -2.8767e+01,  5.7784e+01,
         -9.8620e-01,  1.1005e+02,  2.8454e+01,  3.3309e+01, -4.8898e+01],
        [ 7.2000e-03,  9.2000e-03,  1.1000e-02,  1.2200e-02,  1.2600e-02,
          1.2900e-02,  1.3000e-02,  1.3200e-02,  1.3500e-02,  1.4300e-02]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.7719, 10.7716, 10.7709, 10.7709, 10.7720, 10.7739, 10.7752, 10.7771,
         10.7774, 10.7789]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0799e+01,  1.0799e+01,  1.0799e+01,  1.0798e+01,  1.0798e+01,
          1.0798e+01,  1.0799e+01,  1.0799e+01,  1.0799e+01,  1.0799e+01],
        [-1.9800e+00, -4.3499e+00, -6.2313e+00, -1.1908e+01, -1.3671e+01,
         -1.5995e+01, -1.4077e+01, -1.2414e+01, -1.1800e+01, -8.4426e+00],
        [ 1.1761e+00,  7.0900e-02, -1.1896e+00, -3.3334e+00, -5.4009e+00,
         -7.5197e+00, -8.8312e+00, -9.5477e+00, -9.9982e+00, -9.6870e+00],
        [-3.1561e+00, -4.4208e+00, -5.0417e+00, -8.5751e+00, -8.2703e+00,
         -8.4752e+00, -5.2458e+00, -2.8662e+00, -1.8017e+00,  1.2445e+00],
        [ 4.0163e+01,  4.0152e+01,  4.3933e+01,  2.8684e+01,  3.4905e+01,
          3.3020e+01,  5.0381e+01,  5.1784e+01,  4.0881e+01,  4.6664e+01],
        [ 1.1270e-01,  1.1220e-01,  2.8140e-01, -4.0090e-01,  1.9870e-01,
          2.0310e-01,  1.4229e+00,  1.0647e+00,  5.2800e-01,  7.7830e-01],
        [-6.1570e-01,  4.7570e-01, -3.5294e+01, -3.7186e+01,  6.5643e+00,
          2.2807e+01,  1.8136e+01,  1.9626e+01,  2.0111e+01,  1.3847e+01],
        [-1.3000e-03, -1.3000e-03, -1.3000e-03, -1.3000e-03, -1.6000e-03,
         -1.6000e-03, -2.0000e-03, -1.8000e-03, -1.6000e-03, -1.6000e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.7987, 10.7987, 10.7976, 10.7983, 10.7980, 10.7989, 10.7989, 10.7987,
         10.7994, 10.7994]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.1028e+01,  1.1029e+01,  1.1029e+01,  1.1029e+01,  1.1029e+01,
          1.1030e+01,  1.1031e+01,  1.1031e+01,  1.1030e+01,  1.1029e+01],
        [-1.9640e+01, -1.8262e+01, -1.6604e+01, -1.4800e+01, -1.1614e+01,
         -7.3864e+00,  2.0469e+00,  8.1907e+00,  9.9856e+00,  4.6107e+00],
        [-8.1092e+00, -1.0140e+01, -1.1433e+01, -1.2106e+01, -1.2008e+01,
         -1.1083e+01, -8.4573e+00, -5.1277e+00, -2.1051e+00, -7.6190e-01],
        [-1.1530e+01, -8.1220e+00, -5.1714e+00, -2.6939e+00,  3.9390e-01,
          3.6969e+00,  1.0504e+01,  1.3318e+01,  1.2091e+01,  5.3726e+00],
        [ 3.2161e+01,  3.9895e+01,  2.8246e+01,  3.3800e+01,  4.7311e+01,
          5.7444e+01,  7.2904e+01,  6.7702e+01,  6.2790e+01,  5.2369e+01],
        [ 2.0060e-01,  3.8670e-01,  1.0640e-01,  2.6290e-01,  8.0350e-01,
          1.4314e+00,  1.4598e+00,  8.9400e-01,  7.9390e-01,  5.8160e-01],
        [-1.4191e+01, -3.9258e+01, -5.8709e+01, -4.0455e+01, -4.8664e+01,
         -6.4468e+01, -6.1860e+01, -7.3123e+01, -4.5237e+01, -2.9279e+01],
        [-4.7000e-03, -4.8000e-03, -4.4000e-03, -4.1000e-03, -3.5000e-03,
         -2.7000e-03, -1.8000e-03, -4.0000e-04,  7.0000e-04,  1.5000e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[11.0289, 11.0289, 11.0290, 11.0293, 11.0297, 11.0309, 11.0306, 11.0300,
         11.0287, 11.0285]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0582e+01,  1.0585e+01,  1.0584e+01,  1.0585e+01,  1.0585e+01,
          1.0585e+01,  1.0586e+01,  1.0585e+01,  1.0584e+01,  1.0583e+01],
        [ 1.4415e+01,  2.1180e+01,  2.4819e+01,  2.7879e+01,  3.1240e+01,
          3.2718e+01,  3.6276e+01,  3.7694e+01,  3.3005e+01,  2.7845e+01],
        [ 1.8246e+01,  1.8833e+01,  2.0030e+01,  2.1600e+01,  2.3528e+01,
          2.5366e+01,  2.7548e+01,  2.9577e+01,  3.0263e+01,  2.9779e+01],
        [-3.8314e+00,  2.3470e+00,  4.7887e+00,  6.2793e+00,  7.7124e+00,
          7.3517e+00,  8.7279e+00,  8.1173e+00,  2.7426e+00, -1.9342e+00],
        [ 4.4940e+01,  5.5607e+01,  5.2121e+01,  5.0319e+01,  5.6573e+01,
          5.8555e+01,  5.9823e+01,  6.7335e+01,  6.0029e+01,  6.3770e+01],
        [ 2.3000e-02,  5.1040e-01,  3.5110e-01,  2.6880e-01,  5.5450e-01,
          6.4510e-01,  7.0300e-01,  1.1172e+00,  6.8090e-01,  8.4430e-01],
        [ 6.0641e+01,  3.0538e+01,  4.0077e+01, -2.9655e+01, -6.2539e+01,
         -1.0375e+02, -4.2943e+01, -5.1901e+01, -3.1392e+01, -2.7969e+01],
        [ 8.0000e-04, -2.0000e-04, -1.0000e-04,  0.0000e+00,  1.0000e-04,
          9.0000e-04,  1.7000e-03,  2.9000e-03,  3.8000e-03,  4.0000e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.5849, 10.5844, 10.5846, 10.5850, 10.5847, 10.5856, 10.5853, 10.5836,
         10.5833, 10.5841]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0632e+01,  1.0631e+01,  1.0633e+01,  1.0632e+01,  1.0634e+01,
          1.0633e+01,  1.0633e+01,  1.0635e+01,  1.0634e+01,  1.0632e+01],
        [-3.0889e+01, -3.4797e+01, -3.2362e+01, -3.1153e+01, -2.4918e+01,
         -2.1704e+01, -2.0430e+01, -1.2073e+01, -6.6000e+00, -9.5411e+00],
        [-1.2035e+01, -1.6587e+01, -1.9742e+01, -2.2024e+01, -2.2603e+01,
         -2.2423e+01, -2.2024e+01, -2.0034e+01, -1.7347e+01, -1.5786e+01],
        [-1.8854e+01, -1.8210e+01, -1.2620e+01, -9.1284e+00, -2.3148e+00,
          7.1960e-01,  1.5949e+00,  7.9615e+00,  1.0747e+01,  6.2449e+00],
        [ 2.3374e+01,  2.1245e+01,  3.4034e+01,  3.1730e+01,  4.5119e+01,
          4.3554e+01,  4.4175e+01,  5.4207e+01,  5.1720e+01,  4.4981e+01],
        [ 1.9340e-01,  1.8480e-01,  6.7960e-01,  8.6880e-01,  1.6311e+00,
          9.4540e-01,  9.6710e-01,  1.3172e+00,  9.3410e-01,  7.5550e-01],
        [ 7.1667e+00,  5.5652e+00, -7.5586e+00,  5.0700e+00,  2.0265e+01,
          4.0548e+00, -6.9183e+01, -5.8876e+01, -6.7997e+01, -7.9863e+01],
        [-6.4000e-03, -6.6000e-03, -6.8000e-03, -6.5000e-03, -6.1000e-03,
         -5.2000e-03, -4.5000e-03, -3.9000e-03, -2.2000e-03, -9.0000e-04]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.6310, 10.6326, 10.6323, 10.6338, 10.6332, 10.6327, 10.6349, 10.6345,
         10.6323, 10.6333]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0454e+01,  1.0454e+01,  1.0454e+01,  1.0453e+01,  1.0455e+01,
          1.0457e+01,  1.0458e+01,  1.0464e+01,  1.0463e+01,  1.0464e+01],
        [-1.2126e+01, -9.8081e+00, -8.3156e+00, -9.8747e+00, -7.0867e+00,
          1.1213e+00,  1.0078e+01,  3.3787e+01,  5.0914e+01,  6.4638e+01],
        [-1.5069e+01, -1.4017e+01, -1.2877e+01, -1.2276e+01, -1.1238e+01,
         -8.7665e+00, -4.9975e+00,  2.7594e+00,  1.2390e+01,  2.2840e+01],
        [ 2.9431e+00,  4.2090e+00,  4.5612e+00,  2.4017e+00,  4.1517e+00,
          9.8878e+00,  1.5076e+01,  3.1028e+01,  3.8523e+01,  4.1798e+01],
        [ 5.3004e+01,  4.2330e+01,  4.6716e+01,  4.4647e+01,  5.0004e+01,
          6.8433e+01,  7.1440e+01,  8.2677e+01,  8.4484e+01,  8.7142e+01],
        [ 9.9380e-01,  1.3720e-01,  4.8910e-01,  3.2310e-01,  7.5300e-01,
          2.2317e+00,  1.1081e+00,  1.3646e+00,  1.0430e+00,  1.0606e+00],
        [ 2.3109e+01, -4.4014e+00, -3.6624e+00,  9.2900e+00, -1.3754e+01,
         -2.7173e+01, -3.2468e+01, -4.5058e+01, -3.3501e+01, -4.0443e+01],
        [-1.2000e-03, -9.0000e-04, -1.0000e-03, -9.0000e-04, -1.0000e-03,
         -7.0000e-04,  6.0000e-04,  2.1000e-03,  5.6000e-03,  8.7000e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.4544, 10.4542, 10.4532, 10.4546, 10.4567, 10.4577, 10.4637, 10.4633,
         10.4636, 10.4654]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0778e+01,  1.0777e+01,  1.0777e+01,  1.0777e+01,  1.0779e+01,
          1.0779e+01,  1.0779e+01,  1.0781e+01,  1.0780e+01,  1.0781e+01],
        [ 4.1948e+01,  3.9917e+01,  3.8210e+01,  3.5218e+01,  4.2683e+01,
          4.5187e+01,  4.6837e+01,  5.8024e+01,  6.2541e+01,  6.6082e+01],
        [ 4.1800e+01,  4.1423e+01,  4.0781e+01,  3.9668e+01,  4.0271e+01,
          4.1254e+01,  4.2371e+01,  4.5501e+01,  4.8909e+01,  5.2344e+01],
        [ 1.4850e-01, -1.5060e+00, -2.5704e+00, -4.4504e+00,  2.4122e+00,
          3.9327e+00,  4.4662e+00,  1.2522e+01,  1.3632e+01,  1.3738e+01],
        [ 5.2370e+01,  5.1960e+01,  5.3681e+01,  5.2516e+01,  6.3226e+01,
          6.3056e+01,  7.2095e+01,  8.1091e+01,  7.2556e+01,  7.0939e+01],
        [ 4.9980e-01,  4.9420e-01,  5.3430e-01,  5.0720e-01,  8.9360e-01,
          9.9480e-01,  1.2732e+00,  1.2176e+00,  8.2850e-01,  7.9600e-01],
        [-2.5459e+01, -6.3314e+01, -1.3245e+02, -1.5331e+02, -7.9875e+01,
         -4.0130e+01,  1.6049e+01,  1.8896e+01,  1.3900e-01,  2.9901e+01],
        [-2.9000e-03, -1.9000e-03, -1.1000e-03, -2.0000e-04,  7.0000e-04,
          2.5000e-03,  3.6000e-03,  4.6000e-03,  6.3000e-03,  7.1000e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.7769, 10.7770, 10.7767, 10.7793, 10.7786, 10.7786, 10.7813, 10.7804,
         10.7806, 10.7804]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0828e+01,  1.0828e+01,  1.0828e+01,  1.0828e+01,  1.0828e+01,
          1.0829e+01,  1.0828e+01,  1.0828e+01,  1.0828e+01,  1.0828e+01],
        [ 3.5060e+01,  3.6589e+01,  3.6715e+01,  3.6899e+01,  3.8787e+01,
          4.4139e+01,  4.4653e+01,  4.2399e+01,  3.8479e+01,  3.7358e+01],
        [ 2.9910e+01,  3.1246e+01,  3.2340e+01,  3.3251e+01,  3.4359e+01,
          3.6315e+01,  3.7982e+01,  3.8866e+01,  3.8789e+01,  3.8502e+01],
        [ 5.1497e+00,  5.3433e+00,  4.3758e+00,  3.6472e+00,  4.4289e+00,
          7.8246e+00,  6.6706e+00,  3.5333e+00, -3.0900e-01, -1.1446e+00],
        [ 7.1617e+01,  6.2905e+01,  5.7739e+01,  6.5388e+01,  6.3118e+01,
          7.5987e+01,  6.3886e+01,  6.4445e+01,  6.1456e+01,  6.4153e+01],
        [ 8.6840e-01,  5.7260e-01,  4.1230e-01,  6.4970e-01,  5.0090e-01,
          9.7390e-01,  4.4700e-01,  4.7120e-01,  3.4200e-01,  3.3870e-01],
        [ 5.8178e+01,  2.5604e+01,  4.3767e+01,  7.6586e+00, -6.2219e+00,
         -1.0032e+01, -1.4227e+01, -3.0628e+01, -3.6159e+01,  2.9766e+01],
        [ 3.9000e-03,  4.2000e-03,  4.0000e-03,  3.6000e-03,  3.4000e-03,
          3.3000e-03,  3.8000e-03,  3.8000e-03,  3.7000e-03,  3.5000e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.8277, 10.8275, 10.8276, 10.8282, 10.8293, 10.8285, 10.8279, 10.8275,
         10.8281, 10.8258]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0754e+01,  1.0755e+01,  1.0754e+01,  1.0754e+01,  1.0754e+01,
          1.0754e+01,  1.0754e+01,  1.0754e+01,  1.0753e+01,  1.0754e+01],
        [ 3.1576e+01,  3.6106e+01,  3.5756e+01,  3.5074e+01,  3.4140e+01,
          3.3020e+01,  3.1765e+01,  3.0056e+01,  2.6066e+01,  2.5548e+01],
        [ 2.6855e+01,  2.8705e+01,  3.0115e+01,  3.1107e+01,  3.1714e+01,
          3.1975e+01,  3.1933e+01,  3.1558e+01,  3.0459e+01,  2.9477e+01],
        [ 4.7211e+00,  7.4009e+00,  5.6408e+00,  3.9673e+00,  2.4268e+00,
          1.0450e+00, -1.6750e-01, -1.5014e+00, -4.3933e+00, -3.9291e+00],
        [ 7.3288e+01,  7.3345e+01,  6.3964e+01,  6.5022e+01,  5.7048e+01,
          5.7087e+01,  5.6062e+01,  6.0314e+01,  5.4471e+01,  5.2489e+01],
        [ 1.4095e+00,  1.0023e+00,  6.2840e-01,  6.4550e-01,  1.5730e-01,
          1.5930e-01, -6.0500e-02,  2.4600e-01, -9.2100e-02, -1.0500e-01],
        [ 3.8612e+01,  3.2376e+01,  3.0654e+01,  1.0790e+00, -3.9738e+00,
          3.8259e+01,  3.2561e+01, -3.1576e+01, -2.7010e+00,  9.3952e+00],
        [ 3.5000e-03,  4.0000e-03,  4.3000e-03,  4.1000e-03,  4.0000e-03,
          3.7000e-03,  3.4000e-03,  2.9000e-03,  2.5000e-03,  2.2000e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.7551, 10.7542, 10.7542, 10.7542, 10.7542, 10.7542, 10.7541, 10.7535,
         10.7542, 10.7554]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0585e+01,  1.0585e+01,  1.0585e+01,  1.0585e+01,  1.0586e+01,
          1.0586e+01,  1.0586e+01,  1.0586e+01,  1.0587e+01,  1.0588e+01],
        [ 2.0473e+01,  1.7630e+01,  1.5818e+01,  1.3064e+01,  1.3980e+01,
          1.3758e+01,  1.4667e+01,  1.5285e+01,  1.7821e+01,  2.2159e+01],
        [ 3.4417e+01,  3.1060e+01,  2.8011e+01,  2.5022e+01,  2.2814e+01,
          2.1003e+01,  1.9736e+01,  1.8846e+01,  1.8640e+01,  1.9344e+01],
        [-1.3944e+01, -1.3429e+01, -1.2193e+01, -1.1958e+01, -8.8335e+00,
         -7.2442e+00, -5.0681e+00, -3.5603e+00, -8.1990e-01,  2.8148e+00],
        [ 4.1981e+01,  4.4743e+01,  4.5335e+01,  3.9755e+01,  4.9240e+01,
          4.2142e+01,  4.9173e+01,  5.2718e+01,  6.7145e+01,  6.5178e+01],
        [-4.2300e-02,  9.8500e-02,  1.1960e-01, -1.1950e-01,  4.5480e-01,
          1.1440e-01,  6.5130e-01,  8.9640e-01,  1.8940e+00,  9.2820e-01],
        [ 7.6733e+00,  5.1537e+01,  1.5075e+01, -5.8881e+00, -6.1161e+01,
         -1.1660e+01, -2.0400e+01,  1.0187e+01,  2.5513e+01, -4.1421e+01],
        [-9.0000e-04, -1.5000e-03, -1.7000e-03, -2.0000e-03, -2.3000e-03,
         -1.9000e-03, -1.6000e-03, -1.2000e-03, -7.0000e-04,  1.0000e-04]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.5850, 10.5852, 10.5849, 10.5859, 10.5856, 10.5860, 10.5861, 10.5868,
         10.5876, 10.5860]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0489e+01,  1.0488e+01,  1.0488e+01,  1.0488e+01,  1.0488e+01,
          1.0488e+01,  1.0488e+01,  1.0489e+01,  1.0489e+01,  1.0490e+01],
        [-2.2819e+01, -2.3130e+01, -2.2700e+01, -2.1385e+01, -1.8751e+01,
         -1.6979e+01, -1.6399e+01, -1.4035e+01, -1.0921e+01, -5.3507e+00],
        [-2.8099e+01, -2.7105e+01, -2.6224e+01, -2.5256e+01, -2.3955e+01,
         -2.2560e+01, -2.1328e+01, -1.9869e+01, -1.8080e+01, -1.5534e+01],
        [ 5.2797e+00,  3.9749e+00,  3.5239e+00,  3.8711e+00,  5.2042e+00,
          5.5807e+00,  4.9289e+00,  5.8343e+00,  7.1584e+00,  1.0183e+01],
        [ 3.7351e+01,  3.9445e+01,  5.0267e+01,  5.6352e+01,  5.8081e+01,
          5.6331e+01,  5.4882e+01,  4.8144e+01,  4.6597e+01,  6.3734e+01],
        [ 1.9180e-01,  2.7480e-01,  7.0400e-01,  9.4530e-01,  1.0139e+00,
          9.3160e-01,  8.7490e-01,  6.1140e-01,  5.5080e-01,  1.2211e+00],
        [-5.5214e+01, -5.2688e+01, -5.6528e+01,  1.1511e+01,  3.3866e+01,
         -2.4006e+01,  1.0171e+00, -2.9439e+01, -5.3605e+00, -2.7319e+00],
        [-3.0000e-03, -2.8000e-03, -2.7000e-03, -2.2000e-03, -1.5000e-03,
         -9.0000e-04, -6.0000e-04, -1.0000e-04,  1.0000e-04,  5.0000e-04]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.4876, 10.4877, 10.4880, 10.4884, 10.4883, 10.4879, 10.4885, 10.4889,
         10.4900, 10.4892]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0832e+01,  1.0831e+01,  1.0831e+01,  1.0831e+01,  1.0831e+01,
          1.0830e+01,  1.0830e+01,  1.0830e+01,  1.0831e+01,  1.0830e+01],
        [ 9.4564e+00,  4.0090e+00, -4.8570e-01, -3.7025e+00, -8.1190e+00,
         -1.3570e+01, -1.7652e+01, -2.2663e+01, -2.4079e+01, -2.5571e+01],
        [ 1.9931e+01,  1.6746e+01,  1.3300e+01,  9.8994e+00,  6.2957e+00,
          2.3226e+00, -1.6723e+00, -5.8703e+00, -9.5120e+00, -1.2724e+01],
        [-1.0474e+01, -1.2737e+01, -1.3785e+01, -1.3602e+01, -1.4415e+01,
         -1.5892e+01, -1.5980e+01, -1.6792e+01, -1.4567e+01, -1.2847e+01],
        [ 4.3562e+01,  3.8969e+01,  3.4687e+01,  3.2429e+01,  1.9749e+01,
          1.9839e+01,  2.7835e+01,  1.2343e+01,  2.2908e+01,  2.5622e+01],
        [-5.2300e-02, -1.0790e-01, -9.0800e-02, -4.3900e-02, -2.3610e-01,
          1.5000e-03,  1.9550e-01, -1.7910e-01,  2.7760e-01,  3.5410e-01],
        [ 8.8040e+01,  5.8779e+01, -2.3887e+01,  1.5094e+01,  1.6844e+01,
         -1.1336e+01,  1.0068e+01,  1.0577e+01, -1.9757e+00,  9.0643e+00],
        [-1.0000e-04, -7.0000e-04, -1.6000e-03, -2.3000e-03, -2.7000e-03,
         -3.4000e-03, -4.1000e-03, -4.2000e-03, -4.7000e-03, -4.8000e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.8314, 10.8314, 10.8314, 10.8310, 10.8305, 10.8305, 10.8300, 10.8305,
         10.8304, 10.8309]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0736e+01,  1.0736e+01,  1.0737e+01,  1.0737e+01,  1.0737e+01,
          1.0737e+01,  1.0737e+01,  1.0738e+01,  1.0737e+01,  1.0738e+01],
        [-4.7504e+01, -4.5712e+01, -4.1047e+01, -3.5580e+01, -3.1263e+01,
         -2.8493e+01, -2.4130e+01, -1.8520e+01, -1.5177e+01, -9.8046e+00],
        [-5.6587e+01, -5.4412e+01, -5.1739e+01, -4.8507e+01, -4.5058e+01,
         -4.1745e+01, -3.8222e+01, -3.4282e+01, -3.0461e+01, -2.6329e+01],
        [ 9.0830e+00,  8.7000e+00,  1.0692e+01,  1.2927e+01,  1.3795e+01,
          1.3252e+01,  1.4092e+01,  1.5762e+01,  1.5284e+01,  1.6525e+01],
        [ 5.5662e+01,  5.6342e+01,  5.5170e+01,  7.0000e+01,  7.2146e+01,
          6.7407e+01,  6.7763e+01,  6.3624e+01,  5.3190e+01,  5.9585e+01],
        [ 9.2810e-01,  9.5020e-01,  9.1210e-01,  1.3939e+00,  1.0500e+00,
          8.9480e-01,  9.0270e-01,  8.1080e-01,  5.7920e-01,  7.2120e-01],
        [-1.2042e+02, -9.3268e+01, -6.3631e+01, -1.2167e+00,  4.4549e+01,
          4.7555e+01,  3.4000e+01,  6.0919e+00,  1.4396e+01, -1.0028e+01],
        [-3.6000e-03, -2.1000e-03, -8.0000e-04,  3.0000e-04,  1.4000e-03,
          2.0000e-03,  2.1000e-03,  2.3000e-03,  2.4000e-03,  2.3000e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.7358, 10.7366, 10.7369, 10.7368, 10.7366, 10.7371, 10.7376, 10.7373,
         10.7380, 10.7382]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0589e+01,  1.0592e+01,  1.0592e+01,  1.0592e+01,  1.0591e+01,
          1.0591e+01,  1.0590e+01,  1.0591e+01,  1.0592e+01,  1.0592e+01],
        [-2.7527e+01, -1.6839e+01, -9.5912e+00, -5.0654e+00, -4.1900e+00,
         -1.8586e+00, -3.3149e+00, -3.0285e+00,  6.9320e-01,  3.8749e+00],
        [-3.7777e+01, -3.3589e+01, -2.8789e+01, -2.4045e+01, -2.0074e+01,
         -1.6431e+01, -1.3808e+01, -1.1652e+01, -9.1828e+00, -6.5712e+00],
        [ 1.0250e+01,  1.6750e+01,  1.9198e+01,  1.8979e+01,  1.5884e+01,
          1.4572e+01,  1.0493e+01,  8.6232e+00,  9.8760e+00,  1.0446e+01],
        [ 4.9404e+01,  5.7193e+01,  5.8909e+01,  5.3685e+01,  5.3913e+01,
          5.9959e+01,  5.6895e+01,  5.6962e+01,  6.0627e+01,  5.6063e+01],
        [ 8.0170e-01,  1.0792e+00,  1.0566e+00,  8.3680e-01,  8.4390e-01,
          1.0328e+00,  9.0730e-01,  9.0930e-01,  1.0202e+00,  8.2070e-01],
        [-2.7514e+01, -7.2325e+01, -7.9342e+01, -6.1958e+01, -7.4062e+01,
          9.9000e-01, -2.1017e+01, -7.0491e+01,  1.6437e+01,  5.5898e+01],
        [-3.4000e-03, -2.7000e-03, -9.0000e-04,  9.0000e-04,  2.1000e-03,
          2.8000e-03,  3.7000e-03,  3.8000e-03,  4.0000e-03,  4.7000e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.5925, 10.5921, 10.5917, 10.5908, 10.5913, 10.5903, 10.5907, 10.5918,
         10.5919, 10.5931]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.1103e+01,  1.1102e+01,  1.1102e+01,  1.1101e+01,  1.1102e+01,
          1.1100e+01,  1.1100e+01,  1.1099e+01,  1.1100e+01,  1.1100e+01],
        [-7.3870e-01, -8.0357e+00, -1.6579e+01, -2.6524e+01, -2.6592e+01,
         -3.6813e+01, -4.7953e+01, -6.0846e+01, -6.5137e+01, -6.7291e+01],
        [ 5.6459e+00,  2.9096e+00, -9.8820e-01, -6.0954e+00, -1.0195e+01,
         -1.5519e+01, -2.2005e+01, -2.9774e+01, -3.6846e+01, -4.2935e+01],
        [-6.3846e+00, -1.0945e+01, -1.5591e+01, -2.0429e+01, -1.6397e+01,
         -2.1295e+01, -2.5948e+01, -3.1073e+01, -2.8291e+01, -2.4356e+01],
        [ 4.7216e+01,  4.1830e+01,  3.5729e+01,  3.4357e+01,  4.1378e+01,
          2.9834e+01,  3.4984e+01,  3.4309e+01,  3.5211e+01,  3.6210e+01],
        [ 5.2600e-01,  2.7470e-01, -9.9000e-03, -6.3400e-02,  3.0500e-01,
         -1.9650e-01,  1.8700e-01,  1.6250e-01,  1.9520e-01,  2.3150e-01],
        [ 5.6493e+01,  1.3838e+02, -3.1126e+01, -6.8533e+01, -8.0462e+00,
         -1.6611e+01,  1.3768e+01,  1.7399e+01,  3.6388e+01,  1.3283e+02],
        [-2.0000e-04, -4.0000e-04, -1.0000e-03, -2.1000e-03, -2.8000e-03,
         -2.9000e-03, -4.0000e-03, -4.7000e-03, -5.6000e-03, -6.1000e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[11.1022, 11.1016, 11.1010, 11.1024, 11.1004, 11.0997, 11.0988, 11.0998,
         11.0999, 11.0980]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0616e+01,  1.0621e+01,  1.0620e+01,  1.0618e+01,  1.0618e+01,
          1.0620e+01,  1.0620e+01,  1.0618e+01,  1.0621e+01,  1.0621e+01],
        [-7.2326e+01, -5.0559e+01, -3.7492e+01, -3.3259e+01, -2.7323e+01,
         -1.8314e+01, -8.5512e+00, -6.9466e+00,  3.9624e+00,  1.1312e+01],
        [-8.1752e+01, -7.5513e+01, -6.7909e+01, -6.0979e+01, -5.4248e+01,
         -4.7061e+01, -3.9359e+01, -3.2877e+01, -2.5509e+01, -1.8145e+01],
        [ 9.4260e+00,  2.4955e+01,  3.0417e+01,  2.7720e+01,  2.6924e+01,
          2.8747e+01,  3.0808e+01,  2.5930e+01,  2.9471e+01,  2.9457e+01],
        [ 4.1255e+01,  5.1844e+01,  5.5137e+01,  5.5512e+01,  6.2638e+01,
          6.3083e+01,  6.5339e+01,  6.0311e+01,  5.6806e+01,  6.2512e+01],
        [ 9.3280e-01,  1.3113e+00,  1.0898e+00,  1.0094e+00,  1.1766e+00,
          1.0094e+00,  1.0487e+00,  8.8640e-01,  7.3170e-01,  9.1110e-01],
        [-2.3300e+02, -1.8012e+02, -1.9849e+02, -1.7335e+02,  4.6958e+01,
         -6.0691e+01, -1.4829e+02, -3.5008e+01, -4.8269e+01,  7.2871e+00],
        [-1.2200e-02, -9.8000e-03, -5.5000e-03, -2.0000e-03,  7.0000e-04,
          3.5000e-03,  5.4000e-03,  7.7000e-03,  9.1000e-03,  9.7000e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.6210, 10.6196, 10.6176, 10.6183, 10.6195, 10.6203, 10.6184, 10.6213,
         10.6210, 10.6219]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[ 1.0831e+01,  1.0834e+01,  1.0833e+01,  1.0832e+01,  1.0832e+01,
          1.0833e+01,  1.0835e+01,  1.0833e+01,  1.0833e+01,  1.0833e+01],
        [ 7.0862e+01,  7.6492e+01,  7.9708e+01,  7.7466e+01,  7.3653e+01,
          7.4141e+01,  7.9382e+01,  7.6517e+01,  7.3945e+01,  7.1087e+01],
        [ 6.9179e+01,  7.0642e+01,  7.2455e+01,  7.3457e+01,  7.3496e+01,
          7.3625e+01,  7.4777e+01,  7.5125e+01,  7.4889e+01,  7.4128e+01],
        [ 1.6830e+00,  5.8504e+00,  7.2533e+00,  4.0087e+00,  1.5650e-01,
          5.1570e-01,  4.6055e+00,  1.3924e+00, -9.4410e-01, -3.0419e+00],
        [ 5.3347e+01,  5.9267e+01,  6.3509e+01,  5.8373e+01,  5.5353e+01,
          5.5298e+01,  7.1000e+01,  6.0209e+01,  5.9013e+01,  6.2530e+01],
        [-6.0620e-01,  2.6410e-01,  4.5340e-01,  2.2420e-01,  8.9500e-02,
          8.7000e-02,  7.8760e-01,  3.0620e-01,  2.5280e-01,  4.0970e-01],
        [ 8.9303e+01,  1.2881e+02,  4.6167e+00,  1.6992e+01,  2.4790e+01,
         -2.3324e+01, -3.0222e+01, -3.4178e+01,  2.6738e+01,  7.6981e+00],
        [ 8.5000e-03,  6.9000e-03,  6.2000e-03,  5.5000e-03,  5.0000e-03,
          4.3000e-03,  3.9000e-03,  4.7000e-03,  4.7000e-03,  4.6000e-03]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.8335, 10.8334, 10.8325, 10.8322, 10.8333, 10.8347, 10.8332, 10.8333,
         10.8333, 10.8323]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
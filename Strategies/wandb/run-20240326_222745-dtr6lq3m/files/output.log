  0%|          | 0/350 [00:00<?, ?it/s]C:\Users\dadou\anaconda3\envs\Advanced-Programming\Lib\site-packages\torch\nn\functional.py:5476: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\aten\src\ATen\native\transformers\cuda\sdp_utils.cpp:263.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
  0%|          | 0/350 [00:02<?, ?it/s]
Traceback (most recent call last):
  File "C:\Users\dadou\Documents\Github\Advanced-Programming\Strategies\Transformer_strategy.py", line 417, in <module>
    trainer.train()
  File "C:\Users\dadou\Documents\Github\Advanced-Programming\utils\trainer.py", line 79, in train
    loss.backward()
  File "C:\Users\dadou\anaconda3\envs\Advanced-Programming\Lib\site-packages\torch\_tensor.py", line 522, in backward
    torch.autograd.backward(
  File "C:\Users\dadou\anaconda3\envs\Advanced-Programming\Lib\site-packages\torch\autograd\__init__.py", line 266, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[10.5630, 10.5630, 10.5638, 10.5635, 10.5622, 10.5626, 10.5616, 10.5616,
         10.5615, 10.5597],
        [ 1.0048,  1.0038,  1.0051,  1.0052,  1.0017,  1.0000,  0.9962,  0.9932,
          0.9905,  0.9840],
        [ 1.0130,  1.0112,  1.0101,  1.0092,  1.0077,  1.0062,  1.0041,  1.0018,
          0.9994,  0.9960],
        [ 0.9814,  0.9832,  0.9891,  0.9914,  0.9859,  0.9853,  0.9803,  0.9782,
          0.9770,  0.9680],
        [ 1.3680,  1.3049,  1.3876,  1.4281,  1.3658,  1.4327,  1.3850,  1.4195,
          1.3914,  1.2903],
        [ 1.0533,  1.0263,  1.0617,  1.0791,  1.0567,  1.0925,  1.0865,  1.1198,
          1.1007,  1.0318],
        [ 0.9945,  0.9859,  0.9837,  0.9736,  0.9814,  0.9869,  0.9912,  1.0034,
          1.0105,  0.9931],
        [ 0.9864,  0.9864,  0.9864,  0.9886,  0.9908,  0.9912,  0.9925,  0.9921,
          0.9917,  0.9904]])
preds tensor([[-0.0019,  0.0015,  0.0010, -0.0043, -0.0016, -0.0035,  0.0017,  0.0018,
          0.0002, -0.0009]], grad_fn=<ToCopyBackward0>)
targets tensor([[10.5630, 10.5638, 10.5635, 10.5622, 10.5626, 10.5616, 10.5616, 10.5615,
         10.5597, 10.5591]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[10.6596, 10.6596, 10.6582, 10.6581, 10.6580, 10.6582, 10.6590, 10.6586,
         10.6581, 10.6570],
        [ 0.9782,  0.9797,  0.9772,  0.9750,  0.9734,  0.9730,  0.9754,  0.9763,
          0.9759,  0.9728],
        [ 0.9770,  0.9772,  0.9768,  0.9760,  0.9750,  0.9742,  0.9740,  0.9741,
          0.9740,  0.9733],
        [ 0.9985,  1.0019,  0.9962,  0.9926,  0.9907,  0.9917,  0.9984,  1.0006,
          0.9996,  0.9932],
        [ 1.4271,  1.4384,  1.3684,  1.4002,  1.2309,  1.2673,  1.4453,  1.4380,
          1.3335,  1.2761],
        [ 1.1589,  1.1685,  1.1087,  1.1359,  0.9362,  1.0296,  1.1742,  1.1645,
          1.0815,  1.0360],
        [ 1.0156,  1.0145,  0.9917,  0.9876,  1.0042,  1.0067,  1.0036,  0.9883,
          0.9905,  0.9983],
        [ 0.9890,  0.9908,  0.9912,  0.9899,  0.9895,  0.9882,  0.9868,  0.9877,
          0.9886,  0.9886]])
preds tensor([[0.0062, 0.0068, 0.0066, 0.0065, 0.0064, 0.0064, 0.0066, 0.0060, 0.0069,
         0.0067]], grad_fn=<ToCopyBackward0>)
targets tensor([[10.6596, 10.6582, 10.6581, 10.6580, 10.6582, 10.6590, 10.6586, 10.6581,
         10.6570, 10.6575]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[10.3607, 10.3609, 10.3608, 10.3605, 10.3606, 10.3602, 10.3604, 10.3602,
         10.3606, 10.3599],
        [ 0.9819,  0.9793,  0.9773,  0.9753,  0.9744,  0.9730,  0.9726,  0.9723,
          0.9732,  0.9726],
        [ 0.9864,  0.9846,  0.9828,  0.9809,  0.9791,  0.9774,  0.9760,  0.9748,
          0.9740,  0.9733],
        [ 0.9855,  0.9830,  0.9823,  0.9819,  0.9835,  0.9839,  0.9863,  0.9884,
          0.9926,  0.9929],
        [ 1.3382,  1.3641,  1.3555,  1.3472,  1.3511,  1.3323,  1.2982,  1.2926,
          1.2600,  1.2674],
        [ 1.0700,  1.0797,  1.0765,  1.0734,  1.0748,  1.0678,  1.0022,  0.9969,
          0.9822,  1.0037],
        [ 0.9938,  0.9968,  1.0103,  1.0130,  1.0293,  1.0141,  1.0361,  1.0295,
          0.9970,  0.9838],
        [ 0.9956,  0.9930,  0.9908,  0.9886,  0.9851,  0.9829,  0.9794,  0.9772,
          0.9746,  0.9733]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.3609, 10.3608, 10.3605, 10.3606, 10.3602, 10.3604, 10.3602, 10.3606,
         10.3599, 10.3595]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[10.9591, 10.9582, 10.9559, 10.9563, 10.9545, 10.9531, 10.9519, 10.9508,
         10.9505, 10.9494],
        [ 1.0303,  1.0256,  1.0129,  1.0043,  0.9905,  0.9745,  0.9577,  0.9405,
          0.9267,  0.9126],
        [ 1.0441,  1.0408,  1.0354,  1.0293,  1.0214,  1.0116,  1.0001,  0.9871,
          0.9738,  0.9601],
        [ 0.9734,  0.9690,  0.9490,  0.9414,  0.9247,  0.9068,  0.8906,  0.8770,
          0.8732,  0.8694],
        [ 1.4986,  1.4632,  1.3502,  1.3191,  1.3529,  1.2983,  1.2079,  1.1986,
          1.1258,  1.1286],
        [ 1.0195,  0.9970,  0.9293,  0.9862,  1.0167,  0.9898,  0.9580,  0.9965,
          0.9734,  1.0010],
        [ 0.9894,  0.9978,  1.0356,  1.0186,  1.0555,  1.0147,  1.0173,  1.0317,
          1.0118,  1.0323],
        [ 1.0083,  1.0039,  1.0009,  0.9939,  0.9864,  0.9807,  0.9724,  0.9636,
          0.9553,  0.9465]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.9582, 10.9559, 10.9563, 10.9545, 10.9531, 10.9519, 10.9508, 10.9505,
         10.9494, 10.9495]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[10.8265, 10.8277, 10.8279, 10.8285, 10.8292, 10.8276, 10.8278, 10.8283,
         10.8294, 10.8297],
        [ 0.9778,  0.9786,  0.9800,  0.9833,  0.9887,  0.9878,  0.9878,  0.9897,
          0.9948,  1.0001],
        [ 0.9814,  0.9805,  0.9800,  0.9804,  0.9819,  0.9829,  0.9836,  0.9847,
          0.9866,  0.9893],
        [ 0.9869,  0.9911,  0.9958,  1.0036,  1.0140,  1.0092,  1.0074,  1.0099,
          1.0185,  1.0257],
        [ 1.4627,  1.4541,  1.4780,  1.4462,  1.4037,  1.3978,  1.4085,  1.5538,
          1.6135,  1.5863],
        [ 1.0790,  1.0248,  1.0468,  1.0175,  0.9783,  0.9952,  1.0085,  1.1242,
          1.1717,  1.1488],
        [ 1.0862,  1.0489,  1.0503,  0.9826,  0.9746,  0.9987,  0.9983,  1.0085,
          0.9929,  0.9571],
        [ 1.0039,  1.0000,  0.9961,  0.9943,  0.9925,  0.9930,  0.9921,  0.9912,
          0.9934,  0.9969]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.8277, 10.8279, 10.8285, 10.8292, 10.8276, 10.8278, 10.8283, 10.8294,
         10.8297, 10.8288]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[10.4352, 10.4354, 10.4352, 10.4355, 10.4349, 10.4349, 10.4351, 10.4352,
         10.4363, 10.4360],
        [ 1.0191,  1.0235,  1.0262,  1.0285,  1.0288,  1.0287,  1.0287,  1.0285,
          1.0308,  1.0314],
        [ 1.0083,  1.0118,  1.0151,  1.0183,  1.0209,  1.0229,  1.0246,  1.0259,
          1.0274,  1.0287],
        [ 1.0296,  1.0327,  1.0317,  1.0302,  1.0248,  1.0195,  1.0157,  1.0122,
          1.0144,  1.0128],
        [ 1.6220,  1.7161,  1.7428,  1.7932,  1.7317,  1.7381,  1.7834,  1.7648,
          1.7787,  1.6932],
        [ 1.1637,  1.2065,  1.1802,  1.1887,  1.1466,  1.1490,  1.1665,  1.1574,
          1.1628,  1.1062],
        [ 0.9732,  0.9681,  0.9553,  0.9675,  0.9761,  1.0078,  1.0183,  1.0040,
          1.0276,  1.0105],
        [ 1.0075,  1.0140,  1.0206,  1.0267,  1.0324,  1.0351,  1.0368,  1.0368,
          1.0355,  1.0359]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.4354, 10.4352, 10.4355, 10.4349, 10.4349, 10.4351, 10.4352, 10.4363,
         10.4360, 10.4359]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[10.9918, 10.9921, 10.9923, 10.9930, 10.9927, 10.9933, 10.9926, 10.9919,
         10.9920, 10.9910],
        [ 1.0566,  1.0516,  1.0482,  1.0476,  1.0455,  1.0455,  1.0425,  1.0368,
          1.0323,  1.0242],
        [ 1.0515,  1.0524,  1.0524,  1.0522,  1.0517,  1.0512,  1.0502,  1.0481,
          1.0455,  1.0417],
        [ 1.0236,  1.0085,  0.9997,  0.9987,  0.9945,  0.9957,  0.9904,  0.9804,
          0.9750,  0.9634],
        [ 1.6083,  1.6600,  1.6495,  1.6037,  1.5655,  1.5523,  1.5754,  1.5266,
          1.4045,  1.2853],
        [ 1.1019,  1.1199,  1.1038,  1.0460,  0.9770,  0.9906,  1.0156,  0.9827,
          0.9254,  0.9493],
        [ 1.0225,  1.0500,  1.0062,  1.0122,  1.0892,  1.1199,  1.1220,  1.0490,
          1.0563,  1.0092],
        [ 1.0478,  1.0438,  1.0408,  1.0368,  1.0333,  1.0281,  1.0219,  1.0158,
          1.0092,  1.0031]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.9921, 10.9923, 10.9930, 10.9927, 10.9933, 10.9926, 10.9919, 10.9920,
         10.9910, 10.9905]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[10.4580, 10.4586, 10.4588, 10.4551, 10.4567, 10.4566, 10.4539, 10.4510,
         10.4557, 10.4534],
        [ 0.9704,  0.9744,  0.9783,  0.9729,  0.9727,  0.9728,  0.9668,  0.9557,
          0.9584,  0.9556],
        [ 0.9412,  0.9474,  0.9532,  0.9567,  0.9594,  0.9616,  0.9621,  0.9601,
          0.9590,  0.9576],
        [ 1.0636,  1.0591,  1.0553,  1.0331,  1.0261,  1.0209,  1.0044,  0.9806,
          0.9901,  0.9863],
        [ 1.6182,  1.5522,  1.6514,  1.5525,  1.5760,  1.5483,  1.3735,  1.3141,
          1.4343,  1.4013],
        [ 1.1590,  1.1184,  1.1794,  1.1126,  1.1263,  1.1101,  0.9394,  0.9636,
          1.0606,  1.0440],
        [ 0.9225,  0.9567,  1.0597,  1.0714,  1.0619,  1.0611,  1.0020,  1.0631,
          1.0776,  1.0073],
        [ 1.0276,  1.0364,  1.0395,  1.0425,  1.0346,  1.0294,  1.0228,  1.0083,
          0.9930,  0.9847]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.4586, 10.4588, 10.4551, 10.4567, 10.4566, 10.4539, 10.4510, 10.4557,
         10.4534, 10.4521]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[10.9843, 10.9841, 10.9834, 10.9848, 10.9856, 10.9854, 10.9853, 10.9856,
         10.9862, 10.9853],
        [ 1.0228,  1.0211,  1.0167,  1.0185,  1.0228,  1.0251,  1.0266,  1.0282,
          1.0317,  1.0304],
        [ 1.0219,  1.0221,  1.0213,  1.0210,  1.0218,  1.0229,  1.0241,  1.0254,
          1.0272,  1.0283],
        [ 1.0068,  1.0019,  0.9924,  0.9977,  1.0070,  1.0105,  1.0113,  1.0125,
          1.0172,  1.0110],
        [ 1.5607,  1.5773,  1.4249,  1.5949,  1.6633,  1.6398,  1.6339,  1.6298,
          1.6584,  1.5685],
        [ 1.0938,  1.1082,  0.9756,  1.1295,  1.1815,  1.1534,  1.1493,  1.1463,
          1.1667,  1.1026],
        [ 0.9885,  0.9906,  0.9912,  1.0005,  0.9998,  1.0057,  0.9867,  1.0021,
          1.0138,  1.0274],
        [ 1.0070,  1.0075,  1.0075,  1.0057,  1.0066,  1.0083,  1.0096,  1.0105,
          1.0114,  1.0132]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.9841, 10.9834, 10.9848, 10.9856, 10.9854, 10.9853, 10.9856, 10.9862,
         10.9853, 10.9856]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[10.7782, 10.7786, 10.7790, 10.7801, 10.7802, 10.7813, 10.7803, 10.7805,
         10.7805, 10.7812],
        [ 0.9775,  0.9764,  0.9769,  0.9812,  0.9851,  0.9918,  0.9942,  0.9965,
          0.9986,  1.0024],
        [ 0.9810,  0.9796,  0.9787,  0.9789,  0.9799,  0.9821,  0.9844,  0.9868,
          0.9891,  0.9918],
        [ 0.9874,  0.9876,  0.9910,  1.0017,  1.0094,  1.0215,  1.0221,  1.0224,
          1.0223,  1.0256],
        [ 1.4054,  1.3882,  1.4564,  1.4749,  1.5456,  1.5917,  1.5278,  1.5016,
          1.5443,  1.5207],
        [ 1.0326,  1.0249,  1.0740,  1.0851,  1.1996,  1.2071,  1.1283,  1.1111,
          1.1391,  1.1236],
        [ 0.9684,  0.9721,  0.9884,  1.0109,  0.9922,  1.0263,  0.9610,  0.9835,
          0.9844,  0.9931],
        [ 0.9847,  0.9833,  0.9833,  0.9855,  0.9882,  0.9912,  0.9961,  0.9982,
          1.0009,  1.0035]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.7786, 10.7790, 10.7801, 10.7802, 10.7813, 10.7803, 10.7805, 10.7805,
         10.7812, 10.7822]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[10.7474, 10.7478, 10.7473, 10.7473, 10.7461, 10.7459, 10.7495, 10.7513,
         10.7496, 10.7494],
        [ 1.0480,  1.0512,  1.0516,  1.0513,  1.0466,  1.0418,  1.0488,  1.0597,
          1.0620,  1.0624],
        [ 1.0509,  1.0518,  1.0526,  1.0532,  1.0527,  1.0512,  1.0516,  1.0542,
          1.0568,  1.0590],
        [ 1.0030,  1.0089,  1.0079,  1.0058,  0.9948,  0.9861,  1.0033,  1.0250,
          1.0248,  1.0207],
        [ 1.6790,  1.7416,  1.6983,  1.6558,  1.5556,  1.5397,  1.6951,  1.7420,
          1.6339,  1.5872],
        [ 1.1318,  1.1932,  1.1114,  1.0538,  0.9179,  0.9854,  1.1311,  1.1706,
          1.0793,  1.0399],
        [ 1.0101,  1.0087,  0.9927,  0.9861,  1.0092,  1.0414,  1.0054,  0.9938,
          0.9772,  0.9939],
        [ 1.0180,  1.0193,  1.0215,  1.0224,  1.0224,  1.0206,  1.0175,  1.0197,
          1.0259,  1.0276]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.7478, 10.7473, 10.7473, 10.7461, 10.7459, 10.7495, 10.7513, 10.7496,
         10.7494, 10.7493]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[10.5358, 10.5341, 10.5351, 10.5334, 10.5353, 10.5357, 10.5358, 10.5349,
         10.5306, 10.5249],
        [ 0.9804,  0.9804,  0.9830,  0.9810,  0.9843,  0.9882,  0.9916,  0.9921,
          0.9817,  0.9594],
        [ 0.9691,  0.9710,  0.9731,  0.9744,  0.9761,  0.9783,  0.9808,  0.9830,
          0.9824,  0.9771],
        [ 1.0230,  1.0183,  1.0200,  1.0120,  1.0164,  1.0212,  1.0240,  1.0201,
          0.9947,  0.9497],
        [ 1.5133,  1.4773,  1.4941,  1.4668,  1.5676,  1.6592,  1.6188,  1.5644,
          1.4019,  1.2621],
        [ 1.2155,  1.1402,  1.1542,  1.1314,  1.2156,  1.2306,  1.1482,  1.1185,
          1.0297,  0.9534],
        [ 0.9635,  0.9283,  0.9623,  0.9712,  0.9829,  1.0045,  0.9832,  1.0015,
          1.0084,  1.0216],
        [ 0.9816,  0.9877,  0.9917,  0.9969,  0.9982,  1.0026,  1.0083,  1.0110,
          1.0118,  1.0048]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.5341, 10.5351, 10.5334, 10.5353, 10.5357, 10.5358, 10.5349, 10.5306,
         10.5249, 10.5222]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[10.8085, 10.8084, 10.8079, 10.8076, 10.8078, 10.8083, 10.8083, 10.8085,
         10.8078, 10.8090],
        [ 0.9122,  0.9152,  0.9170,  0.9182,  0.9206,  0.9251,  0.9294,  0.9344,
          0.9365,  0.9432],
        [ 0.9059,  0.9063,  0.9071,  0.9079,  0.9091,  0.9110,  0.9135,  0.9165,
          0.9195,  0.9232],
        [ 0.9972,  1.0040,  1.0069,  1.0079,  1.0114,  1.0182,  1.0235,  1.0292,
          1.0278,  1.0359],
        [ 1.1018,  1.1191,  1.1310,  1.1687,  1.3005,  1.4004,  1.4031,  1.4481,
          1.4296,  1.5986],
        [ 0.9650,  1.0104,  1.0235,  1.0615,  1.2215,  1.2558,  1.1718,  1.1957,
          1.1612,  1.2442],
        [ 0.9291,  0.9390,  0.9464,  0.9541,  0.9463,  0.9473,  0.9559,  0.9866,
          0.9940,  0.9978],
        [ 0.9483,  0.9518,  0.9566,  0.9610,  0.9654,  0.9711,  0.9772,  0.9825,
          0.9873,  0.9899]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.8084, 10.8079, 10.8076, 10.8078, 10.8083, 10.8083, 10.8085, 10.8078,
         10.8090, 10.8092]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[11.0510, 11.0505, 11.0510, 11.0508, 11.0505, 11.0498, 11.0496, 11.0490,
         11.0489, 11.0489],
        [ 0.9857,  0.9793,  0.9768,  0.9738,  0.9705,  0.9655,  0.9610,  0.9555,
          0.9511,  0.9484],
        [ 1.0016,  0.9968,  0.9924,  0.9882,  0.9842,  0.9799,  0.9754,  0.9707,
          0.9659,  0.9616],
        [ 0.9594,  0.9543,  0.9581,  0.9604,  0.9614,  0.9589,  0.9578,  0.9550,
          0.9548,  0.9584],
        [ 1.3311,  1.1771,  1.2556,  1.2640,  1.1933,  1.1822,  1.1840,  1.1800,
          1.1855,  1.1592],
        [ 1.0234,  0.9537,  1.0279,  1.0381,  1.0071,  1.0022,  1.0031,  1.0020,
          1.0059,  0.9860],
        [ 1.0235,  1.0174,  1.0113,  1.0007,  0.9947,  1.0107,  1.0028,  0.9824,
          1.0004,  1.0034],
        [ 0.9877,  0.9860,  0.9825,  0.9807,  0.9798,  0.9785,  0.9768,  0.9754,
          0.9737,  0.9733]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[11.0505, 11.0510, 11.0508, 11.0505, 11.0498, 11.0496, 11.0490, 11.0489,
         11.0489, 11.0483]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[11.0622, 11.0622, 11.0621, 11.0618, 11.0617, 11.0610, 11.0601, 11.0614,
         11.0614, 11.0627],
        [ 0.9955,  0.9910,  0.9872,  0.9830,  0.9796,  0.9741,  0.9662,  0.9658,
          0.9661,  0.9724],
        [ 1.0105,  1.0064,  1.0024,  0.9982,  0.9941,  0.9897,  0.9844,  0.9801,
          0.9767,  0.9754],
        [ 0.9634,  0.9615,  0.9613,  0.9604,  0.9614,  0.9576,  0.9498,  0.9591,
          0.9679,  0.9872],
        [ 1.3892,  1.3343,  1.2680,  1.2594,  1.1475,  1.1357,  1.1193,  1.2147,
          1.2391,  1.4570],
        [ 0.9210,  0.9528,  0.9554,  0.9954,  0.9419,  0.9954,  0.9938,  1.0347,
          1.0436,  1.1546],
        [ 1.0394,  1.0319,  1.0260,  1.0504,  1.0348,  0.9945,  0.9957,  0.9930,
          0.9978,  1.0022],
        [ 0.9982,  0.9956,  0.9921,  0.9895,  0.9864,  0.9833,  0.9798,  0.9768,
          0.9759,  0.9763]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[11.0622, 11.0621, 11.0618, 11.0617, 11.0610, 11.0601, 11.0614, 11.0614,
         11.0627, 11.0618]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[10.9909, 10.9892, 10.9890, 10.9901, 10.9913, 10.9926, 10.9919, 10.9917,
         10.9916, 10.9926],
        [ 0.9655,  0.9644,  0.9632,  0.9673,  0.9757,  0.9876,  0.9944,  0.9988,
          1.0022,  1.0084],
        [ 0.9342,  0.9396,  0.9437,  0.9479,  0.9530,  0.9597,  0.9665,  0.9730,
          0.9789,  0.9849],
        [ 1.0675,  1.0518,  1.0390,  1.0395,  1.0490,  1.0637,  1.0650,  1.0613,
          1.0558,  1.0576],
        [ 1.5874,  1.4770,  1.4837,  1.5644,  1.6438,  1.6552,  1.6112,  1.6086,
          1.6411,  1.6376],
        [ 1.1630,  1.1119,  1.1083,  1.1498,  1.1906,  1.1789,  1.1379,  1.1361,
          1.1590,  1.1534],
        [ 0.9606,  0.9906,  0.9965,  0.9909,  0.9679,  0.9998,  1.0183,  0.9913,
          1.0108,  1.0370],
        [ 1.0044,  1.0070,  1.0066,  1.0057,  1.0061,  1.0092,  1.0136,  1.0153,
          1.0162,  1.0175]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.9892, 10.9890, 10.9901, 10.9913, 10.9926, 10.9919, 10.9917, 10.9916,
         10.9926, 10.9925]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[10.2986, 10.2985, 10.2981, 10.2973, 10.2974, 10.2974, 10.2984, 10.2981,
         10.2969, 10.2968],
        [ 0.9922,  0.9932,  0.9933,  0.9917,  0.9908,  0.9901,  0.9917,  0.9926,
          0.9909,  0.9894],
        [ 0.9940,  0.9937,  0.9935,  0.9930,  0.9924,  0.9918,  0.9916,  0.9917,
          0.9914,  0.9908],
        [ 0.9943,  0.9975,  0.9982,  0.9952,  0.9942,  0.9940,  0.9986,  1.0006,
          0.9971,  0.9946],
        [ 1.4399,  1.4136,  1.4095,  1.3739,  1.4032,  1.4422,  1.4512,  1.4443,
          1.4162,  1.4276],
        [ 1.1098,  1.0979,  1.1237,  1.1030,  1.1201,  1.1428,  1.1481,  1.1656,
          1.1468,  1.1544],
        [ 0.9933,  0.9837,  1.0003,  0.9991,  0.9889,  0.9862,  0.9791,  0.9931,
          0.9939,  0.9985],
        [ 0.9820,  0.9838,  0.9860,  0.9877,  0.9882,  0.9886,  0.9904,  0.9925,
          0.9947,  0.9943]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.2985, 10.2981, 10.2973, 10.2974, 10.2974, 10.2984, 10.2981, 10.2969,
         10.2968, 10.2962]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[10.5444, 10.5469, 10.5466, 10.5471, 10.5467, 10.5458, 10.5460, 10.5467,
         10.5473, 10.5474],
        [ 0.9882,  0.9912,  0.9929,  0.9956,  0.9966,  0.9952,  0.9945,  0.9960,
          0.9987,  1.0010],
        [ 1.0012,  0.9991,  0.9977,  0.9972,  0.9971,  0.9966,  0.9961,  0.9960,
          0.9965,  0.9974],
        [ 0.9665,  0.9794,  0.9871,  0.9953,  0.9983,  0.9956,  0.9952,  0.9991,
          1.0050,  1.0088],
        [ 1.2585,  1.4360,  1.4376,  1.4756,  1.4621,  1.4558,  1.4740,  1.5399,
          1.5399,  1.5471],
        [ 1.0211,  1.1604,  1.1618,  1.1924,  1.1606,  1.1562,  1.1691,  1.2161,
          1.1702,  1.1743],
        [ 1.0048,  0.9908,  0.9886,  0.9807,  0.9959,  0.9963,  0.9956,  0.9837,
          0.9894,  0.9722],
        [ 0.9829,  0.9811,  0.9829,  0.9855,  0.9886,  0.9908,  0.9921,  0.9934,
          0.9961,  0.9991]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.5469, 10.5466, 10.5471, 10.5467, 10.5458, 10.5460, 10.5467, 10.5473,
         10.5474, 10.5472]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[10.9301, 10.9286, 10.9300, 10.9343, 10.9342, 10.9346, 10.9340, 10.9351,
         10.9346, 10.9350],
        [ 1.0708,  1.0610,  1.0579,  1.0712,  1.0800,  1.0876,  1.0904,  1.0957,
          1.0969,  1.0982],
        [ 1.0747,  1.0730,  1.0710,  1.0722,  1.0752,  1.0791,  1.0829,  1.0871,
          1.0907,  1.0939],
        [ 1.0050,  0.9838,  0.9806,  1.0119,  1.0278,  1.0379,  1.0360,  1.0398,
          1.0342,  1.0302],
        [ 1.6223,  1.5140,  1.6121,  1.7417,  1.6462,  1.6442,  1.5987,  1.6235,
          1.6253,  1.6997],
        [ 1.0781,  0.9882,  1.0743,  1.1725,  1.0988,  1.0973,  1.0633,  1.0819,
          1.0832,  1.1389],
        [ 1.0748,  1.0822,  1.0962,  1.0941,  1.0609,  1.0026,  1.0200,  1.0180,
          0.9834,  0.9823],
        [ 1.0478,  1.0452,  1.0351,  1.0294,  1.0316,  1.0298,  1.0294,  1.0289,
          1.0298,  1.0302]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.9286, 10.9300, 10.9343, 10.9342, 10.9346, 10.9340, 10.9351, 10.9346,
         10.9350, 10.9363]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[10.5335, 10.5350, 10.5339, 10.5359, 10.5361, 10.5350, 10.5353, 10.5340,
         10.5346, 10.5374],
        [ 1.0042,  1.0090,  1.0100,  1.0157,  1.0206,  1.0214,  1.0225,  1.0197,
          1.0190,  1.0254],
        [ 0.9923,  0.9958,  0.9988,  1.0025,  1.0064,  1.0098,  1.0127,  1.0145,
          1.0157,  1.0181],
        [ 1.0291,  1.0332,  1.0286,  1.0346,  1.0380,  1.0319,  1.0278,  1.0165,
          1.0118,  1.0225],
        [ 1.5688,  1.5671,  1.5445,  1.6079,  1.5996,  1.6713,  1.6041,  1.5774,
          1.6284,  1.6227],
        [ 1.1685,  1.1672,  1.1530,  1.1929,  1.1657,  1.2055,  1.1179,  1.0772,
          1.1264,  1.1188],
        [ 1.0011,  0.9264,  0.9959,  0.9793,  0.9562,  1.0172,  0.9956,  1.0084,
          1.0084,  1.0351],
        [ 1.0088,  1.0123,  1.0158,  1.0193,  1.0232,  1.0272,  1.0316,  1.0307,
          1.0289,  1.0281]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.5350, 10.5339, 10.5359, 10.5361, 10.5350, 10.5353, 10.5340, 10.5346,
         10.5374, 10.5377]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[10.8169, 10.8177, 10.8171, 10.8156, 10.8161, 10.8161, 10.8181, 10.8192,
         10.8191, 10.8187],
        [ 1.0194,  1.0205,  1.0191,  1.0126,  1.0092,  1.0065,  1.0108,  1.0178,
          1.0227,  1.0251],
        [ 1.0297,  1.0282,  1.0267,  1.0241,  1.0213,  1.0185,  1.0171,  1.0175,
          1.0190,  1.0206],
        [ 0.9794,  0.9858,  0.9858,  0.9752,  0.9732,  0.9729,  0.9872,  1.0042,
          1.0135,  1.0157],
        [ 1.4360,  1.5553,  1.5213,  1.4033,  1.4319,  1.4542,  1.5615,  1.5812,
          1.5738,  1.6140],
        [ 1.0235,  1.0894,  1.0706,  1.0054,  1.0237,  1.0550,  1.1523,  1.1902,
          1.1636,  1.2001],
        [ 1.0125,  0.9966,  0.9804,  0.9961,  1.0001,  0.9678,  1.0213,  0.9986,
          1.0144,  0.9776],
        [ 0.9965,  0.9947,  0.9961,  0.9974,  0.9952,  0.9943,  0.9934,  0.9974,
          1.0009,  1.0044]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.8177, 10.8171, 10.8156, 10.8161, 10.8161, 10.8181, 10.8192, 10.8191,
         10.8187, 10.8186]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[10.5405, 10.5405, 10.5412, 10.5408, 10.5413, 10.5421, 10.5430, 10.5421,
         10.5421, 10.5419],
        [ 1.0340,  1.0386,  1.0434,  1.0457,  1.0483,  1.0519,  1.0563,  1.0568,
          1.0564,  1.0550],
        [ 1.0227,  1.0266,  1.0307,  1.0345,  1.0381,  1.0417,  1.0456,  1.0488,
          1.0513,  1.0530],
        [ 1.0336,  1.0364,  1.0390,  1.0361,  1.0342,  1.0348,  1.0368,  1.0304,
          1.0237,  1.0160],
        [ 1.6972,  1.7136,  1.7474,  1.7176,  1.7234,  1.7910,  1.7941,  1.7672,
          1.8268,  1.7566],
        [ 1.1678,  1.1769,  1.1883,  1.1558,  1.1586,  1.1914,  1.1716,  1.1588,
          1.1842,  1.1289],
        [ 0.9947,  0.9740,  0.9839,  0.9686,  0.9446,  0.9948,  0.9847,  1.0021,
          0.9869,  1.0238],
        [ 1.0127,  1.0175,  1.0224,  1.0285,  1.0324,  1.0364,  1.0421,  1.0456,
          1.0473,  1.0482]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.5405, 10.5412, 10.5408, 10.5413, 10.5421, 10.5430, 10.5421, 10.5421,
         10.5419, 10.5404]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[10.4707, 10.4674, 10.4661, 10.4668, 10.4656, 10.4631, 10.4603, 10.4591,
         10.4599, 10.4616],
        [ 0.9926,  0.9815,  0.9699,  0.9627,  0.9546,  0.9430,  0.9279,  0.9141,
          0.9061,  0.9048],
        [ 1.0118,  1.0054,  0.9978,  0.9901,  0.9823,  0.9734,  0.9631,  0.9518,
          0.9411,  0.9322],
        [ 0.9530,  0.9395,  0.9276,  0.9272,  0.9251,  0.9160,  0.9016,  0.8929,
          0.8977,  0.9155],
        [ 1.3739,  1.3068,  1.2724,  1.3180,  1.1782,  1.1614,  1.1441,  1.1433,
          1.1388,  1.1849],
        [ 1.0157,  0.9780,  0.9829,  1.0207,  0.9574,  0.9939,  0.9939,  0.9997,
          0.9982,  1.0185],
        [ 1.0531,  1.0390,  1.0332,  1.0190,  1.0435,  1.0607,  1.0012,  0.9956,
          1.0175,  1.0127],
        [ 0.9882,  0.9838,  0.9724,  0.9610,  0.9540,  0.9452,  0.9338,  0.9202,
          0.9106,  0.9036]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.4674, 10.4661, 10.4668, 10.4656, 10.4631, 10.4603, 10.4591, 10.4599,
         10.4616, 10.4635]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[10.4730, 10.4727, 10.4722, 10.4737, 10.4745, 10.4757, 10.4757, 10.4761,
         10.4763, 10.4751],
        [ 1.0166,  1.0161,  1.0145,  1.0166,  1.0200,  1.0254,  1.0294,  1.0329,
          1.0359,  1.0349],
        [ 1.0185,  1.0183,  1.0178,  1.0178,  1.0186,  1.0204,  1.0227,  1.0253,
          1.0280,  1.0300],
        [ 0.9987,  0.9981,  0.9951,  1.0003,  1.0073,  1.0171,  1.0218,  1.0248,
          1.0261,  1.0186],
        [ 1.4813,  1.5218,  1.5142,  1.5757,  1.6252,  1.6292,  1.6957,  1.7450,
          1.7151,  1.6376],
        [ 1.0390,  1.0668,  1.0694,  1.1113,  1.1450,  1.1734,  1.2225,  1.1999,
          1.1520,  1.1048],
        [ 0.9911,  1.0141,  0.9933,  0.9832,  1.0067,  0.9995,  0.9746,  0.9725,
          0.9906,  1.0047],
        [ 1.0004,  1.0009,  1.0018,  1.0018,  1.0039,  1.0083,  1.0118,  1.0162,
          1.0219,  1.0259]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.4727, 10.4722, 10.4737, 10.4745, 10.4757, 10.4757, 10.4761, 10.4763,
         10.4751, 10.4756]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[11.0817, 11.0816, 11.0833, 11.0825, 11.0826, 11.0811, 11.0829, 11.0848,
         11.0812, 11.0808],
        [ 0.9304,  0.9243,  0.9276,  0.9276,  0.9289,  0.9240,  0.9292,  0.9422,
          0.9374,  0.9322],
        [ 0.9692,  0.9589,  0.9514,  0.9454,  0.9409,  0.9362,  0.9336,  0.9343,
          0.9339,  0.9324],
        [ 0.8938,  0.9023,  0.9288,  0.9429,  0.9570,  0.9555,  0.9751,  1.0070,
          0.9957,  0.9859],
        [ 1.2009,  1.1626,  1.2904,  1.2730,  1.2706,  1.3270,  1.3957,  1.4821,
          1.3940,  1.3992],
        [ 0.9793,  0.9799,  1.0681,  1.0649,  1.0640,  1.1483,  1.2104,  1.2333,
          1.1233,  1.1261],
        [ 1.0682,  0.9422,  0.9823,  0.9877,  0.9796,  0.9602,  0.9946,  0.9114,
          0.9105,  0.9460],
        [ 0.9553,  0.9513,  0.9478,  0.9513,  0.9527,  0.9540,  0.9566,  0.9619,
          0.9698,  0.9733]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[11.0816, 11.0833, 11.0825, 11.0826, 11.0811, 11.0829, 11.0848, 11.0812,
         11.0808, 11.0816]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[10.8271, 10.8275, 10.8277, 10.8286, 10.8291, 10.8288, 10.8285, 10.8293,
         10.8292, 10.8293],
        [ 0.9674,  0.9612,  0.9574,  0.9581,  0.9609,  0.9625,  0.9631,  0.9667,
          0.9695,  0.9725],
        [ 0.9803,  0.9758,  0.9714,  0.9681,  0.9660,  0.9646,  0.9637,  0.9637,
          0.9644,  0.9655],
        [ 0.9628,  0.9574,  0.9581,  0.9679,  0.9800,  0.9872,  0.9911,  1.0004,
          1.0060,  1.0111],
        [ 1.1958,  1.1974,  1.2026,  1.3466,  1.3929,  1.2893,  1.3040,  1.3667,
          1.3829,  1.4086],
        [ 0.9822,  1.0007,  1.0028,  1.0621,  1.0811,  1.0385,  1.0446,  1.0704,
          1.0770,  1.0876],
        [ 0.9969,  1.0301,  1.0149,  1.0192,  1.0093,  1.0064,  1.0029,  0.9936,
          0.9955,  0.9853],
        [ 0.9886,  0.9825,  0.9776,  0.9728,  0.9724,  0.9733,  0.9733,  0.9741,
          0.9763,  0.9794]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.8275, 10.8277, 10.8286, 10.8291, 10.8288, 10.8285, 10.8293, 10.8292,
         10.8293, 10.8273]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[10.7332, 10.7337, 10.7334, 10.7342, 10.7341, 10.7335, 10.7332, 10.7336,
         10.7331, 10.7333],
        [ 0.9960,  0.9958,  0.9948,  0.9967,  0.9979,  0.9969,  0.9952,  0.9952,
          0.9937,  0.9933],
        [ 1.0013,  1.0001,  0.9990,  0.9984,  0.9983,  0.9980,  0.9973,  0.9968,
          0.9961,  0.9954],
        [ 0.9867,  0.9890,  0.9890,  0.9952,  0.9986,  0.9969,  0.9938,  0.9952,
          0.9930,  0.9936],
        [ 1.3786,  1.3988,  1.3717,  1.5046,  1.4945,  1.4413,  1.4159,  1.3949,
          1.3727,  1.4520],
        [ 1.0042,  1.0133,  1.0016,  1.0590,  1.0547,  1.0317,  1.0207,  1.0116,
          1.0026,  1.0887],
        [ 1.0010,  1.0015,  1.0017,  1.0204,  1.0155,  0.9944,  1.0095,  0.9906,
          0.9881,  0.9843],
        [ 0.9974,  0.9956,  0.9947,  0.9939,  0.9943,  0.9947,  0.9943,  0.9939,
          0.9934,  0.9930]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.7337, 10.7334, 10.7342, 10.7341, 10.7335, 10.7332, 10.7336, 10.7331,
         10.7333, 10.7330]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[10.8954, 10.8953, 10.8959, 10.8962, 10.8960, 10.8963, 10.8969, 10.8962,
         10.8958, 10.8956],
        [ 0.8885,  0.8940,  0.9014,  0.9097,  0.9164,  0.9238,  0.9325,  0.9376,
          0.9408,  0.9432],
        [ 0.8653,  0.8693,  0.8740,  0.8796,  0.8855,  0.8919,  0.8989,  0.9055,
          0.9116,  0.9169],
        [ 1.0326,  1.0373,  1.0452,  1.0532,  1.0564,  1.0604,  1.0663,  1.0635,
          1.0575,  1.0509],
        [ 1.4426,  1.3484,  1.4423,  1.4815,  1.4458,  1.4760,  1.5681,  1.4879,
          1.4337,  1.4877],
        [ 1.2362,  1.1116,  1.1700,  1.1952,  1.1502,  1.1667,  1.2249,  1.1319,
          1.1060,  1.1318],
        [ 0.9862,  0.9908,  0.9754,  0.9931,  1.0101,  0.9843,  0.9661,  0.9466,
          0.9811,  0.9767],
        [ 0.9715,  0.9759,  0.9781,  0.9816,  0.9855,  0.9882,  0.9908,  0.9952,
          0.9978,  0.9996]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.8953, 10.8959, 10.8962, 10.8960, 10.8963, 10.8969, 10.8962, 10.8958,
         10.8956, 10.8954]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[10.6958, 10.6953, 10.6959, 10.6953, 10.6951, 10.6952, 10.6935, 10.6934,
         10.6939, 10.6955],
        [ 1.0192,  1.0187,  1.0199,  1.0185,  1.0166,  1.0154,  1.0092,  1.0040,
          1.0012,  1.0038],
        [ 1.0204,  1.0204,  1.0206,  1.0205,  1.0200,  1.0194,  1.0175,  1.0148,
          1.0121,  1.0105],
        [ 1.0011,  0.9999,  1.0022,  0.9990,  0.9953,  0.9937,  0.9822,  0.9750,
          0.9743,  0.9848],
        [ 1.6647,  1.6109,  1.5944,  1.5812,  1.4937,  1.5080,  1.3683,  1.3725,
          1.4187,  1.5053],
        [ 1.1141,  1.0646,  1.0495,  1.0373,  0.9568,  1.0105,  0.9080,  1.0020,
          1.0240,  1.0652],
        [ 1.0149,  1.0109,  1.0138,  1.0077,  1.0035,  1.0115,  1.0070,  1.0059,
          1.0109,  0.9898],
        [ 1.0105,  1.0110,  1.0101,  1.0096,  1.0083,  1.0066,  1.0053,  1.0009,
          0.9974,  0.9952]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.6953, 10.6959, 10.6953, 10.6951, 10.6952, 10.6935, 10.6934, 10.6939,
         10.6955, 10.6963]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[10.6841, 10.6844, 10.6846, 10.6842, 10.6839, 10.6841, 10.6815, 10.6826,
         10.6812, 10.6827],
        [ 0.9763,  0.9748,  0.9744,  0.9731,  0.9715,  0.9711,  0.9637,  0.9613,
          0.9558,  0.9564],
        [ 0.9797,  0.9783,  0.9771,  0.9758,  0.9745,  0.9733,  0.9708,  0.9682,
          0.9650,  0.9625],
        [ 0.9871,  0.9864,  0.9883,  0.9881,  0.9872,  0.9889,  0.9757,  0.9758,
          0.9691,  0.9767],
        [ 1.3794,  1.4203,  1.3797,  1.3679,  1.3254,  1.3518,  1.2453,  1.1958,
          1.1752,  1.2949],
        [ 0.9965,  1.0185,  1.0002,  0.9948,  0.9813,  1.0104,  0.9683,  0.9835,
          0.9932,  1.0424],
        [ 1.0191,  1.0134,  1.0203,  1.0629,  1.0546,  1.0427,  1.0212,  0.9982,
          0.9770,  0.9740],
        [ 1.0057,  1.0004,  0.9965,  0.9930,  0.9890,  0.9842,  0.9807,  0.9746,
          0.9706,  0.9662]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.6844, 10.6846, 10.6842, 10.6839, 10.6841, 10.6815, 10.6826, 10.6812,
         10.6827, 10.6844]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[10.7996, 10.8002, 10.8020, 10.8028, 10.8040, 10.8043, 10.8067, 10.8047,
         10.8032, 10.8004],
        [ 0.7770,  0.7805,  0.7916,  0.8053,  0.8223,  0.8389,  0.8614,  0.8740,
          0.8803,  0.8774],
        [ 0.8034,  0.7950,  0.7908,  0.7904,  0.7938,  0.8000,  0.8100,  0.8206,
          0.8305,  0.8378],
        [ 0.8923,  0.9210,  0.9598,  0.9961,  1.0319,  1.0598,  1.0944,  1.1015,
          1.0942,  1.0693],
        [ 1.2725,  1.2661,  1.3286,  1.3164,  1.3814,  1.4119,  1.4723,  1.4832,
          1.5085,  1.4523],
        [ 1.0387,  1.0339,  1.0806,  1.0715,  1.1219,  1.1450,  1.2240,  1.1776,
          1.1867,  1.1370],
        [ 1.0485,  1.0183,  0.9952,  0.9334,  0.8613,  0.8978,  0.9957,  0.8261,
          0.8519,  0.7406],
        [ 0.8891,  0.8799,  0.8751,  0.8794,  0.8851,  0.8983,  0.9154,  0.9347,
          0.9496,  0.9671]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.8002, 10.8020, 10.8028, 10.8040, 10.8043, 10.8067, 10.8047, 10.8032,
         10.8004, 10.7999]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[10.4910, 10.4893, 10.4911, 10.4911, 10.4915, 10.4906, 10.4912, 10.4926,
         10.4926, 10.4915],
        [ 0.9863,  0.9829,  0.9849,  0.9866,  0.9889,  0.9889,  0.9904,  0.9950,
          0.9988,  0.9991],
        [ 0.9837,  0.9832,  0.9833,  0.9837,  0.9846,  0.9853,  0.9861,  0.9878,
          0.9900,  0.9918],
        [ 1.0034,  0.9957,  1.0007,  1.0041,  1.0081,  1.0063,  1.0082,  1.0162,
          1.0208,  1.0172],
        [ 1.3575,  1.2841,  1.4387,  1.5293,  1.5910,  1.5024,  1.5604,  1.6147,
          1.6595,  1.5540],
        [ 1.0027,  0.9615,  1.0970,  1.2224,  1.2130,  1.1211,  1.1533,  1.1834,
          1.1933,  1.1224],
        [ 0.9592,  0.9772,  0.9682,  0.9698,  0.9568,  0.9800,  0.9917,  0.9983,
          1.0197,  1.0032],
        [ 0.9794,  0.9807,  0.9798,  0.9825,  0.9873,  0.9930,  0.9961,  0.9996,
          1.0044,  1.0088]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.4893, 10.4911, 10.4911, 10.4915, 10.4906, 10.4912, 10.4926, 10.4926,
         10.4915, 10.4909]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[10.4067, 10.4083, 10.4075, 10.4086, 10.4098, 10.4084, 10.4063, 10.4055,
         10.4066, 10.4032],
        [ 0.9618,  0.9663,  0.9683,  0.9727,  0.9791,  0.9812,  0.9783,  0.9746,
          0.9745,  0.9670],
        [ 0.9660,  0.9654,  0.9655,  0.9665,  0.9686,  0.9708,  0.9720,  0.9721,
          0.9721,  0.9705],
        [ 0.9824,  0.9951,  1.0002,  1.0094,  1.0207,  1.0209,  1.0108,  1.0009,
          1.0006,  0.9850],
        [ 1.4000,  1.4801,  1.4513,  1.3799,  1.4620,  1.3969,  1.3401,  1.3863,
          1.4357,  1.3713],
        [ 1.0376,  1.1078,  1.0826,  1.0199,  1.0920,  1.0348,  0.9850,  1.0561,
          1.1162,  1.0379],
        [ 1.0349,  1.0461,  1.0488,  1.0019,  1.0025,  0.9850,  0.9685,  0.9568,
          0.9438,  0.9582],
        [ 0.9820,  0.9785,  0.9790,  0.9781,  0.9772,  0.9811,  0.9829,  0.9811,
          0.9816,  0.9838]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.4083, 10.4075, 10.4086, 10.4098, 10.4084, 10.4063, 10.4055, 10.4066,
         10.4032, 10.4020]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[10.9700, 10.9687, 10.9678, 10.9675, 10.9689, 10.9694, 10.9678, 10.9687,
         10.9672, 10.9684],
        [ 0.9852,  0.9791,  0.9711,  0.9640,  0.9642,  0.9666,  0.9629,  0.9637,
          0.9590,  0.9602],
        [ 0.9946,  0.9912,  0.9867,  0.9815,  0.9774,  0.9747,  0.9717,  0.9695,
          0.9667,  0.9647],
        [ 0.9745,  0.9672,  0.9571,  0.9510,  0.9612,  0.9740,  0.9715,  0.9789,
          0.9734,  0.9813],
        [ 1.3842,  1.2676,  1.1211,  1.1078,  1.3107,  1.3455,  1.3087,  1.3797,
          1.3045,  1.3850],
        [ 1.0795,  1.0002,  0.8959,  0.9937,  1.0923,  1.1081,  1.1237,  1.1674,
          1.1212,  1.1707],
        [ 1.0003,  1.0088,  0.9902,  0.9975,  1.0148,  1.0136,  1.0130,  1.0060,
          0.9918,  1.0034],
        [ 0.9882,  0.9877,  0.9860,  0.9825,  0.9794,  0.9790,  0.9794,  0.9781,
          0.9785,  0.9768]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.9687, 10.9678, 10.9675, 10.9689, 10.9694, 10.9678, 10.9687, 10.9672,
         10.9684, 10.9687]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[10.4201, 10.4187, 10.4183, 10.4181, 10.4187, 10.4186, 10.4179, 10.4164,
         10.4176, 10.4175],
        [ 0.9019,  0.8879,  0.8773,  0.8699,  0.8669,  0.8658,  0.8649,  0.8624,
          0.8646,  0.8677],
        [ 0.9564,  0.9408,  0.9260,  0.9126,  0.9012,  0.8918,  0.8841,  0.8775,
          0.8726,  0.8694],
        [ 0.8504,  0.8515,  0.8593,  0.8722,  0.8916,  0.9110,  0.9268,  0.9364,
          0.9536,  0.9694],
        [ 1.1847,  1.1900,  1.1592,  1.1659,  1.1346,  1.1383,  1.1420,  1.0620,
          1.1292,  1.1482],
        [ 0.9878,  1.0022,  0.9883,  1.0029,  0.9893,  1.0016,  1.0037,  0.9637,
          1.0332,  1.0544],
        [ 1.0778,  1.0793,  1.0689,  1.1282,  1.0406,  1.0040,  0.9409,  0.9422,
          0.8807,  0.9177],
        [ 0.9114,  0.8939,  0.8781,  0.8641,  0.8553,  0.8470,  0.8461,  0.8483,
          0.8505,  0.8601]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.4187, 10.4183, 10.4181, 10.4187, 10.4186, 10.4179, 10.4164, 10.4176,
         10.4175, 10.4179]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[11.0322, 11.0313, 11.0308, 11.0301, 11.0303, 11.0302, 11.0301, 11.0309,
         11.0315, 11.0315],
        [ 1.0283,  1.0267,  1.0232,  1.0174,  1.0132,  1.0095,  1.0062,  1.0067,
          1.0095,  1.0118],
        [ 1.0138,  1.0168,  1.0185,  1.0186,  1.0177,  1.0162,  1.0143,  1.0129,
          1.0124,  1.0125],
        [ 1.0404,  1.0290,  1.0159,  1.0007,  0.9919,  0.9860,  0.9819,  0.9865,
          0.9951,  1.0007],
        [ 1.7580,  1.6339,  1.6039,  1.5127,  1.5069,  1.5076,  1.5019,  1.5364,
          1.5186,  1.5678],
        [ 1.1491,  1.0871,  1.0735,  0.9890,  0.9968,  1.0003,  0.9972,  1.0185,
          1.0089,  1.0353],
        [ 1.0019,  0.9946,  0.9915,  0.9973,  1.0284,  1.0048,  1.0022,  1.0372,
          1.0731,  1.0441],
        [ 1.0180,  1.0197,  1.0193,  1.0180,  1.0149,  1.0123,  1.0088,  1.0061,
          1.0044,  1.0026]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[11.0313, 11.0308, 11.0301, 11.0303, 11.0302, 11.0301, 11.0309, 11.0315,
         11.0315, 11.0312]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[10.6734, 10.7020, 10.7362, 10.7596, 10.7696, 10.7764, 10.7776, 10.7739,
         10.7745, 10.7722],
        [ 0.4385,  0.4158,  0.5092,  0.6618,  0.8174,  0.9632,  1.0820,  1.1619,
          1.2248,  1.2639],
        [ 0.6878,  0.6234,  0.5922,  0.6004,  0.6407,  0.7046,  0.7815,  0.8603,
          0.9370,  1.0069],
        [ 0.2937,  0.3879,  0.7033,  1.0775,  1.3833,  1.6077,  1.7314,  1.7501,
          1.7299,  1.6645],
        [ 1.1904,  1.3210,  1.4389,  1.5210,  1.5184,  1.5625,  1.5823,  1.5797,
          1.6449,  1.6144],
        [ 0.9833,  1.0543,  1.1033,  1.1375,  1.1364,  1.1877,  1.1793,  1.1691,
          1.1974,  1.1589],
        [ 1.4474,  1.2613,  1.1638,  1.1081,  0.5871,  0.8466,  0.7994,  0.8132,
          0.2442, -0.2134],
        [ 0.7234,  0.6344,  0.5927,  0.6203,  0.6984,  0.7817,  0.8930,  0.9930,
          1.0794,  1.1723]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.7020, 10.7362, 10.7596, 10.7696, 10.7764, 10.7776, 10.7739, 10.7745,
         10.7722, 10.7676]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[10.6004, 10.6016, 10.6014, 10.5982, 10.5972, 10.5974, 10.5970, 10.5971,
         10.5959, 10.5968],
        [ 1.0367,  1.0415,  1.0443,  1.0373,  1.0287,  1.0222,  1.0156,  1.0106,
          1.0033,  1.0000],
        [ 1.0296,  1.0327,  1.0358,  1.0367,  1.0356,  1.0333,  1.0300,  1.0263,
          1.0218,  1.0174],
        [ 1.0243,  1.0295,  1.0293,  1.0090,  0.9893,  0.9781,  0.9690,  0.9647,
          0.9568,  0.9585],
        [ 1.7523,  1.7667,  1.7865,  1.5830,  1.4489,  1.5031,  1.4692,  1.4280,
          1.2878,  1.3290],
        [ 1.1684,  1.1762,  1.1806,  1.0557,  0.9802,  1.0273,  1.0102,  0.9895,
          0.9334,  1.0141],
        [ 1.0227,  0.9953,  0.9994,  1.0170,  1.0548,  1.0605,  1.0307,  1.0260,
          1.0244,  1.0199],
        [ 1.0311,  1.0351,  1.0386,  1.0416,  1.0377,  1.0289,  1.0206,  1.0118,
          1.0048,  0.9952]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.6016, 10.6014, 10.5982, 10.5972, 10.5974, 10.5970, 10.5971, 10.5959,
         10.5968, 10.5967]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[10.9843, 10.9844, 10.9844, 10.9848, 10.9844, 10.9842, 10.9841, 10.9828,
         10.9825, 10.9811],
        [ 1.0460,  1.0459,  1.0453,  1.0459,  1.0443,  1.0415,  1.0386,  1.0305,
          1.0227,  1.0106],
        [ 1.0362,  1.0389,  1.0410,  1.0427,  1.0438,  1.0440,  1.0436,  1.0415,
          1.0381,  1.0328],
        [ 1.0326,  1.0259,  1.0194,  1.0168,  1.0101,  1.0024,  0.9959,  0.9800,
          0.9678,  0.9494],
        [ 1.6469,  1.6660,  1.6785,  1.6717,  1.6779,  1.6119,  1.6530,  1.5464,
          1.5092,  1.3280],
        [ 1.1410,  1.1519,  1.1590,  1.1551,  1.1586,  1.1211,  1.1445,  1.0839,
          0.9949,  0.8370],
        [ 0.9610,  0.9931,  0.9710,  0.9682,  0.9756,  1.0243,  1.0418,  1.0156,
          1.0644,  1.0633],
        [ 1.0175,  1.0193,  1.0210,  1.0224,  1.0237,  1.0241,  1.0228,  1.0206,
          1.0158,  1.0110]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.9844, 10.9844, 10.9848, 10.9844, 10.9842, 10.9841, 10.9828, 10.9825,
         10.9811, 10.9836]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[10.7545, 10.7540, 10.7534, 10.7538, 10.7541, 10.7542, 10.7540, 10.7542,
         10.7547, 10.7546],
        [ 0.9571,  0.9566,  0.9548,  0.9552,  0.9569,  0.9591,  0.9608,  0.9632,
          0.9670,  0.9701],
        [ 0.9522,  0.9524,  0.9521,  0.9520,  0.9522,  0.9529,  0.9538,  0.9551,
          0.9569,  0.9590],
        [ 1.0027,  1.0012,  0.9973,  0.9988,  1.0025,  1.0066,  1.0086,  1.0120,
          1.0173,  1.0202],
        [ 1.3094,  1.2260,  1.2101,  1.3062,  1.3190,  1.3432,  1.3384,  1.3328,
          1.3960,  1.4094],
        [ 1.1487,  1.0517,  1.0333,  1.1402,  1.1577,  1.1908,  1.1643,  1.1575,
          1.2345,  1.1821],
        [ 0.9930,  0.9954,  0.9971,  1.0090,  1.0121,  1.0095,  0.9958,  0.9835,
          0.9851,  0.9982],
        [ 0.9851,  0.9860,  0.9855,  0.9847,  0.9847,  0.9847,  0.9851,  0.9855,
          0.9868,  0.9886]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.7540, 10.7534, 10.7538, 10.7541, 10.7542, 10.7540, 10.7542, 10.7547,
         10.7546, 10.7552]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[10.7927, 10.7917, 10.7923, 10.7926, 10.7927, 10.7914, 10.7909, 10.7896,
         10.7894, 10.7894],
        [ 1.0259,  1.0176,  1.0129,  1.0101,  1.0080,  1.0022,  0.9957,  0.9866,
          0.9790,  0.9731],
        [ 1.0355,  1.0322,  1.0286,  1.0250,  1.0218,  1.0179,  1.0134,  1.0078,
          1.0017,  0.9955],
        [ 0.9824,  0.9689,  0.9654,  0.9665,  0.9689,  0.9630,  0.9570,  0.9469,
          0.9418,  0.9413],
        [ 1.4544,  1.3920,  1.4284,  1.4316,  1.3943,  1.3301,  1.3801,  1.3082,
          1.2859,  1.2385],
        [ 0.9851,  0.9726,  1.0138,  1.0150,  1.0009,  0.9766,  1.0210,  0.9908,
          0.9911,  0.9820],
        [ 1.0355,  1.0406,  0.9866,  0.9944,  1.0006,  1.0168,  1.0375,  1.0540,
          1.0500,  0.9932],
        [ 1.0136,  1.0088,  1.0026,  0.9982,  0.9961,  0.9934,  0.9890,  0.9855,
          0.9803,  0.9750]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.7917, 10.7923, 10.7926, 10.7927, 10.7914, 10.7909, 10.7896, 10.7894,
         10.7894, 10.7886]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[10.5745, 10.5742, 10.5753, 10.5746, 10.5723, 10.5719, 10.5739, 10.5748,
         10.5754, 10.5764],
        [ 1.0093,  1.0090,  1.0114,  1.0115,  1.0054,  0.9995,  1.0001,  1.0029,
          1.0068,  1.0123],
        [ 1.0114,  1.0111,  1.0113,  1.0116,  1.0104,  1.0082,  1.0066,  1.0059,
          1.0062,  1.0076],
        [ 0.9970,  0.9969,  1.0025,  1.0022,  0.9891,  0.9791,  0.9845,  0.9934,
          1.0027,  1.0136],
        [ 1.5079,  1.5386,  1.6670,  1.5678,  1.4187,  1.3383,  1.4372,  1.4800,
          1.4965,  1.5895],
        [ 1.0233,  1.0503,  1.2322,  1.0792,  0.9424,  0.9448,  1.0512,  1.0734,
          1.0820,  1.1301],
        [ 1.0096,  1.0346,  1.0370,  1.0304,  1.0320,  0.9994,  1.0107,  0.9881,
          0.9714,  1.0015],
        [ 1.0096,  1.0083,  1.0070,  1.0079,  1.0066,  1.0013,  0.9952,  0.9939,
          0.9939,  0.9961]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.5742, 10.5753, 10.5746, 10.5723, 10.5719, 10.5739, 10.5748, 10.5754,
         10.5764, 10.5772]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[10.9558, 10.9551, 10.9554, 10.9546, 10.9548, 10.9548, 10.9562, 10.9546,
         10.9548, 10.9554],
        [ 1.0061,  1.0059,  1.0069,  1.0046,  1.0032,  1.0023,  1.0070,  1.0042,
          1.0028,  1.0041],
        [ 1.0122,  1.0110,  1.0103,  1.0093,  1.0081,  1.0070,  1.0071,  1.0066,
          1.0059,  1.0056],
        [ 0.9868,  0.9891,  0.9933,  0.9899,  0.9890,  0.9893,  1.0011,  0.9951,
          0.9934,  0.9973],
        [ 1.5584,  1.4897,  1.5080,  1.4030,  1.3740,  1.3610,  1.5533,  1.4557,
          1.4706,  1.5384],
        [ 1.1023,  1.0634,  1.0737,  1.0142,  0.9978,  0.9927,  1.1031,  1.0526,
          1.0651,  1.1244],
        [ 1.0462,  1.0489,  1.0105,  1.0006,  1.0011,  0.9841,  0.9932,  0.9797,
          0.9689,  0.9667],
        [ 0.9996,  0.9991,  0.9974,  0.9965,  0.9947,  0.9939,  0.9930,  0.9956,
          0.9956,  0.9965]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.9551, 10.9554, 10.9546, 10.9548, 10.9548, 10.9562, 10.9546, 10.9548,
         10.9554, 10.9546]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[10.3453, 10.3455, 10.3443, 10.3442, 10.3440, 10.3432, 10.3434, 10.3433,
         10.3434, 10.3438],
        [ 1.0107,  1.0063,  1.0003,  0.9953,  0.9911,  0.9861,  0.9829,  0.9802,
          0.9785,  0.9783],
        [ 1.0232,  1.0200,  1.0160,  1.0118,  1.0075,  1.0030,  0.9987,  0.9946,
          0.9910,  0.9881],
        [ 0.9724,  0.9688,  0.9626,  0.9598,  0.9591,  0.9571,  0.9590,  0.9616,
          0.9658,  0.9722],
        [ 1.3765,  1.4426,  1.4424,  1.2091,  1.2460,  1.2520,  1.2844,  1.2384,
          1.1818,  1.2233],
        [ 0.9611,  1.0430,  1.0428,  0.8911,  1.0170,  1.0198,  1.0375,  1.0146,
          0.9859,  1.0210],
        [ 1.0165,  0.9981,  0.9909,  1.0038,  1.0192,  1.0204,  1.0073,  1.0274,
          1.0299,  0.9960],
        [ 1.0004,  0.9917,  0.9882,  0.9851,  0.9794,  0.9750,  0.9706,  0.9676,
          0.9654,  0.9627]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.3455, 10.3443, 10.3442, 10.3440, 10.3432, 10.3434, 10.3433, 10.3434,
         10.3438, 10.3433]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[10.4188, 10.4167, 10.4164, 10.4195, 10.4198, 10.4201, 10.4204, 10.4221,
         10.4218, 10.4215],
        [ 1.0171,  1.0114,  1.0060,  1.0087,  1.0115,  1.0142,  1.0170,  1.0227,
          1.0263,  1.0281],
        [ 1.0264,  1.0236,  1.0202,  1.0181,  1.0169,  1.0166,  1.0170,  1.0185,
          1.0205,  1.0225],
        [ 0.9814,  0.9733,  0.9675,  0.9796,  0.9893,  0.9972,  1.0034,  1.0146,
          1.0190,  1.0190],
        [ 1.4485,  1.4152,  1.4100,  1.5606,  1.5884,  1.6292,  1.5366,  1.5613,
          1.5556,  1.5927],
        [ 1.0413,  1.0301,  1.0282,  1.1439,  1.1653,  1.2018,  1.0983,  1.1175,
          1.1131,  1.1419],
        [ 0.9699,  0.9557,  1.0158,  1.0396,  1.0364,  1.0169,  0.9990,  0.9922,
          0.9890,  0.9818],
        [ 0.9974,  0.9978,  0.9961,  0.9943,  0.9961,  0.9978,  1.0009,  1.0026,
          1.0066,  1.0101]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.4167, 10.4164, 10.4195, 10.4198, 10.4201, 10.4204, 10.4221, 10.4218,
         10.4215, 10.4234]])
[4mTime series transformer
[33mx[39m --> (None, None, None):  torch.Size([512, 8, 10])
[33mx_deconv[39m --> (None, None, None):  torch.Size([512, 8, 10])
[4mPositional encoding
[33mx[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mpe[39m --> (None, None, None):  torch.Size([1000, 1, 8])
[33mpe_resized[39m --> (None, None, None):  torch.Size([10, 1, 8])
[33mx + pe_resized[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted and pos_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_transformer_encoded[39m --> (None, None, None):  torch.Size([10, 512, 8])
[33mx_permuted[39m --> (None, None, None):  torch.Size([512, 10, 8])
[33mx_fc_decoded[39m --> (None, None, None):  torch.Size([512, 10, 1])
signal tensor([[10.9060, 10.9056, 10.9042, 10.9031, 10.9032, 10.9032, 10.9024, 10.9025,
         10.9022, 10.9029],
        [ 1.0898,  1.0881,  1.0804,  1.0695,  1.0606,  1.0531,  1.0435,  1.0360,
          1.0283,  1.0245],
        [ 1.0644,  1.0706,  1.0740,  1.0743,  1.0726,  1.0696,  1.0651,  1.0599,
          1.0541,  1.0486],
        [ 1.0786,  1.0593,  1.0316,  1.0028,  0.9838,  0.9715,  0.9575,  0.9505,
          0.9444,  0.9478],
        [ 1.6883,  1.6711,  1.6095,  1.5633,  1.6277,  1.6055,  1.5388,  1.5387,
          1.4769,  1.4863],
        [ 1.0940,  1.0856,  1.0589,  1.0389,  1.0668,  1.0546,  0.9863,  0.9999,
          0.9679,  1.0041],
        [ 0.9272,  0.9456,  0.9738,  0.9693,  1.0057,  1.0146,  1.0936,  1.0957,
          1.0957,  1.1760],
        [ 1.0482,  1.0504,  1.0522,  1.0500,  1.0447,  1.0408,  1.0355,  1.0276,
          1.0189,  1.0096]])
preds tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],
       grad_fn=<ToCopyBackward0>)
targets tensor([[10.9056, 10.9042, 10.9031, 10.9032, 10.9032, 10.9024, 10.9025, 10.9022,
         10.9029, 10.9041]])